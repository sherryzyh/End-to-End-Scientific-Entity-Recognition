Proceedings O
of O
NAACL O
- O
HLT O
2018 O
, O
pages O
37–46 O
New O
Orleans O
, O
Louisiana O
, O
June O
1 O
- O
6 O
, O
2018 O
. O

c O

2018 O
Association O
for O
Computational O
Linguistics O
A O
Deep B-MethodName
Generative I-MethodName
Model I-MethodName
of O
Vowel O
Formant O
Typology O

Ryan O
Cotterell O
andJason O
Eisner O
Department O
of O
Computer O
Science O
Johns O
Hopkins O
University O
, O
Baltimore O
MD O
, O
21218 O
{ O
ryan.cotterell O
, O
eisner O
} O
@jhu.edu O

Abstract O
What O
makes O
some O
types O
of O
languages O
more O
probable O
than O
others O
? O

For O
instance O
, O
we O
know O
that O
almost O
all O
spoken O
languages O
contain O
the O
vowel O
phoneme O
/i/ O
; O
why O
should O
that O
be O
? O

The O
ﬁeld O
of O
linguistic O
typology O
seeks O
to O
answer O
these O
questions O
and O
, O
thereby O
, O
divine O
the O
mech- O
anisms O
that O
underlie O
human O
language O
. O

In O
our O
work O
, O
we O
tackle O
the O
problem O
of O
vowel O
system O
typology O
, O
i.e. O
, O
we O
propose O
a O
generative B-MethodName
proba-bility I-MethodName
model I-MethodName
of O
which O
vowels O
a O
language O
con- O
tains O
. O

In O
contrast O
to O
previous O
work O
, O
we O
work O
di- O
rectly O
with O
the O
acoustic O
information O
— O
the O
ﬁrst O
two O
formant O
values O
— O
rather O
than O
modeling O
dis- O
crete O
sets O
of O
phonemic O
symbols O
( O
IPA O
) O
. O

We O
de- O
velop O

a O
novel O
generative B-MethodName
probability I-MethodName
model I-MethodName
and O
report O
results O
based O
on O
a O
corpus O
of O
233 O
lan- O
guages O
. O

1 O
Introduction O
Human O
languages O
are O
far O
from O
arbitrary O
; O
cross- O
linguistically O
, O
they O
exhibit O
surprising O
similarity O
in O
many O
respects O
and O
many O
properties O
appear O
to O
be O
universally O
true O
. O

The O
ﬁeld O
of O
linguistic O
typology O
seeks O
to O
investigate O
, O
describe O
and O
quantify O
the O
axes O
along O
which O
languages O
vary O
. O

One O
facet O
of O
language O
that O
has O
been O
the O
subject O
of O
heavy O
investigation O
is O
the O
nature O
of O
vowel O
inventories O
, O
i.e. O
, O
which O
vowels O
a O
language O
contains O
. O

It O
is O
a O
cross O
- O
linguistic O
univer- O
sal O
that O
all O
spoken O
languages O
have O
vowels O
( O
Gordon O
, O
2016 O
) O
, O
and O
the O
underlying O
principles O
guiding O
vowel O
selection O
are O
understood O
: O
vowels O
must O
be O
both O
easily O
recognizable O
and O
well O
- O
dispersed O
( O
Schwartz O
et O
al O
. O
, O
2005 O
) O
. O

In O
this O
work O
, O
we O
offer O
a O
more O
formal O
treatment O
of O
the O
subject O
, O
deriving O
a O
generative B-MethodName
prob-ability I-MethodName
model I-MethodName
of O
vowel O
inventory O
typology O
. O

Our O
work O
builds O
on O
( O
Cotterell O
and O
Eisner O
, O
2017 O
) O
by O
in- O

vestigating O
not O
just O
discrete O
IPA O
inventories O
but O
the O
cross O
- O
linguistic O
variation O
in O
acoustic O
formants O
. O

The O
philosophy O
behind O
our O
approach O
is O
that O
lin- O
guistic O
typology O
should O
be O
treated O
probabilisticallyand O
its O
goal O
should O
be O
the O
construction O
of O
a O
univer- O
sal O
prior O
over O
potential O
languages O
. O

A O
probabilistic O
approach O
does O
not O
rule O
out O
linguistic O
systems O
com- O
pletely O
( O
as O
long O
as O
one O
’s O
theoretical O
formalism O
can O
describe O
them O
at O
all O
) O
, O
but O
it O
can O
position O
phenomena O
on O
a O
scale O
from O
very O
common O
to O
very O
improbable O
. O

Probabilistic O
modeling O
also O
provides O
a O
discipline O
for O
drawing O
conclusions O
from O
sparse O
data O
. O

While O
we O
know O
of O
over O
7000 O
human O
languages O
, O
we O
have O
some O
sort O
of O
linguistic O
analysis O
for O
only O
2300 O
of O
them O
( O
Comrie O
et O
al O
. O
, O
2013 O
) O
, O
and O
the O
dataset O
used O
in O
this O
paper O
( O
Becker O
- O
Kristal O
, O
2010 O
) O
provides O
simple O
vowel O
data O
for O
fewer O
than O
250 O
languages O
. O

Formants O
are O
the O
resonant O
frequencies O
of O
the O
hu- O
man O
vocal O
tract O
during O
the O
production O
of O
speech O
sounds O
. O

We O
propose O
a O
Bayesian O
generative B-MethodName
model I-MethodName
of O
vowel O
inventories O
, O
where O
each O
language O
’s O
inven- O

tory O
is O
a O
ﬁnite O
subset O
of O
acoustic O
vowels O
represented O
as O
points O
( O
F1,F2)∈R2 O
. O

We O
deploy O
tools O
from O
the O
neural O
- O
network O
and O
point O
- O
process O
literatures O
and O
experiment O
on O
a O
dataset O
with O
233 O
distinct O
languages O
. O

We O
show O
that O
our O
most O
complicated O
model O
outper- O
forms O
simpler O
models O
. O

2 O
Acoustic O
Phonetics O
and O
Formants O
Much O
of O
human O
communication O
takes O
place O
through O
speech O
: O
one O
conversant O
emits O
a O
sound O
wave O
to O
be O
comprehended O
by O
a O
second O
. O

In O
this O
work O
, O
we O
consider O
the O
nature O
of O
the O
portions O
of O
such O
sound O
waves O
that O
correspond O
to O
vowels O
. O

We O
brieﬂy O
review O
the O
relevant O
bits O
of O
acoustic O
phonetics O
so O
as O
to O
give O
an O
overview O
of O
the O
data O
we O
are O
actually O
modeling O
and O
develop O
our O
notation O
. O

The O
anatomy O
of O
a O
sound O
wave O
. O

The O
sound O
wave O
that O
carries O
spoken O
language O
is O
a O
function O
from O
time O
to O
amplitude O
, O
describing O
sound O
pressure O
vari- O
ation O
in O
the O
air O
. O

To O
distinguish O
vowels O
, O
it O
is O
help- O
ful O
to O
transform O
this O
function O
into O
a O
spectrogram O
( O
Fig O
. O
1 O
) O
by O
using O
a O
short O
- O
time O
Fourier O
transform37 O

Example O
spectrogram O
of O
the O
three O
English O
vowels O
: O
/i/ O
, O
/u/ O

and O
/ O
A/. O
Thex O
- O
axis O
is O
time O
and O
y O
- O
axis O
is O
frequency O
. O

The O
ﬁrst O
two O
formants O
F1andF2are O
marked O
in O
with O
arrows O
for O
each O
vowel O
. O

The O
ﬁgure O
was O
made O
with O
Praat O
( O
Boersma O
et O
al O
. O
, O
2002 O
) O
. O

( O
Deng O
and O
O’Shaughnessy O
, O
2003 O
, O
Chapter O
1 O
) O
to O
de- O
compose O
each O
short O
interval O
of O
the O
wave O
function O
into O
a O
weighted O
sum O
of O
sinusoidal O
waves O
of O
differ- O
ent O
frequencies O
( O
measured O
in O
Hz O
) O
. O

At O
each O
interval O
, O
the O
variable O
darkness O
of O
the O
spectrogram O
indicates O
the O
weights O
of O
the O
different O
frequencies O
. O

In O
pho- O
netic O
analysis O
, O
a O
common O
quantity O
to O
consider O
is O
aformant O
— O
a O
local O
maximum O
of O
the O
( O
smoothed O
) O
frequency O
spectrum O
. O

The O
fundamental O
frequency O
F0determines O
the O
pitch O
of O
the O
sound O
. O

The O
formants O
F1andF2determine O
the O
quality O
of O
the O
vowel O
. O

Two O
is O
all O
you O
need O
( O
and O
what O
we O
left O
out O
) O
. O

In O
terms O
of O
vowel O
recognition O
, O
it O
is O
widely O
speculated O
that O
humans O
rely O
almost O
exclusively O
on O
the O
ﬁrst O
two O
formants O
of O
the O
sound O
wave O
( O
Ladefoged O
, O
2001 O
, O
Chapter O
5 O
) O
. O

The O
two O
- O
formant O
assumption O
breaks O
down O
in O
edge O
cases O
: O
e.g. O
, O
the O
third O
formant O
F3 O
helps O
to O
distinguish O
the O
roundness O
of O
the O
vowel O
( O
Ladefoged O
, O
2001 O
, O
Chapter O
5 O
) O
. O

Other O
non O
- O
formant O
features O
may O
also O
play O
a O
role O
. O

For O
example O
, O
in O
tonal O
languages O
, O
the O
same O
vowel O
may O
be O
realized O
with O
different O
tones O
( O
which O
are O
signaled O
using O
F0 O
): O

Mandarin O
Chinese O
makes O
a O
distinction O
between O
m O
ˇ O
a O
( O
horse O
) O
and O
m O
´ O
a O
( O
hemp O
) O
without O
modifying O
the O
qual- O
ity O
of O
the O
vowel O
/a/. O

Other O
features O
, O
such O
as O
creaky O
voice O
, O
can O
play O
a O
role O
in O
distinguishing O
phonemes O
. O

We O
do O
not O
explicitly O
model O
any O
of O
these O
aspects O
of O
vowel O
space O
, O
limiting O
ourselves O
to O
( O
F1,F2)as O
in O
previous O
work O
( O
Liljencrants O
and O
Lindblom O
, O
1972 O
) O
. O

However O
, O
it O
would O
be O
easy O
to O
extend O
all O
the O
models O
we O
will O
propose O
here O
to O
incorporate O
such O
informa- O
tion O
, O
given O
appropriate O
datasets O
. O

3 O
The O
Phonology O
of O
Vowel O
Systems O
The O
vowel O
inventories O
of O
the O
world O
’s O
languages O
display O
clear O
structure O
and O
appear O
to O
obey O
several O
underlying O
principles O
. O

The O
most O
prevalent O
of O
theseprinciples O
are O
focalization O
anddispersion O
. O

Focalization O
. O

The O
notion O
of O
focalization O
grew O
out O
of O
quantal O
vowel O
theory O
( O
Stevens O
, O
1989 O
) O
. O

Quan- O
tal O
vowels O
are O
those O
that O
are O
phonetically O
“ O
better O
” O
than O
others O
. O

They O
tend O
to O
display O
certain O
proper- O
ties O
, O
e.g. O
, O
the O
formants O
tend O
to O
be O
closer O
together O
( O
Stevens O
, O
1987 O
) O
. O

Cross O
- O
linguistically O
, O
quantal O
vow- O
els O
are O
the O
most O
frequently O
attested O
vowels O
, O
e.g. O
, O
the O
cross O
- O
linguistically O
common O
vowel O
/i/ O
is O
considered O
quantal O
, O
but O
less O
common O
/y/ O
is O
not O
. O

Dispersion O
. O

The O
second O
core O
principle O
of O
vowel O
system O
organization O
is O
known O
as O
dispersion O
. O

As O
the O
name O
would O
imply O
, O
the O
principle O
states O
that O
the O
vowels O
in O
“ O
good O
” O
vowel O
systems O
tend O
to O
be O
spread O
out O
. O

The O
motivation O
for O
such O
a O
principle O
is O
clear O
— O
a O
well O
- O
dispersed O
set O
of O
vowels O
reduces O
a O
listener O
’s O
potential O
confusion O
over O
which O
vowel O
is O
being O
pronounced O
. O

See O
Schwartz O
et O
al O
. O

( O
1997 O
) O
for O
a O
review O
of O
dispersion O
in O
vowel O
system O
typology O
and O
its O
interaction O
with O
focalization O
, O
which O
has O
led O
to O
the O
joint O
dispersion O
- O
focalization O
theory O
. O

Notation O
. O

We O
will O
denote O
the O
universal O
set O
of O
international O
phonetic O
alphabet O
( O
IPA O
) O
symbols O
asV. O

The O
observed O
vowel O
inventory O
for O
lan- O
guage O
/ O
lscripthas O
sizen O
/ O
lscriptand O
is O
denoted O
V O
/ O
lscript= O
{ O
( O
v O
/ O
lscript O
1,v O
/ O
lscript O
1 O
) O
, O
... O
, O
( O
v O
/ O
lscript O
n O
/ O
lscript O
, O
v O
/ O
lscript O
n O
/ O
lscript)}⊆V× O
Rd O
, O
where O
for O
eachk∈[1,n O
/ O
lscript],v O
/ O
lscript O
k∈V O
is O
an O
IPA O
symbol O
assigned O
by O
a O
linguist O
and O
v O
/ O
lscript O
k∈Rdis O
a O
vector O
of O
dmeasur- O
able O
phonetic O
quantities O
. O

In O
short O
, O
the O
IPA O
symbol O
v O
/ O
lscript O
kwas O
assigned O
as O
a O
label O
for O
a O
phoneme O
with O
pro- O
nunciation O
v O
/ O
lscript O
k. O

The O
ordering O
of O
the O
elements O
within O
V O
/ O
lscriptis O
arbitrary O
. O

Goals O
. O

This O
framework O
recognizes O
that O
the O
same O
IPA O
symbolv(such O
as O
/u/ O
) O
may O
represent O
a O
slightly O
different O
sound O
vin O
one O
language O
than O
in O
another O
, O
although O
they O
are O
transcribed O
identically O
. O

We O
are O
speciﬁcally O
interested O
in O
how O
the O
vowels O
in O
a O
lan- O
guage O
inﬂuence O
one O
another O
’s O
ﬁne O
- O
grained O
pro- O
nunciation O
in O
Rd O
. O

In O
general O
, O
there O
is O
no O
reason O
to O
suspect O
that O
speakers O
of O
two O
languages O
, O
whose O
phonological O
systems O
contain O
the O
same O
IPA O
symbol O
, O
should O
produce O
that O
vowel O
with O
identical O
formants O
. O

Data O
. O

For O
the O
remainder O
of O
the O
paper O
, O
we O
will O
taked= O
2 O
so O
that O
each O
v= O
( O
F1,F2)∈R2 O
, O
the O
vector O
consisting O
of O
the O
ﬁrst O
two O
formant O
values O
, O
as O
compiled O
from O
the O
ﬁeld O
literature O
by O
Becker- O
Kristal O
( O
2006 O
) O
. O

This O
dataset O
provides O
inventories O
V O
/ O
lscriptin O
the O
form O
above O
. O

Thus O
, O
we O
do O
not O
consider O
further O
variation O
of O
the O
vowel O
pronunciation O
that38 O

may O
occur O
within O
the O
language O
( O
between O
speakers O
, O
between O
tokens O
of O
the O
vowel O
, O
or O
between O
earlier O
and O
later O
intervals O
within O
a O
token O
) O
. O

4 O
Phonemes O
versus O
Phones O
Previous O
work O
( O
Cotterell O
and O
Eisner O
, O
2017 O
) O
has O
placed O
a O
distribution O
over O
discrete O
phonemes O
, O
ignor- O

ing O
the O
variation O
across O
languages O
in O
the O
pronuncia- O
tionof O
each O
phoneme O
. O

In O
this O
paper O
, O
we O
crack O
open O
the O
phoneme O
abstraction O
, O
moving O
to O
a O
learned O
set O
of O
ﬁner O
- O
grained O
phones O
. O

Cotterell O
and O
Eisner O
( O
2017 O
) O
proposed O
( O
among O
other O
options O
) O
using O
a O
determinantal O
point O
process O
( O
DPP B-MethodName
) O
over O
a O
universal O
inventory O
Vof O
53 O
sym- O
bolic O
( O
IPA O
) O
vowels O
. O

A O
draw O
from O
such O
a O
DPP B-MethodName
is O
a O
language O
- O
speciﬁc O
inventory O
of O
vowel O
phonemes O
, O
V⊆V. O

In O
this O
paper O
, O
we O
say O
that O
a O
language O
in- O
stead O
draws O
its O
inventory O
from O
a O
larger O
set O
¯V O
, O
again O
using O
a O
DPP B-MethodName
. O

In O
both O
cases O
, O
the O
reason O
to O
use O
a O
DPP B-MethodName
is O
that O
it O
prefers O
relatively O
diverse O
inventories O
whose O
individual O
elements O
are O
relatively O
quantal O
. O

While O
we O
could O
in O
principle O
identify O
¯VwithRd O
, O
for O
convenience O
we O
still O
take O
it O
to O
be O
a O
( O
large O
) O
dis- O
crete O
ﬁnite O
set O
¯V={¯v1 O
, O
... O
, O
¯vN O
} O
, O
whose O
elements O
we O
call O
phones O
.¯Vis O

a O
learned O
cross O
- O
linguistic O
pa- O
rameter O
of O
our O
model O
; O
thus O
, O
its O
elements O
— O
the O
“ O
uni- O
versal O
phones”—may O
or O
may O
not O
correspond O
to O
phonetic O
categories O
traditionally O
used O
by O
linguists O
. O

We O
presume O
that O
language O
/lscriptdraws O
from O
the O
DPP B-MethodName
a O
subset O
¯V O
/ O
lscript⊆¯V O
, O
whose O
size O
we O
call O
n O
/ O
lscript O
. O

For O
each O
universal O
phone O
¯vithat O
appears O
in O
this O
inventory O
¯V O
/ O
lscript O
, O
the O
language O
then O
draws O
an O
observable O
language- O
speciﬁc O
pronunciation O
v O
/ O
lscript O
i∼N O
/ O
parenleftbig O
µi O
, O
σ2I O
/ O
parenrightbig O
from O
a O
distribution O
associated O
cross O
- O
linguistically O
with O
the O
universal O
phone O
¯vi O
. O

We O
now O
have O
an O
inventory O
of O
pronunciations O
. O

As O
a O
ﬁnal O
step O
in O
generating O
the O
vowel O
inventory O
, O
we O
could O
model O
IPA O
labels O
. O

For O
each O
¯vi∈¯V O
/ O
lscript O
, O
a O
ﬁeld O
linguist O
presumably O
draws O
the O
IPA O
label O
v O
/ O
lscript O
i O
conditioned O
on O
all O
the O
pronunciations O
{ O
v O
/ O
lscript O
i∈Rd O
: O
¯vi∈¯V O
/ O
lscript}in O
the O
inventory O
( O
and O
perhaps O
also O
on O
their O
underlying O
phones O
¯vi∈¯V O
/ O
lscript O
) O
. O

This O
labeling O
process O
may O
be O
complex O
. O

While O
each O
pronuncia- O
tion O
in O
Rd(or O
each O
underlying O
phone O
in O
¯V O
) O
may O
have O
a O
preference O
for O
certain O
IPA O
labels O
in O
V O
, O
the O
n O
/ O
lscriptlabels O
must O
be O
drawn O
jointly O
because O
the O
lin- O
guist O
will O
take O
care O
not O
to O
use O
the O
same O
label O
for O
two O
phones O
, O
and O
also O
because O
the O
linguist O
may O
like O
to O
describe O
the O
inventory O
using O
a O
small O
number O
of O
distinct O
IPA O
features O
, O
which O
will O
tend O
to O
favor O
fac- O
torial O
grids O
of O
symbols O
. O

The O
linguist O
’s O
use O
of O
IPAfeatures O
may O
also O
be O
informed O
by O
phonological O
and O
phonetic O
processes O
in O
the O
language O
. O

We O
leave O
mod- O
eling O
of O
this O
step O
to O
future O
work O
; O
so O
our O
current O
likelihood O
term O
ignores O
the O
evidence O
contributed O
by O
the O
IPA O
labels O
in O
the O
dataset O
, O
considering O
only O
the O
pronunciations O
in O
Rd O
. O

The O
overall O
idea O
is O
that O
human O
languages O
/lscriptdraw O
their O
inventories O
from O
some O
universal O
prior O
, O
which O
we O
are O
attempting O
to O
reconstruct O
. O

A O
caveat O
is O
that O
we O
will O
train O
our O
method O
by O
maximum O
- O
likelihood O
, O
which O
does O
not O
quantify O
our O
uncertainty O
about O
the O
reconstructed O
parameters O
. O

An O
additional O
caveat O
is O
that O
some O
languages O
in O
our O
dataset O
are O
related O
to O
one O
another O
, O
which O
belies O
the O
idea O
that O
they O
were O
drawn O
independently O
. O

Ideally O
, O
one O
ought O
to O
capture O
these O
relationships O
using O
hierarchical O
or O
evolution- O
ary O
modeling O
techniques O
. O

5 O
Determinantal O
Point O
Processes O
Before O
delving O
into O
our O
generative B-MethodName
model I-MethodName
, O
we O
brieﬂy O
review O
technical O
background O
used O
by O
Cot- O
terell O
and O
Eisner O
( O
2017 O
) O
. O

A O
DPP B-MethodName
is O
a O
probability O
distribution O
over O
the O
subsets O
of O
a O
ﬁxed O
ground O
set O
of O
sizeN O
— O
in O
our O
case O
, O
the O
set O
of O
phones O
¯V. O
The O
DPP B-MethodName
is O
usually O
given O
as O
an O
L O
- O
ensemble O
( O
Borodin O
and O
Rains O
, O
2005 O
) O
, O
meaning O
that O
it O
is O
parameterized O
by O
a O
positive O
semi O
- O
deﬁnite O
matrix O
L∈RN×N. O
Given O
a O
discrete O
base O
set O
¯Vof O
phones O
, O
the O
probability O
of O
a O
subset O
¯V⊆¯Vis O
given O
by O
p(¯V)∝det(L¯V O
) O
, O
( O
1 O
) O
whereL¯Vis O
the O
submatrix O
of O
Lcorresponding O
to O
the O
rows O
and O
columns O
associated O
with O
the O
subset O
¯V⊆¯V. O
The O
entryLij O
, O
wherei O
/ O
negationslash O
= O
j O
, O
has O
the O
effect O
of O
describing O
the O
similarity O
between O
the O
elements O
¯viand¯vj(both O
in O
¯V)—an O
ingredient O
needed O
to O
model O
dispersion O
. O

And O
, O
the O
entry O
Liidescribes O
the O
quality O
— O
focalization O
— O
of O
the O
vowel O
¯vi O
, O
i.e. O
, O
how O
much O
the O
model O
wants O
to O
have O
¯viin O
a O
sampled O
set O
independent O
of O
the O
other O
members O
. O

5.1 O
Probability O
Kernel O
In O
this O
work O
, O
each O
phone O
¯vi∈¯Vis O
associated O
with O
a O
probability O
density O
over O
the O
space O
of O
possible O
pro- O
nunciations O
R2 O
. O

Our O
measure O
of O
phone O
similarity O
will O
consider O
the O
“ O
overlap O
” O
between O
the O
densities O
associated O
with O
two O
phones O
. O

This O
works O
as O
follows O
: O
Given O
two O
densities O
f(x O
, O
y)andf O
/ O
prime(x O
, O
y)overR2 O
, O
we O
deﬁne O
the O
kernel O
( O
Jebara O
et O
al O
. O
, O
2004 O
) O
as O
K(f O
, O
f O
/ O
prime;ρ O

) O

= O
/integraldisplay O
x O
/ O
integraldisplay O
yf(x O
, O
y)ρf O
/ O
prime(x O
, O
y)ρdxdy O
, O
( O
3)39 O

M O
/ O
productdisplay O
/lscript=1 O
/ O
bracketleftBig O
p(v O
/ O
lscript,1, O
... O
,v O
/ O
lscript O
, O
n O
/ O
lscript|µ1, O
... O
,µN O
, O
N)/bracketrightBig O
p(µ1, O
... O
µN|N)p(N O
) O
( O
2 O
) O
= O
M O
/ O
productdisplay O
/lscript=1 O
/ O
bracketleftBigg O
/ O
summationdisplay O
a O
/ O
lscript∈A(n O
/ O
lscript O
, O
N)/parenleftBiggn O
/ O
lscript O
/ O
productdisplay O
k=1p(v O
/ O
lscript O
, O
k|µa O
/ O
lscript O
k O
) O
/bracehtipupleft O
/ O
bracehtipdownright O
/ O
bracehtipdownleft O
/ O
bracehtipupright O
4 O
/ O
parenrightBigg O
p(¯V(a O
/ O
lscript)|µ1, O
... O
,µN O
, O
N)/bracehtipupleft O
/ O
bracehtipdownright O
/ O
bracehtipdownleft O
/ O
bracehtipupright O
3 O
/ O
bracketrightBigg O

p(µ1, O
... O
µN|N)/bracehtipupleft O
/ O
bracehtipdownright O
/ O
bracehtipdownleft O
/ O
bracehtipupright O
2p(N)/bracehtipupleft O
/ O
bracehtipdownright O
/ O
bracehtipdownleft O
/ O
bracehtipupright O
1 O
Figure O
2 O
: O
Joint O
likelihood O
of O
Mvowel O
systems O
under O
our O
deep O
generative B-MethodName
probability I-MethodName
model I-MethodName
for O
continuous O
- O
space O
vowel O
inventories O
. O

Here O
language O
/lscripthas O
an O
observed O
inventory O
of O
pronunciations O
{ O
v O
/ O
lscript O
, O
k O
: O
1≤k≤n O
/ O
lscript O
} O
, O
anda O
/ O
lscript O
k∈[1,N]denotes O
a O
phone O
that O
might O
be O
responsible O
for O
the O
pronunciation O
v O
/ O
lscript O
, O
k. O

Thus O
, O
a O
/ O
lscriptdenotes O
some O
way O
to O
jointly O
label O
all O
n O
/ O
lscriptpronunciations O
with O
distinct O
phones O
. O

We O
must O
sum O
over O
all O
/ O
parenleftbigN O
n O
/ O
lscript O
/ O
parenrightbig O
such O
labelings O
a O
/ O
lscript∈A(n O
/ O
lscript O
, O
N)since O
the O
true O
labeling O
is O
not O
observed O
. O

In O
other O
words O
, O
we O
sum O
over O
all O
ways O
a O
/ O
lscriptof O
completing O
the O
data O
for O
language O
/lscript O
. O

Within O
each O
summand O
, O
the O
product O
of O
factors O
3 O
and O
4 O
is O
the O
probability O
of O
the O
completed O
data O
, O
i.e. O
, O
the O
joint O
probability O
of O
generating O
the O
inventory O
¯V(a O
/ O
lscript)of O
phones O
used O
in O
the O
labeling O
and O
their O
associated O
pronunciations O
. O

Factor O
3 O
considers O
the O
prior O
probability O
of O
¯V(a O
/ O
lscript)under O
the O
DPP B-MethodName
, O
and O
factor O
4 O
is O
a O
likelihood O
term O
that O
considers O
the O
probability O
of O
the O
associated O
pronunciations O
. O

with O
inverse O
temperature O
parameter O
ρ O
. O

In O
our O
setting O
, O
f O
, O
f O
/ O
primewill O
both O
be O
Gaussian O
dis- O
tributions O
with O
means O
µandµ/primethat O
share O
a O
ﬁxed O
spherical O
covariance O
matrix O
σ2I. O

Then O
eq O
. O

( O
3 O
) O
and O
indeed O
its O
generalization O
to O
any O
Rdhas O
a O
closed- O
form O
solution O
( O
Jebara O
et O
al O
. O
, O
2004 O
, O
§ O
3.1 O
): O
K(f O
, O
f O
/ O
prime;ρ O
) O
= O
( O
4 O
) O
( O
2ρ)d O
2 O
/ O
parenleftbig O
2πσ2 O
/ O
parenrightbig(1−2ρ)d O
2exp O
/ O
parenleftbigg O
−ρ||µ−µ/prime||2 O
4σ2 O
/ O
parenrightbigg O
. O

Notice O
that O
making O
ρsmall O
( O
i.e. O
, O
high O
temperature O
) O
has O
an O
effect O
on O
( O
4)similar O
to O
scaling O
the O
variance O
σ2by O
the O
temperature O
, O
but O
it O
also O
results O
in O
chang- O
ing O
the O
scale O
ofK O
, O
which O
affects O
the O
balance O
be- O
tween O
dispersion O
and O
focalization O
in O
( O
6 O
) O
below O
. O

5.2 O
Focalization O
Score O
The O
probability O
kernel O
given O
in O
eq O
. O

( O
3 O
) O
naturally O
handles O
the O
linguistic O
notion O
of O
dispersion O
. O

What O
about O
focalization O
? O

We O
say O
that O
a O
phone O
is O
focal O
to O
the O
extent O
that O
it O
has O
a O
high O
score O
F(µ O
) O
= O
exp O
( O
U2tanh(U1µ+b1 O
) O
+ O
b2)>0 O
( O
5 O
) O
where O
µis O
the O
mean O
of O
its O
density O
. O

To O
learn O
the O
parameters O
of O
this O
neural O
network O
from O
data O
is O
to O
learn O
which O
phones O
are O
focal O
. O

We O
use O
a O
neural O
net- O
work O
since O
the O
focal O
regions O
of O
R2are O
distributed O
in O
a O
complex O
way O
. O

5.3 O
TheLMatrix O
Iffi O
= O
N(µi O
, O
σ2I)is O
the O
density O
associated O
with O
the O
phone O
¯vi O
, O
we O
may O
populate O
an O
N×NrealAlgorithm O
1 O
Generative O
Process O
1 O
: O
N∼Poisson O
( O
λ O
) O
( O
∈N O
) O
1 O
2 O
: O
fori= O
1toN O
: O
3:µi∼N O
( O
0,I O
) O
( O
∈R2 O
) O
2 O
4 O
: O
deﬁneL∈RN×Nvia O
( O
6 O
) O
5 O
: O
for O
/ O
lscript= O
1toM O
: O
6 O
: O
¯V O
/ O
lscript∼DPP(L O
) O
( O
⊆[1,N O
] O
) O
; O
letn O
/ O
lscript=|¯V O
/ O
lscript|3 O
7 O
: O
fori∈¯V O
/ O
lscript O
: O
8 O
: O
˜v O
/ O
lscript O
i∼N O
/ O
parenleftbig O
µi O
, O
σ2I O
/ O
parenrightbig O
4 O
9 O
: O
v O
/ O
lscript O
i O
= O
νθ O
/ O
parenleftbig˜v O
/ O
lscript O
i O
/ O
parenrightbig O
4 O
matrixLwhere O
Lij=/braceleftBigg O
K(fi O
, O
fj;ρ O
) O
ifi O
/ O
negationslash O
= O
j O
K(fi O
, O
fj;ρ O
) O

+ O
F(µi)ifi O
= O
j(6 O
) O
SinceLis O
the O
sum O
of O
two O
positive O
deﬁnite O
ma- O
trices O
( O
the O
ﬁrst O
specializes O
a O
known O
kernel O
and O
the O
second O
is O
diagonal O
and O
positive O
) O
, O
it O
is O
also O
positive O
deﬁnite O
. O

As O
a O
result O
, O
it O
can O
be O
used O
to O
parameterize O
a O
DPP B-MethodName
over O
¯V. O
Indeed O
, O
since O
Lis O
positive O
deﬁnite O
and O
not O
merely O
positive O
semideﬁnite O
, O
it O
will O
assign O
positive O
probability O
to O
anysubset O
of O
¯V. O
As O
previously O
noted O
, O
this O
DPP B-MethodName
does O
not O
deﬁne O
a O
distribution O
over O
an O
inﬁnite O
set O
, O
e.g. O
, O
the O
pow- O
erset O
of O
R2 O
, O
as O
does O
recent O
work O
on O
continuous O
DPPs O
( O
Affandi O
et O
al O
. O
, O
2013 O
) O
. O

Rather O
, O
it O
deﬁnes O
a O
distribution O
over O
the O
powerset O
of O
a O
set O
of O
densities O
with O
ﬁnite O
cardinality O
. O

Once O
we O
have O
sampled O
a O
subset O
of O
densities O
, O
a O
real O
- O
valued O
quantity O
may O
be O
additionally O
sampled O
from O
each O
sampled O
density O
. O

6 O
A O
Deep O
Generative B-MethodName
Model I-MethodName
We O
are O
now O
in O
a O
position O
to O
expound O
our O
generative B-MethodName
model I-MethodName
of O
continuous O
- O
space O
vowel O
typology O
. O

We40 O

generate O
a O
set O
of O
formant O
pairs O
for O
Mlanguages O
in O
a O
four O
step O
process O
. O

Note O
that O
throughout O
this O
exposition O
, O
language O
- O
speciﬁc O
quantities O
with O
be O
superscripted O
with O
an O
integral O
language O
marker O
/lscript O
, O
whereas O
universal O
quantities O
are O
left O
unsuper- O
scripted O
. O

The O
generative O
process O
is O
written O
in O
al- O
gorithmic O
form O
in O
Alg O
. O

1 O
. O
Note O
that O
each O
step O
is O
numbered O
and O
color O
- O
coded O
for O
ease O
of O
comparison O
with O
the O
full O
joint O
likelihood O
in O
Fig O
. O

2 O
. O
Step O
1 O
: O
p(N).We O
sample O
the O
size O
Nof O
the O
uni- O
versal O
phone O
inventory O
¯Vfrom O
a O
Poisson O
distribu- O
tion O
with O
a O
rate O
parameter O
λ O
, O
i.e. O
, O
N∼Poisson O
( O
λ O
) O
. O

( O
7 O
) O
That O
is O
, O
we O
do O
not O
presuppose O
a O
certain O
number O
of O
phones O
in O
the O
model O
. O

Step O
2 O
: O
p(µ1, O
... O
,µN).Next O
, O
we O
sample O
the O
means O
µiof O
the O
Gaussian O
phones O
. O

In O
the O
model O
presented O
here O
, O
we O
assume O
that O
each O
phone O
is O
generated O
independently O
, O
so O
p(µ1, O
... O
,µN O
) O

= O
/producttextN O
i=1p(µi O
) O
. O

Also O
, O
we O
assume O
a O
standard O
Gaussian O
prior O
over O
the O
means O
, O
µi∼N(0,I O
) O
. O

The O
sampled O
means O
deﬁne O
our O
NGaussian O
phonesN O
/ O
parenleftbig O
µi O
, O
σ2I O
/ O
parenrightbig O
: O
we O
are O
assuming O
for O
simplic- O
ity O
that O
all O
phones O
share O
a O
single O
spherical O
covari- O
ance O
matrix O
, O
deﬁned O
by O
the O
hyperparameter O
σ2 O
. O

The O
dispersion O
and O
focalization O
of O
these O
phones O
deﬁne O
the O
matrix O
Laccording O
to O
equations O
( O
4)–(6 O
) O
, O
whereρin(4)and O

the O
weights O
of O
the O
focalization O
neural O
net O
( O
5 O
) O
are O
also O
hyperparameters O
. O

Step O
3 O
: O
p(¯V O
/ O
lscript|µ1, O
... O
,µN).Next O
, O
for O
each O
lan- O
guage O
/ O
lscript∈[1, O
... O
,M O
] O
, O
we O
sample O
a O
diverse O
subset O
of O
theNphones O
, O
via O
a O
single O
draw O
from O
a O
DPP B-MethodName
parameterized O
by O
matrix O
L O
: O
¯V O
/ O
lscript∼DPP(L O
) O
, O
( O
8) O
where O
¯V O
/ O
lscript⊆[1,N O
] O
. O

Thus O
, O
i∈¯V O
/ O
lscriptmeans O
that O
language O
/ O
lscriptcontains O
phone O
¯vi O
. O
Note O
that O
even O
the O
size O
of O
the O
inventory O
, O
n O
/ O
lscript=|¯V O
/ O
lscript| O
, O
was O
chosen O
by O
the O
DPP B-MethodName
. O

In O
general O
, O
we O
have O
n O
/ O
lscript O
/ O
lessmuchN. O
Step O
4:/producttext O
i∈¯V O
/ O
lscriptp(v O
/ O
lscript O

i|µi)The O
ﬁnal O
step O
in O
our O
generative O
process O
is O
that O
the O
phones O
¯viin O
language O
/lscriptmust O
generate O
the O
pronunciations O
v O
/ O
lscript O
i∈R2(for- O
mant O
vectors O
) O
that O
are O
actually O
observed O
in O
lan- O
guage O
/ O
lscript O
. O

Each O
vector O
takes O
two O
steps O
. O

For O
each O
i∈¯V O
/ O
lscript O
, O
we O
generate O
an O
underlying O
˜vi∈R2from O
the O
corresponding O
Gaussian O
phone O
. O

Then O
, O
we O
runthis O
vector O
through O
a O
feed O
- O
forward O
neural O
network O
νθwith O
parameters O
θ O
. O

In O
short O
: O
˜v O
/ O
lscript O
i∼N(µi O
, O
σ2I O
) O
( O
9 O
) O
v O
/ O
lscript O
i O
= O
νθ(˜v O
/ O
lscript O
i O
) O
, O
( O
10 O
) O
where O
the O
second O
step O
is O
deterministic O
. O

We O
can O
fuse O
these O
two O
steps O
into O
a O
single O
step O
p(vi|µi O
) O
, O
whose O
closed O
- O
form O
density O
is O
given O
in O
eq O
. O

( O
12 O
) O
be- O
low O
. O

In O
effect O
, O
step O
4 O
takes O
a O
Gaussian O
phone O
as O
input O
and O
produces O
the O
observed O
formant O
vector O
with O
an O
underlying O
formant O
vector O
in O
the O
middle O
. O

This O
completes O
our O
generative O
process O
. O

We O
do O
not O
observe O
all O
the O
steps O
, O
but O
only O
the O
ﬁnal O
col- O
lection O
of O
pronunciations O
v O
/ O
lscript O
ifor O
each O
language O
, O
where O
the O
subscripts O
ithat O
indicate O
phone O
identity O
have O
been O
lost O
. O

The O
probability O
of O
this O
incomplete O
dataset O
involves O
summing O
over O
possible O
phones O
for O
each O
pronunciation O
, O
and O
is O
presented O
in O
Fig O
. O

2 O
. O
6.1 O

A O
Neural O
Transformation O
of O
a O
Gaussian O
A O
crucial O
bit O
of O
our O
model O
is O
running O
a O
sample O
from O
a O
Gaussian O
through O
a O
neural O
network O
. O

Under O
certain O
restrictions O
, O
we O
can O
ﬁnd O
a O
closed O
form O
for O
the O
resulting O
density O
; O
we O
discuss O
these O
below O
. O

Let O
νθbe O
a O
depth-2 B-HyperparameterName
multi I-HyperparameterName
- I-HyperparameterName
layer I-HyperparameterName
perceptron O
νθ(˜ O
vi O
) O

= O
W2tanh O
( O
W1˜ O
vi+b1 O
) O
+ O
b2.(11 O
) O

In O
order O
to O
ﬁnd O
a O
closed O
- O
form O
solution O
, O
we O
require O
that O
( O
5)be O
a O
diffeomorphism O
, O
i.e. O
, O
an O
invertible O
mapping O
from O
R2→R2where O
both O
νθand O
its O
inverseν−1 O
θare O
differentiable O
. O

This O
will O
be O
true O
as O
long O
asW1,W2∈R2×2are O
square O
matrices O
of O
full- O
rank O
and O
we O
choose O
a O
smooth O
, O
invertible O
activation O
function O
, O
such O
as O
tanh B-MethodName
. O

Under O
those O
conditions O
, O
we O
may O
apply O
the O
standard O
theorem O
for O
transforming O
a O
random O
variable O
( O
see O
Stark O
and O
Woods O
, O
2011 O
): O
p(vi|µi O
) O

= O
p(ν−1 O
θ(vi)|µi)detJν−1 O
θ(vi O
) O

= O
p(˜vi|µi)detJν−1 O
θ(vi)(12 O
) O

whereJν−1 O
θ(x)is O
the O
Jacobian O
of O
the O
inverse O
of O
the O
neural O
network O
at O
the O
point O
x. O
Recall O
that O
p(˜vi|µi O
) O
is O
Gaussian O
- O
distributed O
. O

7 O
Modeling O
Assumptions O
Imbued O
in O
our O
generative O
story O
are O
a O
number O
of O
assumptions O
about O
the O
linguistic O
processes O
behind O
vowel O
inventories O
. O

We O
brieﬂy O
draw O
connections O
between O
our O
theory O
and O
the O
linguistics O
literature.41 O

Why O
underlying O
phones O
? O

A O
technical O
assump- O
tion O
of O
our O
model O
is O
the O
existence O
of O
a O
universal O
set O
of O
underlying O
phones O
. O

Each O
phone O
is O
equipped O
with O
a O
probability O
distribution O
over O
reported O
acous- O
tic O
measurements O
( O
pronunciations O
) O
, O
to O
allow O
for O
a O
single O
phone O
to O
account O
for O
multiple O
slightly O
differ- O
ent O
pronunciations O
in O
different O
languages O
( O
though O
never O
in O
the O
same O
language O
) O
. O

This O
distribution O
can O
capture O
both O
actual O
interlingual O
variation O
and O
also O
random O
noise O
in O
the O
measurement O
process O
. O

While O
our O
universal O
phones O
may O
seem O
to O
re- O
semble O
the O
universal O
IPA O
symbols O
used O
in O
phono- O
logical O
transcription O
, O
they O
lack O
the O
rich O
featural O
speciﬁcations O
of O
such O
phonemes O
. O

A O
phone O
in O
our O
model O
has O
no O
features O
other O
than O
its O
mean O
position O
, O
which O
wholly O
determines O
its O
behavior O
. O

Our O
univer- O
sal O
phones O
are O
not O
a O
substantive O
linguistic O
hypothe- O
sis O
, O
but O
are O
essentially O
just O
a O
way O
of O
partitioning O
R2 O
into O
ﬁnitely O
many O
small O
regions O
whose O
similarity O
and O
focalization O
can O
be O
precomputed O
. O

This O
techni- O
cal O
trick O
allows O
us O
to O
use O
a O
discrete O
rather O
than O
a O
continuous O
DPP B-MethodName
over O
the O
R2space.1 O
Why O
a O
neural O
network O
? O

Our O
phones O
are O
Gaus- O
sians O
of O
spherical O
variance O
σ2 O
, O
presumed O
to O
be O
scat- O
tered O
with O
variance O
1 O
about O
a O
two O
- O
dimensional O
la- O
tentvowel O
space O
. O

Distances O
in O
this O
latent O
space O
are O
used O
to O
compute O
the O
dissimilarity O
of O
phones O
for O
modeling O
dispersion O
, O
and O
also O
to O
describe O
the O
phone O
’s O
ability O
to O
vary O
across O
languages O
. O

That O
is O
, O
two O
phones O
that O
are O
distant O
in O
the O
latent O
space O
can O
appear O
in O
the O
same O
inventory O
— O
presumably O
they O
are O
easy O
to O
discriminate O
in O
both O
perception O
and O
articulation O
— O
and O
it O
is O
easy O
to O
choose O
which O
one O
better O
explains O
an O
acoustic O
measurement O
, O
thereby O
affecting O
the O
other O
measurements O
that O
may O
appear O
in O
the O
inventory O
. O

We O
relate O
this O
latent O
space O
to O
measurable O
acous- O
tic O
space O
by O
a O
learned O
diffeomorphism O
νθ(Cotterell O
and O
Eisner O
, O
2017 O
) O
. O

ν−1 O
θcan O
be O
regarded O
as O
warping O
the O
acoustic O
distances O
into O
perceptual O
/ O
articulatory O
distances O
. O

In O
some O
“ O
high O
- O
resolution O
” O
regions O
of O
acoustic O
space O
, O
phones O
with O
fairly O
similar O
( O
F1,F2 O
) O
values O
might O
yet O
be O
far O
apart O
in O
the O
latent O
space O
. O

Conversely O
, O
in O
other O
regions O
, O
relatively O
large O
acous- O
1Indeed O
, O
we O
could O
have O
simply O
taken O
our O
universal O
phone O
set O
to O
be O
a O
huge O
set O
of O
tiny O
, O
regularly O
spaced O
overlapping O
Gaus- O
sians O
that O
“ O
covered O
” O
( O
say O
) O
the O
unit O
circle O
. O

As O
a O
computational O
matter O
, O
we O
instead O
opted O
to O
use O
a O
smaller O
set O
of O
Gaussians O
, O
giving O
the O
learner O
the O
freedom O
to O
infer O
their O
positions O
and O
tune O
their O
variance O
σ2 O
. O

Because O
of O
this O
freedom O
, O
this O
set O
should O
not O
be O
too O
large O
, O
or O
a O
MAP O
learner O
may O
overﬁt O
the O
training O
data O
with O
zero O
- O
variance O
Gaussians O
and O
be O
unable O
to O
explain O
the O
test O
languages O
— O
similar O
to O
overﬁtting O
a O
Gaussian O
mixture O
model.tic O
changes O
in O
some O
direction O
might O
not O
prevent O
two O
phones O
from O
acting O
as O
similar O
or O
two O
pronunci- O
ations O
from O
being O
attributed O
to O
the O
same O
phone O
. O

In O
general O
, O
a O
unit O
circle O
of O
radius O
σin O
latent O
space O
may O
be O
mapped O
by O
νθto O
an O
oddly O
shaped O
connected O
re- O
gion O
in O
acoustic O
space O
, O
and O
a O
Gaussian O
in O
latent O
space O
may O
be O
mapped O
to O
a O
multimodal O
distribution O
. O

8 O
Inference O
and O
Learning O
We O
ﬁt O
our O
model O
via O
MAP B-MethodName
- I-MethodName
EM I-MethodName
( O
Dempster O
et O
al O
. O
, O
1977 O
) O
. O

The O
E O
- O
step O
involves O
deciding O
which O
phones O
each O
language O
has O
. O

To O
achieve O
this O
, O
we O
fashion O
a O
Gibbs O
sampler O
( O
Geman O
and O
Geman O
, O
1984 O
) O
, O
yielding O
a O
Markov O
- O
Chain O
Monte O
Carlo O
E O
- O
step O
( O
Levine O
and O
Casella O
, O
2001 O
) O
. O

8.1 O
Inference O
: O
MCMC B-MethodName
E I-MethodName
- I-MethodName
Step I-MethodName
Inference O
in O
our O
model O
is O
intractable O
even O
when O
the O
phones O
µ1, O
... O
,µNare O
ﬁxed O
. O

Given O
a O
language O
withnvowels O
, O
we O
have O
to O
determine O
which O
subset O
of O
theNphones O
best O
explains O
those O
vowels O
. O

As O
discussed O
above O
, O
the O
alignment O
abetween O
the O
n O
vowels O
andnof O
theNphones O
represents O
a O
latent O
variable O
. O

Marginalizing O
it O
out O
is O
# O
P O
- O
hard O
, O
as O
we O
can O
see O
that O
it O
is O
equivalent O
to O
summing O
over O
all O
bipartite O
matchings O
in O
a O
weighted O
graph O
, O
which O
, O
in O
turn O
, O
is O
as O
costly O
as O
computing O
the O
permanent O
of O
a O
matrix O
( O
Valiant O
, O
1979 O
) O
. O

Our O
sampler2is O
an O
approxi- O
mation O
algorithm O
for O
the O
task O
. O

We O
are O
interested O
in O
sampling O
a O
, O
the O
labeling O
of O
observed O
vowels O
with O
universal O
phones O
. O

Note O
that O
this O
implicitly O
sam- O
ples O
the O
language O
’s O
phone O
inventory O
¯V(a O
) O
, O
which O
is O
fully O
determined O
by O
a. O
Speciﬁcally O
, O
we O
employ O
an O
MCMC B-MethodName
method O
closely O
related O
to O
Gibbs O
sampling O
. O

At O
each O
step O
of O
the O
sampler O
, O
we O
update O
our O
vowel O
- O
phone O
align- O
menta O
/ O
lscriptas O
follows O
. O

Choose O
a O
language O
/lscriptand O
a O
vowel O
index O
k∈[1,n O
/ O
lscript O
] O
, O
and O
leti O
= O
a O
/ O
lscript O
k(that O
is O
, O
pronunciation O
v O
/ O
lscript O
, O
kis O
currently O
labeled O
with O
univer- O
sal O
phone O
¯vi O
) O
. O

We O
will O
consider O
changing O
a O
/ O
lscript O
ktoj O
, O
wherejis O
drawn O
from O
the O
( O
N−n O
/ O
lscript)phones O
that O
donotappear O
in O
¯V(a O
/ O
lscript O
) O
, O
heuristically O
choosing O
jin O
proportion O
to O
the O
likelihood O
p(v O
/ O
lscript O
, O
k|µj O
) O
. O

We O
then O
stochastically O
decide O
whether O
to O
keep O
a O
/ O
lscript O
k O
= O
ior O
set O
a O
/ O
lscript O
k O
= O
jin O
proportion O
to O
the O
resulting O
values O
of O
the O
product O
4·3 O
in O
eq O
. O

( O
2 O
) O
. O

For O
a O
single O
E O
- O
step O
, O
the O
Gibbs O
sampler O
“ O
warm- O
starts O
” O
with O
the O
labeling O
from O
the O
end O
of O
the O
pre- O
vious O
iteration O
’s O
E O
- O
step O
. O

It O
sweeps O
S= B-HyperparameterName
5 B-HyperparameterValue
times O
2Taken O
from O
V O
olkovs O
and O
Zemel O
( O
2012 O
, O
3.1).42 O

through O
all O
vowels O
for O
all O
languages O
, O
and O
returns O
S O
sampled O
labelings O
, O
one O
from O
the O
end O
of O
each O
sweep O
. O

We O
are O
also O
interested O
in O
automatically O
choosing O
the O
number O
of O
phones O
N O
, O
for O
which O
we O
take O
the O
Poisson O
’s O
rate O
parameter O
λ= B-HyperparameterName
100 B-HyperparameterValue
. O

To O
this O
end O
, O
we O
employ O
reversible O
- O
jump O
MCMC B-MethodName
( O
Green O
, O
1995 O
) O
, O
resamplingNat O
the O
start O
of O
every O
E O
- O
step O
. O

8.2 O
Learning O
: O
M O
- O
Step O
Given O
the O
set O
of O
sampled O
alignments O
provided O
by O
the O
E O
- O
step O
, O
our O
M O
- O
step O
consists O
of O
optimizing O
the O
log O
- O
likelihood O
of O
the O
now O
- O
complete O
training O
data O
using O
the O
inferred O
latent O
variables O
. O

We O
achieved O
this O
through O
SGD B-MethodName
training O
of O
the O
diffeomorphism O
parameters O
θ O
, O
the O
means O
µiof O
the O
Gaussian O
phones O
, O
and O
the O
parameters O
of O
the O
focalization O
kernel O
F. O
9 O
Experiments O
9.1 O
Data O
Our O
data O
is O
taken O
from O
the O
Becker O
- O
Kristal O
corpus O
( O
Becker O
- O
Kristal O
, O
2006 O
) O
, O
which O
is O
a O
compilation O
of O
various O
phonetic O
studies O
and O
forms O
the O
largest O
multi- O
lingual O
phonetic O
database O
. O

Each O
entry O
in O
the O
corpus O
corresponds O
to O
a O
linguist O
’s O
phonetic O
description O
of O
a O
language O
’s O
vowel O
system O
: O
an O
inventory O
consist- O
ing O
of O
IPA O
symbols O
where O
each O
symbol O
is O
associ- O
ated O
with O
two O
or O
more O
formant O
values O
. O

The O
corpus O
contains O
data O
from O
233 O
distinct O
languages O
. O

When O
multiple O
inventories O
were O
available O
for O
the O
same O
language O
( O
due O
to O
various O
studies O
in O
the O
literature O
) O
, O
we O
selected O
one O
at O
random O
and O
discarded O
the O
others O
. O

9.2 O
Baselines O
Baseline O
# O
1 O
: O
Removing O
dispersion O
. O

The O
key O
technical O
innovation O
in O
our O
work O
lies O
in O
the O
incor- O
poration O
of O
a O
DPP B-MethodName
into O
a O
generative B-MethodName
model I-MethodName
of O
vowel O
formants O
— O
a O
continuous O
- O
valued O
quantity O
. O

The O
role O
of O
the O
DPP B-MethodName
was O
to O
model O
the O
linguistic O
principle O
of O
dispersion O
— O
we O
may O
cripple O
this O
portion O
of O
our O
model O
, O
e.g. O
, O
by O
forcing O
Kto O
be O
a O
diagonal O
kernel O
, O
i.e. O
,Kij= O
0 O
fori O
/ O
negationslash O
= O
j. O

In O
this O
case O
the O
DPP B-MethodName
becomes O
a O
Bernoulli O
Point O
Process O
( O
BPP)—a O
spe- O
cial O
case O
of O
the O
DPP B-MethodName
. O

Since O
dispersion O
is O
widely O
accepted O
to O
be O
an O
important O
principle O
governing O
naturally O
occurring O
vowel O
systems O
, O
we O
expect O
a O
system O
trained O
without O
such O
knowledge O
to O
perform O
worse O
. O

Baseline O
# O
2 O
: O
Removing B-TaskName
the I-TaskName
neural I-TaskName
network I-TaskName
νθ O
. O

Another O
question O
we O
may O
ask O
of O
our O
formulation O
is O
whether O
we O
actually O
need O
a O
fancy O
neural O
mapping O
νθto O
model O
our O
typological O
data O
well O
. O

The O
humanperceptual O
system O
is O
known O
to O
perform O
a O
non O
- O
linear O
transformation O
on O
acoustic O
signals O
, O
starting O
with O
the O
non O
- O
linear O
cochlear O
transform O
that O
is O
physically O
performed O
in O
the O
ear O
. O

While O
ν−1 O
θis O
intended O
as O
loosely O
analogous O
, O
we O
determine O
its O
beneﬁt O
by O
re- O
moving O
eq O
. O

( O
10 O
) O
from O
our O
generative O
story O
, O
i.e. O
, O
we O
take O
the O
observed O
formants O
vkto O
arise O
directly O
from O
the O
Gaussian O
phones O
. O

Baseline O
# O
3 O
: O
Supervised O
phones O
and O
alignments O
. O

A O
ﬁnal O
baseline O
we O
consider O
is O
supervised O
phones O
. O

Linguists O
standardly O
employ O
a O
ﬁnite O
set O
of O
phones O
— O
symbols O
from O
the O
international O
phonetic O
alphabet O
( O
IPA O
) O
. O

In O
phonetic O
annotation O
, O
it O
is O
common O
to O
map O
each O
sound O
in O
a O
language O
back O
to O
this O
universal O
dis- O
crete O
alphabet O
. O

Under O
such O
an O
annotation O
scheme O
, O
it O
is O
easy O
to O
discern O
, O
cross O
- O
linguistically O
, O
which O
vow- O
els O
originate O
from O
the O
same O
phoneme O
: O
an O
/ O
I/ O
in O
German O
may O
be O
roughly O
equated O
with O
an O
/ O
I/ O
in O
En- O
glish O
. O

However O
, O
it O
is O
not O
clear O
how O
consistent O
this O
annotation O
truly O
is O
. O

There O
are O
several O
reasons O
to O
expect O
high O
- O
variance O
in O
the O
cross O
- O
linguistic O
acous- O
tic O
signal O
. O

First O
, O
IPA O
symbols O
are O
primarily O
useful O
for O
interlinked O
phonological O
distinctions O
, O
i.e. O
, O
one O
applies O
the O
symbol O
/ O
I/ O
to O
distinguish O
it O
from O
/i/ O
in O
the O
given O
language O
, O
rather O
than O
to O
associate O
it O
with O
the O
sound O
bearing O
the O
same O
symbol O
in O
a O
second O
language O
. O

Second O
, O
ﬁeld O
linguists O
often O
resort O
to O
the O
closest O
common O
IPA O
symbol O
, O
rather O
than O
an O
exact O
match O
: O
if O
a O
language O
makes O
no O
distinction O
between O
/i/ O
and O
/ O
I/ O
, O
it O
is O
more O
common O
to O
denote O
the O
sound O
with O
a O
/i/. O

Thus O
, O
IPA O
may O
not O
be O
as O
universal O
as O
hoped O
. O

Our O
dataset O
contains O
50 O
IPA O
symbols O
so O
this O
baseline O
is O
only O
reported O
for O
N= B-HyperparameterName
50 B-HyperparameterValue
. O

9.3 O
Evaluation O
Evaluation O
in O
our O
setting O
is O
tricky O
. O

The O
scientiﬁc O
goal O
of O
our O
work O
is O
to O
place O
a O
bit O
of O
linguistic O
the- O
ory O
on O
a O
ﬁrm O
probabilistic O
footing O
, O
rather O
than O
a O
downstream O
engineering O
- O
task O
, O
whose O
performance O
we O
could O
measure O
. O

We O
consider O
three O
metrics O
. O

Cross O
- O
Entropy O
. O

Our O
ﬁrst O
evaluation O
metric O
is O
cross O
- O
entropy O
: O
the O
average O
negative O
log O
- O
probability O
of O
the O
vowel O
systems O
in O
held O
- O
out O
test O
data O
, O
given O
the O
universal O
inventory O
of O
Nphones O
that O
we O
trained O
through O
EM O
. O

We O
ﬁnd O
this O
to O
be O
the O
cleanest O
method O
for O
scientiﬁc O
evaluation O
— O
it O
is O
the O
metric O
of O
opti- O
mization O
and O
has O
a O
clear O
interpretation O
: O
how O
sur- O
prised O
was O
the O
model O
to O
see O
the O
vowel O
systems O
of O
held O
- O
out O
, O
but O
attested O
, O
languages O
? O

The O
cross O
- O
entropy O
is O
the O
negative O
log O
of O
the O
/ O
producttext O
/ O
bracketleftbig O
· O
· O
· O
/bracketrightbig O
expression O
in O
eq O
. O

( O
2 O
) O
, O
with O
/lscriptnow O
rang-43 O

N O
metric O
DPP B-MethodName
+ O
νθBPP+νθDPP−νθSup O
. O

Cross B-MetricName
- I-MetricName
entropy I-MetricName
in O
nats O
per O
language O
( O
lower O
is O
better O
) O
and O
expected O
Euclidean O
- O
distance O
error O
of O
the O
cloze O
prediction O
( O
lower O
is O
better O
) O
. O

The O
overall O
best O
value O
for O
each O
task O
is O
bold- O
faced O
. O

The O
case O
N= B-HyperparameterName
50 B-HyperparameterValue
is O
compared O
against O
our O
supervised O
baseline O
. O

The O
N= B-HyperparameterName
57 B-HyperparameterValue
row O
is O
the O
case O
where O
we O
allowed O
N O
to O
ﬂuctuate O
during O
inference O
using O
reversible O
- O
jump O
MCMC B-MethodName
; O
this O
was O
theNvalue O
selected O
at O
the O
ﬁnal O
EM O
iteration O
. O

ing O
over O
held O
- O
out O
languages.3Wallach O
et O
al O
. O

( O
2009 O
) O
give O
several O
methods O
for O
estimating O
the O
intractable O
sum O
in O
language O
/lscript O
. O

We O
use O
the O
simple O
harmonic O
mean O
estimator O
, O
based O
on O
50 O
samples O
of O
a O
/ O
lscriptdrawn O
with O
our O
Gibbs O
sampler O
( O
warm O
- O
started O
from O
the O
ﬁnal O
E O
- O
step O
of O
training O
) O
. O

Cloze O
Evaluation O
. O

In O
addition O
, O
following O
Cot- O
terell O
and O
Eisner O
( O
2017 O
) O
, O
we O
evaluate O
our O
trained O
model O
’s O
ability O
to O
perform O
a O
cloze O
task O
( O
Taylor O
, O
1953 O
) O
. O

Given O
n O
/ O
lscript−1orn O
/ O
lscript−2of O
the O
vowels O
in O
held- O
out O
language O
/lscript O
, O
can O
we O
predict O
the O
pronunciations O
vkof O
the O
remaining O
1 O
or O
2 O
? O

We O
predict O
vkto O
be O
νθ(µi)wherei O
= O
a O
/ O
lscript O
kis O
the O
phone O
inferred O
by O
the O
sampler O
. O

Note O
that O
the O
sampler O
’s O
inference O
here O
is O
based O
only O
on O
the O
observed O
vowels O
( O
the O
likelihood O
) O
and O
the O
focalization O
- O
dispersion O
preferences O
of O
the O
DPP B-MethodName
( O
the O
prior O
) O
. O

We O
report O
the O
expected O
error O
of O
such O
a O
prediction O
— O
where O
error O
is O
quantiﬁed O
by O
Eu- O
clidean O
distance O
in O
( O
F1,F2)formant O
space O
— O
over O
the O
same O
50 O
samples O
of O
a O
/ O
lscript O
. O

For O
instance O
, O
consider O
a O
previously O
unseen O
vowel O
system O
with O
formant O
values O
{ O
( O
499,2199 O
) O
, O
( O
861,1420 O
) O
, O
( O
571,1079 O
) O
} O
. O

A O
“ O
cloze1 O
” O
evaluation O
would O
aim O
to O
predict O
{ O
( O
499,2199)}as O
the O
missing O
3Since O
that O
expression O
is O
the O
product O
of O
both O
probability O
distributions O
and O
probability O
densities O
, O
our O
“ O
cross O
- O
entropy O
” O
metric O
is O
actually O
the O
sum O
of O
both O
entropy O
terms O
and O
( O
poten- O
tially O
negative O
) O
differential O
entropy O
terms O
. O

Thus O
, O
a O
value O
of O
0 O
has O
no O
special O
signiﬁcance O
. O

A O
graph O
of O
v= O
( O
F1,F2)in O
the O
union O
of O
all O
the O
training O
languages O
’ O
inventories O
, O
color O
- O
coded O
by O
inferred O
phone O
( O
N= B-HyperparameterName
50 B-HyperparameterValue
) O
. O

vowel O
, O
given{(861,1420 O
) O
, O
( O
571,1079 O
) O
} O
, O
and O
the O
fact O
thatn O
/ O
lscript= O
3 O
. O

A O
“ O
cloze12 O
” O
evaluation O
would O
aim O
to O
predict O
two O
missing O
vowels O
. O

9.4 O
Experimental O
Details O
Here O
, O
we O
report O
experimental O
details O
and O
the O
hy- O
perparameters O
that O
we O
use O
to O
achieve O
the O
results O
reported O
. O

We O
consider O
a O
neural O
network O
νθwith O
k∈[1,4]layers O
and O
ﬁnd O
k= O
1 O
the O
best O
per- O
former O
on O
development O
data O
. O

Recall O
that O
our O
dif- O
feomorphism O
constraint O
requires O
that O
each B-HyperparameterName
layer I-HyperparameterName
have O
exactly O
two B-HyperparameterValue
hidden I-HyperparameterValue
units I-HyperparameterValue
, O
the O
same O
as O
the O
number O
of O
observed O
formants O
. O

We O
consider O
N∈ O
{ O
15,25,50,100}phones O
as O
well O
as O
letting O
Nﬂuc- O
tuate O
with O
reversible O
- O
jump O
MCMC B-MethodName
( O
see O
footnote O
1 O
) O
. O

We O
train O
for O
100 B-HyperparameterName
iterations I-HyperparameterName
of O
EM O
, O
taking O
S= O
5 O
samples O
at O
each O
E O
- O
step O
. O

At O
each O
M O
- O
step O
, O
we O
run O
50 B-HyperparameterName
iterations I-HyperparameterName
of O
SGD B-MethodName
for O
the O
focalization O
NN O
and O
also O
for O
the O
diffeomorphism O
NN O
. O

For O
each O
N O
, O
we O
selected O
( O
σ2,ρ)by O
minimizing O
cross O
- O
entropy O
on O
a O
held O
- O
out O
development O
set O
. O

We O
considered O
( O
σ2,ρ)∈{10k}5 O
k=1×{ρk}5 O
k=1 O
. O

9.5 O
Results O
and O
Error O
Analysis O
We O
report O
results O
in O
Tab O
. O

1 O
. O

We O
ﬁnd O
that O
our O
DPP B-MethodName
model O
improves O
over O
the O
baselines O
. O

The O
results O
support O
two O
claims O
: O
( O
i O
) O
dispersion O
plays O
an O
impor- O
tant O
role O
in O
the O
structure O
of O
vowel O
systems O
and O
( O
ii O
) O
learning O
a O
non O
- O
linear O
transformation O
of O
a O
Gaussian O
improves O
our O
ability O
to O
model O
sets O
of O
formant O
- O
pairs O
. O

Also O
, O
we O
observe O
that O
as O
we O
increase O
the O
number O
of O
phones O
, O
the O
role O
of O
the O
DPP B-MethodName
becomes O
more O
impor- O
tant O
. O

We O
visualize O
a O
sample O
of O
the O
trained O
alignment O
in O
Fig O
. O

3.44 O

Frequency O
Encodes O
Dispersion O
. O

Why O
does O
dis- O
persion O
not O
always O
help O
? O

The O
models O
with O
fewer O
phones O
do O
not O
reap O
the O
beneﬁts O
that O
the O
models O
with O
more O
phones O
do O
. O

The O
reason O
lies O
in O
the O
fact O
that O
the O
most O
common O
vowel O
formants O
are O
already O
dispersed O
. O

This O
indicates O
that O
we O
still O
have O
not O
quite O
modeled O
the O
mechanisms O
that O
select O
for O
good O
vowel O
formants O
, O
despite O
our O
work O
at O
the O
phonetic O
level O
; O
further O
research O
is O
needed O
. O

We O
would O
prefer O
a O
model O
that O
explains O
the O
evolutionary O
motivation O
of O
sound O
systems O
as O
communication O
systems O
. O

Number O
of O
Induced O
Phones O
. O

What O
is O
most O
salient O
in O
the O
number O
of O
induced O
phones O
is O
that O
it O
is O
close O
to O
the O
number O
of O
IPA O
phonemes O
in O
the O
data O
. O

However O
, O
the O
performance O
of O
the O
phoneme- O
supervised O
system O
is O
much O
worse O
, O
indicating O
that O
, O
perhaps O
, O
while O
the O
linguists O
have O
the O
right O
idea O
about O
the O
number O
of O
universal O
symbols O
, O
they O
did O
not O
specify O
the O
correct O
IPA O
symbol O
in O
all O
cases O
. O

Our O
data O
analysis O
indicates O
that O
this O
is O
often O
due O
to O
pragmatic O
concerns O
in O
linguistic O
ﬁeld O
analysis O
. O

For O
example O
, O
even O
if O
/ O
I/ O
is O
the O
proper O
IPA O
symbol O
for O
the O
sound O
, O
if O
there O
is O
no O
other O
sound O
in O
the O
vicinity O
the O
annotator O
may O
prefer O
to O
use O
more O
common O
/i/. O
10 O
Related O
Work O
Most O
closely O
related O
to O
our O
work O
is O
the O
classic O
study O
of O
Liljencrants O
and O
Lindblom O
( O
1972 O
) O
, O
who O
provide O
a O
simulation O
- O
based O
account O
of O
vowel O
systems O
. O

They O
argued O
that O
minima O
of O
a O
certain O
objective O
that O
en- O
codes O
dispersion O
should O
correspond O
to O
canonical O
vowel O
systems O
of O
a O
given O
size O
n. O

Our O
tack O
is O
dif- O
ferent O
in O
that O
we O
construct O
a O
generative B-MethodName
probability I-MethodName
model I-MethodName
, O
whose O
parameters O
we O
learn O
from O
data O
. O

How- O
ever O
, O
the O
essence O
of O
modeling O
is O
the O
same O
in O
that O
we O
explain O
formant O
values O
, O
rather O
than O
discrete O
IPA O
symbols O
. O

By O
extension O
, O
our O
work O
is O
also O
closely O
related O
to O
extensions O
of O
this O
theory O
( O
Schwartz O
et O
al O
. O
, O
1997 O
; O
Roark O
, O
2001 O
) O
that O
focused O
on O
incorporating O
the O
notion O
of O
focalization O
into O
the O
experiments O
. O

Our O
present O
paper O
can O
also O
be O
regarded O
as O
a O
con- O
tinuation O
of O
Cotterell O
and O
Eisner O
( O
2017 O
) O
, O
in O
which O
we O
used O
DPPs O
to O
model O
vowel O
inventories O
as O
sets O
of O
discrete O
IPA O
symbols O
. O

That O
paper O
pretended O
that O
each O
IPA O
symbol O
had O
a O
single O
cross O
- O
linguistic O
( O
F1,F2)pair O
, O
an O
idealization O
that O
we O
remove O
in O
this O
paper O
by O
discarding O
the O
IPA O
symbols O
and O
modeling O
formant O
values O
directly.11 O
Conclusion O
Our O
model O
combines O
existing O
techniques O
of O
proba- O
bilistic O
modeling O
and O
inference O
to O
attempt O
to O
ﬁt O
the O
actual O
distribution O
of O
the O
world O
’s O
vowel O
systems O
. O

We O
presented O
a O
generative B-MethodName
probability I-MethodName
model I-MethodName
of O
sets O
of O
measured O
( O
F1,F2)pairs O
. O

We O
view O
this O
as O
a O
necessary O
step O
in O
the O
development O
of O
generative B-MethodName
probability I-MethodName
model I-MethodName
that O
can O
explain O
the O
distribu- O
tion O
of O
the O
world O
’s O
languages O
. O

Previous O
work O
on O
generating O
vowel O
inventories O
has O
focused O
on O
how O
those O
inventories O
were O
transcribed O
into O
IPA O
by O
ﬁeld O
linguists O
, O
whereas O
we O
focus O
on O
the O
ﬁeld O
linguists O
’ O
acoustic O
measurements O
of O
how O
the O
vowels O
are O
actu- O
ally O
pronounced O
. O

Acknowledgments O
We O
would O
like O
to O
acknowledge O
Tim O
Vieira O
, O
Katha- O
rina O
Kann O
, O
Sebastian O
Mielke O
and O
Chu O
- O
Cheng O
Lin O
for O
reading O
many O
early O
drafts O
. O

The O
ﬁrst O
author O
would O
like O
to O
acknowledge O
an O
NDSEG O
grant O
and O
a O
Facebook O
PhD O
fellowship O
. O

This O
material O
is O
also O
based O
upon O
work O
supported O
by O
the O
National O
Sci- O
ence O
Foundation O
under O
Grant O
No O
. O
1718846 O
to O
the O
last O
author O
. O

References O
Raja O
Haﬁz O
Affandi O
, O
Emily O
Fox O
, O
and O
Ben O
Taskar O
. O

2013 O
. O

Approximate O
inference O
in O
continuous O
determinantal O
processes O
. O

In O
Advances O
in O
Neural O
Information O
Pro- O
cessing O
Systems O
, O
pages O
1430–1438 O
. O

Roy O
Becker B-DatasetName
- I-DatasetName
Kristal I-DatasetName
. O

2006 O
. O

Predicting O
vowel O
inven- O
tories O
: O
The O
dispersion O
- O
focalization O
theory O
revisited O
. O

The O
Journal O
of O
the O
Acoustical O
Society O
of O
America O
, O
120(5):3248–3248 O
. O

Roy O
Becker B-DatasetName 
- I-DatasetName
Kristal I-DatasetName
. O

2010 O
. O

Acoustic O
Typology O
of O
Vowel O
Inventories O
and O
Dispersion O
Theory O
: O
Insights O
from O
a O
Large O
Cross O
- O
Linguistic O
Corpus O
. O

Ph.D. O
thesis O
, O
UCLA O
. O

Paulus O
Petrus O
Gerardus O
Boersma O
et O

al O
. O
2002 O
. O

Praat O
, O
a O
system O
for O
doing O
phonetics O
by O
computer O
. O

Glot O
Inter- O
national O
, O
5 O
. O

Alexei O
Borodin O
and O
Eric O
M. O
Rains O
. O

2005 O
. O

Eynard- O
Mehta O
theorem O
, O
Schur O
process O
, O
and O
their O
Pfafﬁan O
analogs O
. O

Journal O
of O
Statistical O
Physics O
, O
121(3- O
4):291–317 O
. O

Bernard O
Comrie O
, O
Matthew O
S. O
Dryer O
, O
David O
Gil O
, O
and O
Martin O
Haspelmath O
. O

2013 O
. O

Introduction O
. O

In O
Matthew O
S. O
Dryer O
and O
Martin O
Haspelmath O
, O
editors O
, O
The O
World O
Atlas O
of O
Language O
Structures O
Online O
. O

Max O
Planck O
Institute O
for O
Evolutionary O
Anthropol- O
ogy O
, O
Leipzig.45 O

Ryan O
Cotterell O
and O
Jason O
Eisner O
. O

2017 O
. O

Probabilistic O
typology O
: O

Deep O
generative B-MethodName
model I-MethodName
of O
vowel O
inven- O
tories O
. O

In O
Proceedings O
of O
the O
55th O
Annual O
Meet- O
ing O
of O
the O
Association O
for O
Computational O
Linguistics O
( O
ACL O
) O
, O
Vancouver O
, O
Canada O
. O

Arthur O
P. O
Dempster O
, O
Nan O
M. O
Laird O
, O
and O
Donald O
B. O
Ru- O
bin O
. O

1977 O
. O

Maximum O
likelihood O
from O
incomplete O
data O
via O
the O
EM O
algorithm O
. O

Journal O
of O
the O
Royal O
Rta- O
tistical O
Society O
, O
Series O
B O
( O
Statistical O
Methodology O
) O
, O
pages O
1–38 O
. O

Li O
Deng O
and O
Douglas O
O’Shaughnessy O
. O

2003 O
. O

Speech O
Processing O
: O
A O
Dynamic O
and O
Optimization O
- O
Oriented O
Approach O
. O

CRC O
Press O
. O

Stuart O
Geman O
and O
Donald O
Geman O
. O

1984 O
. O

Stochas- O

tic O
relaxation O
, O
Gibbs O
distributions O
, O
and O
the O
Bayesian O
restoration O
of O
images O
. O

IEEE O
Transactions O
on O
Pattern O
Analysis O
and O
Machine O
Intelligence O
, O
( O
6):721–741 O
. O

Matthew O
K. O
Gordon O
. O

2016 O
. O

Phonological O
Typology O
. O

Oxford O
. O

Peter O
J. O
Green O
. O

1995 O
. O

Reversible O
jump O
Markov O
chain O
Monte O
Carlo O
computation O
and O
Bayesian O
model O
de- O
termination O
. O

Biometrika O
, O
82(4):711–732 O
. O

Tony O
Jebara O
, O
Risi O
Kondor O
, O
and O
Andrew O
Howard O
. O

2004 O
. O

Probability O
product O
kernels O
. O

Journal O
of O
Machine O
Learning O
Research O
, O
5:819–844 O
. O

Peter O
Ladefoged O
. O

2001 O
. O

Vowels O
and O
Consonants O
: O
An O
Introduction O
to O
the O
Sounds O
of O
Languages O
. O

Wiley- O
Blackwell O
. O

Richard O
A. O
Levine O
and O
George O
Casella O
. O

2001 O
. O

Im- O
plementations O
of O
the O
Monte O
Carlo O
EM O
algorithm O
. O

Journal O
of O
Computational O
and O
Graphical O
Statistics O
, O
10(3):422–439 O
. O

Johan O
Liljencrants O
and O
Bj O
¨orn O
Lindblom O
. O

1972 O
. O

Numer- O
ical O
simulation O
of O
vowel O
quality O
systems O
: O

The O
role O
of O
perceptual O
contrast O
. O

Language O
, O
pages O
839–862 O
. O

Brian O
Roark O
. O

2001 O
. O

Explaining O
vowel O
inventory O
ten- O
dencies O
via O
simulation O
: O
Finding O
a O
role O
for O
quantal O
locations O
and O
formant O
normalization O
. O

In O
North O
East O
Linguistic O
Society O
, O
volume O
31 O
, O
pages O
419–434 O
. O

Jean O
- O
Luc O
Schwartz O
, O
Christian O
Abry O
, O
Louis O
- O
Jean O
Bo O
¨e O
, O
Nathalie O
Vall O
´ O
ee O
, O
and O
Lucie O
M O
´ O
enard O
. O

2005 O
. O

The O
dispersion O
- O
focalization O
theory O
of O
sound O
systems O
. O

The O
Journal O
of O
the O
Acoustical O
Society O
of O
America O
, O
117(4):2422–2422 O
. O
Jean O
- O
Luc O
Schwartz O
, O
Louis O
- O
Jean O
Bo O
¨e O
, O
Nathalie O
Vall O
´ O
ee O
, O
and O
Christian O
Abry O
. O

1997 O
. O

The O
dispersion- O
focalization O
theory O
of O
vowel O
systems O
. O

Journal O
of O
Phonetics O
, O
25(3):255–286 O
. O

Henry O
Stark O
and O
John O
Woods O
. O

2011 O
. O

Probability O
, O
Statis- O
tics O
, O
and O
Random O
Processes O
for O
Engineers O
. O

Pearson O
. O

Kenneth O
N. O
Stevens O
. O
1987 O
. O

Relational O
properties O
as O
per- O
ceptual O
correlates O
of O
phonetic O
features O
. O

In O
Interna- O
tional O
Conference O
of O
Phonetic O
Sciences O
, O
pages O
352 O
– O
355.Kenneth O
N. O
Stevens O
. O
1989 O
. O

On O
the O
quantal O
nature O
of O
speech O
. O

Journal O
of O
Phonetics O
, O
17:3–45 O
. O

Wilson O
L. O
Taylor O
. O

1953 O
. O

Cloze B-MetricName
procedure O
: O
a O
new O
tool O
for O
measuring O
readability O
. O

Journalism O
and O
Mass O
Communication O
Quarterly O
, O
30(4):415 O
. O

Leslie O
G. O
Valiant O
. O

1979 O
. O

The O
complexity O
of O
comput- O
ing O
the O
permanent O
. O

Theoretical O
Computer O
Science O
, O
8(2):189–201 O
. O

Maksims O
V O
olkovs O
and O
Richard O
S. O
Zemel O
. O

2012 O
. O

Efﬁ- O
cient O
sampling O
for O
bipartite O
matching O
problems O
. O

In O
Advances O
in O
Neural O
Information O
Processing O
Systems O
, O
pages O
1313–1321 O
. O

Hanna O
Wallach O
, O
Ian O
Murray O
, O
Ruslan O
Salakhutdinov O
, O
and O
David O
Mimno O
. O

2009 O
. O

Evaluation O
methods O
for O
topic O
models O
. O

In O
International O
Conference O
on O
Ma- O
chine O
Learning O
( O
ICML O
) O
, O
pages O
1105–1112.46 O