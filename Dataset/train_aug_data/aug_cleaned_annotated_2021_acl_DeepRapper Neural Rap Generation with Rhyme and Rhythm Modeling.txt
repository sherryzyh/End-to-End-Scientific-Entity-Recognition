Neural O
networks O
that O
model O
rhyme O
and O
rhythm O
improve O
the O
performance O
of O
Lanqing O
Xue O
, O
Kaitao O
Song O
, O
Duocai O
Wu O
, O
Xu O
Tan O
, O
Nevin O
L. O
Zhang O
, O
Tao O
Qin O
, O
Wei O
- O
Qiang O
Zhang O
, O
and O
Tie O
- O
Yan O
Liu O
. O

. O


 O
The O
sentence O
is O
saying O
that O
a O
research O
project O
at O
Tsinghua O
University O
is O
looking O
into O
a O
way O
to O
produce O
lyrics O
and O
beats O
for O
singing O
that O
takes O
into O
account O
both O
rhyme O
and O
rhythm O
. O

Previous O
works O
for O
rap B-TaskName
generation I-TaskName
have O
focused O
on O
rhyming O
lyrics O
but O
have O
ignored O
rhythmic O
beats O
, O
which O
are O
important O
for O
rap O
performance O
. O

In O
this O
paper O
, O
we O
develop O
a O
Transformer O
- O
based O
rap O
generation O
system O
called O
DeepRapper B-MethodName
that O
can O
model O
both O
rhymes O
and O
rhythms O
. O

As O
far O
as O
we O
know O
, O
DeepRapper B-MethodName
is O
the O
first O
system O
to O
generate O
rap O
with O
both O
rhymes O
and O
rhythms O
. O

Both O
objective O
and O
subjective O
evaluations O
show O
that O
DeepRapper B-MethodName
creates O
high O
- O
quality O
raps O
with O
creative O
rhymes O
and O
rhythms O
. O

, O
2015 O
) O


 O
The O
rapid O
development O
of O
artificial O
intelligence O
has O
led O
to O
increased O
interest O
in O
automatic O
rap B-TaskName
lyrics I-TaskName
generation I-TaskName
from O
academia O
( O
Potash O
et O
. O
, O
2015 O
) O
. O

Previous O
works O
for O
rap B-TaskName
generation I-TaskName
have O
mainly O
focused O
on O
lyric O
generation O
, O
with O
some O
developing O
strategies O
for O
rhyme O
modeling O
. O

Although O
many O
works O
have O
studied O
rhyming O
modeling O
in O
other O
artistic O
genres O
( O
e.g. O
, O
poetry O
) O
( O
Li O
et O
al O
. O
, O
2020 O
; O
Van O
de O
Cruys O
, O
2020 O
; O
Liu O
et O
al O
. O
, O
2020 O
) O
, O
they O
are O
not O
suitable O
for O
rap B-TaskName
generation I-TaskName
due O
to O
the O
complex O
rhyme O
structure O
in O
rap O
. O

If O
a O
song O
has O
no O
rhythm O
, O
it O
can O
not O
be O
considered O
a O
full O
song O
. O

In O
this O
paper O
, O
we O
develop O
a O
Transformer O
- O
based O
rap O
generation O
system O
called O
DeepRapper B-MethodName
which O
can O
model O
both O
rhymes O
and O
rhythms O
. O

Our O
Deep- B-MethodName
Rapper I-MethodName
model O
is O
pre O
- O
trained O
in O
the O
pre O
- O
training O
stage O
using O
the O
above O
two O
datasets O
. O

The O
model O
is O
fine O
- O
tuned O
for O
the O
final O
rap B-TaskName
generation I-TaskName
. O

Both O
objective O
and O
subjective O
evaluations O
verify O
the O
advantages O
of O
DeepRapper B-MethodName
in O
generating O
rap O
lyrics O
with O
rhymes O
and O
rhythms O
. O

Our O
main O
contributions O
are O
as O
follows O
: O
modeling O
rhythms O
in O
rap B-TaskName
generation I-TaskName
, O
and O
developing O
. O

DeepRapper B-MethodName
is O
the O
first O
that O
we O
know O
of O
to O
explicitly O
model O
N O
- O
gram O
rhymes O
. O

As O
far O
as O
we O
know O
, O
DeepRapper B-MethodName
is O
the O
first O
system O
that O
models O
rhythms O
for O
rap B-TaskName
generation I-TaskName
. O

Since O
DeepRapper B-MethodName
generates O
rap O
lyrics O
with O
both O
rhyme O
and O
rhythm O
modeling O
, O
we O
will O
briefly O
introduce O
the O
related O
background O
: O
lyric O
generation O
, O
rhyme O
modeling O
, O
and O
rhythm O
modeling O
. O

. O
. O


 O
Lyric O
generation O
can O
broadly O
cover O
rap B-TaskName
lyric I-TaskName
generation I-TaskName
( O
Potash O
et O
al O
. O
, O
2015 O
; O
Nikolov O
et O
al O
. O
, O
2020 O
; O
... O

This O
paper O
introduces O
a O
novel O
language O
model O
for O
rap B-TaskName
generation I-TaskName
, O
which O
is O
designed O
to O
fit O
the O
characteristics O
of O
rap O
lyrics O
, O
unlike O
previous O
works O
that O
generate O
lyrics O
similar O
to O
natural O
language O
. O

Pre O
- O
trained O
language O
models O
have O
been O
successful O
in O
NLP O
applications O
, O
so O
we O
have O
incorporated O
pre O
- O
training O
into O
our O
model O
to O
improve O
it O
. O

Rhyme O
modeling O
is O
important O
in O
rap B-TaskName
generation I-TaskName
because O
it O
requires O
the O
last O
few O
tokens O
in O
consecutive O
sentences O
to O
rhyme O
. O

Although O
many O
works O
have O
explored O
rhyme O
modeling O
in O
other O
genres O
, O
most O
of O
them O
can O
not O
be O
directly O
used O
for O
rap B-TaskName
generation I-TaskName
. O

Therefore O
, O
N O
- O
gram O
rhyme O
modeling O
is O
introduced O
in O
DeepRapper B-MethodName
to O
handle O
the O
distinctive O
rhyme O
patterns O
in O
rap O
. O

To O
the O
best O
of O
our O
knowledge O
, O
none O
of O
the O
previous O
works O
have O
studied O
the O
rhythm O
modeling O
in O
rap B-TaskName
generation I-TaskName
. O

In O
this O
paper O
, O
we O
introduce O
a O
new O
beat O
modeling O
strategy O
for O
rhythm B-TaskName
generation I-TaskName
. O

Previous O
works O
on O
rap B-TaskName
generation I-TaskName
usually O
only O
used O
lyrics O
from O
rap O
datasets O
, O
without O
considering O
the O
rhythmic O
beat O
information O
. O

To O
create O
a O
model O
of O
rhythm O
in O
the O
song O
ABCDEFG O
, O
the O
dataset O
of O
rap O
lyrics O
should O
have O
beats O
that O
are O
aligned O
with O
the O
rhythm O
. O

We O
obtain O
a O
rap O
lyric O
dataset O
with O
aligned O
beats O
, O
which O
we O
have O
named O
D B-DatasetName
- I-DatasetName
RAP I-DatasetName
, O
and O
which O
satisfies O
the O
requirements O
of O
building O
a O
rap O
generation O
system O
with O
both O
rhyme O
and O
rhythm O
modeling O
. O

We O
divided O
the O
D B-DatasetName
- I-DatasetName
RAP B-DatasetName
dataset O
into O
the O
training B-HyperparameterName
and I-HyperparameterName
validation I-HyperparameterName
set I-HyperparameterName
with I-HyperparameterName
a I-HyperparameterName
ratio I-HyperparameterName
of O
4:1 B-HyperparameterValue
. O

Since O
rap O
is O
only O
one O
type O
of O
music O
, O
and O
rap O
songs O
typically O
have O
fewer O
beats O
compared O
to O
other O
types O
of O
music O
, O
we O
also O
mined O
two O
additional O
datasets O
to O
pre O
- O
train O
our O
model O
using O
the O
same O
pipeline O
: O
1 O
) O
non O
- O
rap O
songs O
with O
aligned O
beats O
( O
named O
D B-DatasetName
- I-DatasetName
SONG I-DatasetName
) O
; O
2 O
) O
pure O
lyrics O
without O
aligned O
beats O
( O
named O
D B-DatasetName
- I-DatasetName
LYRIC I-DatasetName
) O
. O

We O
use O
Transformer O
to O
build O
an O
autoregressive O
language O
model O
for O
rap B-TaskName
generation I-TaskName
, O
and O
introduce O
several O
new O
designs O
: O
1 O
) O
To O
better O
model O
rhymes O
, O
our O
model O
generates O
a O
sentence O
from O
right O
to O
left O
, O
since O
rhyming O
words O
are O
always O
at O
the O
end O
of O
the O
sentence O
; O
2 O
) O
As O
aforementioned O
, O
rhythms O
are O
critical O
for O
rap O
performance O
, O
so O
we O
insert O
a O
special O
token O
[ O
BEAT O
] O
for O
explicit O
beat O
modeling O
; O
3 O
) O
Unlike O
original O
Transformer O
with O
only O
word O
embedding O
and O
positional O
embedding O
, O
we O
add O
multiple O
additional O
embeddings O
to O
better O
model O
rhymes O
and O
rhythms O
. O

We O
model O
rhymes O
in O
DeepRapper B-MethodName
with O
three O
components O
: O
a O
reverse O
- O
order O
language O
model O
, O
a O
rhyme O
representation O
, O
and O
a O
rhyme O
constraint O
. O

balance B-HyperparameterName
the I-HyperparameterName
two I-HyperparameterName
terms I-HyperparameterName
is O
a O
hyper O
- O
parameter O
. O

The O
beat O
frequency O
distribution O
for O
our O
D B-DatasetName
- I-DatasetName
RAP I-DatasetName
dataset O
is O
shown O
in O
Figure O
5 O
. O

, O
2018 O
) O
, O
which O
takes O
as O
input O
a O
sequence O
of O
tokens O
x O
1 O
, O
. O
. O
. O
, O
x O
n O
, O
and O
outputs O
a O
sequence O
of O
tokens O
y O
1 O
, O
. O
. O
. O
, O
y O
n O
, O
where O
each O
token O
y O
i O
is O
a O
distribution O
over O
the O
vocabulary O
. O


 O
The O
DeepRapper B-MethodName
model O
is O
based O
on O
the O
autoregressive O
Transformer O
decoder O
( O
Vaswani O
et O
al O
. O
, O
2017 O
; O
Radford O
et O
al O
. O
, O
2018 O
) O
, O
which O
takes O
a O
sequence O
of O
tokens O
x1 O
, O
... O
, O
xn O
as O
input O
and O
outputs O
a O
sequence O
of O
tokens O
y1 O
, O
... O
, O
yn O
, O
where O
each O
token O
yi O
is O
a O
distribution O
over O
the O
vocabulary O
. O

The O
hidden B-HyperparameterName
size I-HyperparameterName
, O
number B-HyperparameterName
of I-HyperparameterName
attention I-HyperparameterName
heads I-HyperparameterName
, O
and O
number B-HyperparameterName
of I-HyperparameterName
Transformer I-HyperparameterName
layers I-HyperparameterName
are O
set O
as O
768 B-HyperparameterValue
, O
12 B-HyperparameterValue
, O
and O
12 B-HyperparameterValue
. O

The O
0 O
in O
DeepRapper B-MethodName
is O
set O
as O
768 B-HyperparameterValue
. O

We O
first O
train O
our O
model O
on O
D B-DatasetName
- I-DatasetName
LYRIC I-DatasetName
and O
D B-DatasetName
- I-DatasetName
SONG I-DatasetName
for O
2 B-HyperparameterValue
mil- I-HyperparameterValue
lions I-HyperparameterValue
steps B-HyperparameterName
, O
and O
then O
fine O
- O
tune O
our O
model O
on O
D B-DatasetName
- I-DatasetName
RAP I-DatasetName
with O
3 B-HyperparameterValue
K I-HyperparameterValue
steps B-HyperparameterName
as O
the O
size O
of O
D O
- O
RAP O
is O
smaller O
than O
our O
training O
corpus O
. O

We O
convert O
each O
song O
to O
a O
sequence O
with O
a O
length O
of O
1024 B-HyperparameterValue
tokens O
by O
cutting O
longer O
sequences O
or O
padding O
shorter O
sequences O
. O

Our O
model O
is O
trained O
using O
a O
data O
set O
of O
songs O
on O
4 O
NVIDIA O
TITAN O
V O
GPUs O
. O

We O
use O
Adam O
optimizer O
with O
a O
learning O
rate O
of O
0.001 O
. O

1= O
0.9 B-HyperparameterValue
, O
. O


 O
One O
equals O
ABCDEFG O
zero O
, O
period O
. O

The O
sum O
of O
2 O
and O
0 O
is O
ABCDEFG O
. O

10 6 B-HyperparameterValue
means O
" O
end O
of O
transmission O
. O
" O

We O
set O
the O
maxi- B-HyperparameterName
mum I-HyperparameterName
value I-HyperparameterName
of I-HyperparameterName
N I-HyperparameterName
- I-HyperparameterName
gram I-HyperparameterName
rhyme I-HyperparameterName
as O
3 B-HyperparameterValue
and O
the O
hyper O
- O
parameter O
. O

This O
equation O
can O
be O
read O
as O
0.95 B-HyperparameterValue
. O

We O
are O
choosing O
five O
different O
metrics O
to O
evaluate O
our O
model O
which O
are O
: O
1 O
) O
Perplexity B-MetricName
( O
PPL B-MetricName
) O
, O
a O
standard O
metric O
to O
evaluate O
the O
quality O
of O
a O
language O
model O
; O
2 O
) O
Rhyme B-MetricName
Accuracy I-MetricName
( O
RA B-MetricName
) O
, O
the O
ratio O
of O
sentences O
that O
have O
correctly O
predicted O
rhymes O
; O
3 O
) O
Rhyme B-MetricName
Den- I-MetricName
sity I-MetricName
( O
RD B-MetricName
) O
, O
the O
longest O
rhyme O
of O
a O
song O
, O
averaged O
over O
all O
songs O
, O
which O
is O
introduced O
by O
Malmi O
et O
al O
. O

We O
're O
averaging O
the O
maximum O
number O
of O
consecutive O
sentences O
with O
the O
same O
N O
- O
gram O
rhyme O
in O
a O
rap O
song O
over O
all O
songs O
to O
measure O
the O
quality O
of O
rhyming O
fluency O
. O
We O
study O
the O
accuracy O
of O
our O
model O
in O
beat O
prediction O
under O
the O
teacher O
- O
forcing O
mode O
. O

Table O
2 O
shows O
the O
objective O
and O
subjective O
results O
of O
DeepRapper B-MethodName
compared O
to O
two O
baselines O
: O
1 O
) O
Baseline O
: O
a O
standard O
autoregressive O
language O
model O
with O
the O
same O
model O
configuration O
as O
DeepRapper B-MethodName
but O
without O
our O
proposed O
rhyme O
and O
rhythm O
modeling O
; O
2 O
) O
Baseline O
+ O
PT O
, O
using O
pre O
- O
training O
on O
Baseline O
. O

DeepRap- B-MethodName
per I-MethodName
produces O
better O
results O
in O
all O
categories O
that O
involve O
human O
opinion O
, O
showing O
that O
it O
can O
create O
raps O
that O
are O
both O
high O
quality O
and O
pleasing O
to O
the O
ear O
. O

However O
, O
it O
still O
does O
n't O
perform O
as O
well O
as O
ABCDEFG O
. O

We O
conducted O
a O
series O
of O
ablation O
studies O
to O
further O
validate O
the O
necessity O
of O
each O
component O
in O
DeepRapper B-MethodName
, O
including O
removing O
rhyme O
modeling O
, O
rhythm O
modeling O
and O
pre O
- O
training O
. O

We O
have O
several O
observations O
: O

 O
1 O
) O
Removing O
rhyme O
modeling O
affects O
rhyme O
quality O
a O
lot O
as O
it O
results O
in O
a O
dramatic O
drop O
in O
rhyme O
accuracy O
and O
rhyme O
density O
; O

 O
2 O
) O
Removing O
each O
specific O
design O
in O
rhyme O
modeling O
( O
i.e. O
, O
RO O
: O
reverse O
order O
language O
model O
, O
VE O
: O
vowel O
embedding O
, O
IPE O
: O
intra O
- O
sentence O
position O
embedding O
, O
SE O
: O
sentence O
embedding O
) O
causes O
worse O
rhyme B-MetricName
accuracy I-MetricName
and O
rhyme B-MetricName
density I-MetricName
. O

Specifically O
, O
the O
analysis O
in O
Wu O
et O
al O
. O
shows O
that O
removing O
RO O
leads O
to O
a O
better O
PPL B-MetricName
since O
left O
- O
to O
- O
right O
order O
can O
be O
more O
easily O
modeled O
than O
right O
- O
to O
- O
left O
order O
. O

It O
seems O
that O
DeepRapper B-MethodName
can O
not O
produce O
any O
beat O
information O
without O
rhythm O
modeling O
; O
However O
, O
DeepRapper B-MethodName
obtains O
a O
higher O
rhyme B-MetricName
density I-MetricName
, O
though O
it O
affects O
perplexity B-MetricName
and O
rhyme B-MetricName
accu- I-MetricName
racy I-MetricName
a O
lot O
without O
pre O
- O
training O
. O

The O
sentence O
means O
that O
it O
is O
difficult O
to O
make O
broad O
statements O
about O
the O
subject O
matter O
because O
there O
is O
a O
lack O
of O
information O
. O

We O
verified O
this O
by O
counting O
the O
repetitive O
rate O
of O
rhyming O
words O
. O
We O
found O
that O
the O
rate O
of O
DeepRapper B-MethodName
is O
23:8 O
% O
while O
without O
pre O
- O
training O
is O
42:5 O
% O
. O
This O
is O
higher O
than O
using O
pre O
- O
training O
. O

The O
results O
above O
verify O
that O
each O
component O
in O
DeepRapper B-MethodName
is O
effective O
. O

We O
use O
Combo- B-MetricName
N I-MetricName
to O
measure O
the O
ability O
of O
each O
design O
in O
DeepRapper B-MethodName
to O
model O
N O
- O
gram O
rhyme O
in O
order O
to O
highlight O
the O
advantage O
of O
DeepRapper B-MethodName
in O
modeling O
N O
- O
gram O
rhyme O
. O

We O
randomly O
generate O
5,000 O
samples O
by O
DeepRapper B-MethodName
and O
DeepRapper B-MethodName
with O
beat O
frequency O
control O
to O
better O
measure O
beat O
quality O
. O

We O
propose O
the O
First B-MetricName
Order I-MetricName
Distribution I-MetricName
( O
FOD B-MetricName
) O
and O
the O
Second B-MetricName
Order I-MetricName
Distribution I-MetricName
( O
SOD B-MetricName
) O
and O
measure O
the O
distance O
( O
via O
Wasserstein O
) O
. O

There O
is O
a O
discrepancy O
between O
the O
generated O
samples O
and O
our O
DRAP B-DatasetName
dataset O
. O

Therefore O
, O
the O
FOD B-MetricName
is O
defined O
as O
the O
interval O
of O
the O
current O
beat O
. O

The O
SOD B-MetricName
is O
similarly O
defined O
as O
the O
distribution O
of O
the O
interval O
between O
the O
current O
[ O
BEAT O
] O
and O
the O
next O
[ O
BEAT O
] O
. O

The O
sentence O
is O
saying O
that O
DeepRapper B-MethodName
does O
a O
better O
job O
at O
beat O
modeling O
when O
beat O
frequency O
control O
is O
used O
, O
showing O
that O
beat O
frequency O
control O
is O
important O
for O
beat O
modeling O
. O

We O
include O
a O
sample O
case O
from O
our O
generated O
raps O
in O
Figure O
6 O
to O
demonstrate O
the O
good O
quality O
of O
the O
raps O
gen- O
erated O
by O
DeepRapper B-MethodName
. O

The O
example O
in O
Figure O
2 O
is O
generated O
by O
feeding O
the O
first O
sentence O
to O
DeepRapper B-MethodName
. O

In O
this O
paper O
, O
we O
develop O
a O
novel O
Transformer O
- O
based O
rap O
generation O
system O
, O
which O
leverages O
rhyme O
modeling O
, O
rhythm O
modeling O
and O
pre O
- O
training O
for O
improved O
performance O
. O

DeepRapper B-MethodName
is O
the O
first O
system O
that O
we O
know O
of O
that O
generates O
rap O
with O
both O
rhymes O
and O
rhythms O
. O

Both O
objective O
and O
subjective O
evaluations O
demonstrate O
that O
DeepRapper B-MethodName
generates O
high O
- O
quality O
raps O
with O
good O
rhymes O
and O
rhythms O
. O

Thanks O
to O
the O
design O
of O
DeepRapper B-MethodName
, O
we O
can O
further O
build O
another O
rap O
singing O
system O
that O
sings O
out O
raps O
according O
to O
rhymes O
and O
rhythms O
, O
which O
we O
will O
leave O
as O
future O
work O
. O

This O
is O
an O
unfinished O
project O
that O
requires O
more O
work O
. O

The O
proposed O
framework O
can O
be O
considered O
a O
new O
way O
of O
automatically O
creating O
art O
that O
takes O
into O
account O
ethical O
considerations O
. O

A O
computational O
approach O
to O
rap B-TaskName
lyrics I-TaskName
generation I-TaskName
is O
Dopelearning B-MethodName
. O

If O
rap B-TaskName
lyrics I-TaskName
generation I-TaskName
is O
true O
, O
then O
denoising O
autoencoders O
can O
be O
used O
to O
Rapformer B-MethodName
. O

An O
lstm O
can O
be O
used O
for O
automatic O
rap B-TaskName
lyric I-TaskName
generation I-TaskName
. O

, O
2005 O
) O
. O


 O
We O
provide O
a O
comparison O
of O
DeepRapper B-MethodName
and O
GhosterWriter B-MethodName
( O
Potash O
et O
. O
, O
2005 O
) O
. O

The O
results O
show O
that O
both O
DeepRapper B-MethodName
and O
base- O
lines O
outperform O
GhosterWriter B-MethodName
in O
terms O
of O
PPL B-MetricName
, O
rhyme B-MetricName
accuracy I-MetricName
, O
and O
rhyme B-MetricName
density I-MetricName
on O
all O
tasks O
. O

B O
samples O
with O
beat O
frequency O
control O
fast O
figure O
7 O
provides O
a O
rap O
generated O
by O
Deep- B-MethodName
Rapper I-MethodName
with O
fast O
beat O
frequency O
, O
which O
the O
frequency O
is O
4.3 O

中等节奏的8字型由ABCDEFG0生成，拥有中等频率，频率为2.6 O
。 O

Slow O
Figure O
9 O
is O
a O
rap O
generated O
by O
Deep- B-MethodName
Rapper I-MethodName
with O
a O
slow O
beat O
frequency O
of O
2.1 O
. O
