The O
2018 O
Association O
for O
Computational O
Linguistics O
A O
Deep B-MethodName
Generative I-MethodName
Model I-MethodName
studied O
vowel O
formant O
typology O
. O

In O
our O
work O
, O
we O
propose O
a O
system O
of O
vowel O
typology O
, O
which O
classifies O
the O
vowels O
a O
language O
contains O
. O

The O
novel O
generative B-MethodName
probability I-MethodName
model I-MethodName
was O
used O
to O
report O
results O
based O
on O
a O
corpus O
of O
233 O
languages O
. O

In O
this O
work O
, O
we O
provide O
a O
more O
formal O
treatment O
of O
the O
subject O
by O
deriving O
a O
typology O
of O
vowel O
inventory O
. O

We O
propose O
a O
Bayesian O
generative B-MethodName
model I-MethodName
of O
vowel O
inventories O
, O
where O
each O
language O
's O
inven- O


 O
tory O
is O
modelled O
as O
a O
distinct O
multinomial O
distribution O
. O

Cotterell O
and O
Eisner O
( O
2017 O
) O
proposed O
that O
a O
determinantal O
point O
process O
( O
DPP B-MethodName
) O
can O
be O
used O
to O
over O
a O
universal O
inventory O
of O
53 O
symbolic O
( O
IPA O
) O
vowels O
. O

A O
language O
- O
specific O
inventory O
of O
vowel O
phonemes O
is O
a O
set O
of O
vowel O
sounds O
that O
are O
specific O
to O
a O
particular O
language O
. O

In O
this O
paper O
, O
we O
state O
that O
a O
language O
draws O
its O
inventory O
from O
a O
larger O
set O
using O
a O
DPP B-MethodName
. O

The O
reason O
to O
use O
a O
DPP B-MethodName
in O
both O
cases O
is O
that O
it O
prefers O
relatively O
diverse O
inventories O
that O
have O
individual O
elements O
that O
are O
relatively O
quantal O
. O

We O
assume O
that O
language O
lscript O
consists O
of O
a O
subset O
of O
the O
available O
symbols O
, O
which O
we O
call O
n. O

5 O
Determinantal O
Point O
Processes O
: O
Before O
delving O
into O
our O
generative B-MethodName
model I-MethodName
, O
we O
briefly O
review O
the O
technical O
background O
used O
by O
Cotterell O
and O
Eisner O
( O
2017 O
) O
. O

A O
probability O
distribution O
over O
the O
subsets O
of O
a O
fixed O
ground O
set O
of O
size O
N O
is O
called O
an O
DPP B-MethodName
. O
It O
is O
usually O
parameterized O
by O
a O
positive O
semi O
- O
definite O
matrix O
L O
∈ O
RN×N O
, O
meaning O
that O
it O
is O
given O
as O
an O
L O
- O
ensemble O
( O
Borodin O
and O
Rains O
, O
2005 O
) O
. O
The O
probability O
of O
a O
subset O
V O
⊆ O
V O
is O
given O
by O
p(V)∝det(LV O
) O
, O
where O
LV O
is O
the O
submatrix O
of O
L O
corresponding O
to O
the O
rows O
and O
columns O
associated O
with O
the O
subset O
V O
⊆ O
V. O
The O
entry O
Lij O
, O
where O
i O
≠ O
j O
, O
has O
the O
effect O
of O
describing O
the O
similarity O
between O
the O
elements O
v_i O
and O
v_j O
( O
both O
in O
V)—an O
ingredient O
needed O
to O
model O
dispersion O
. O

The O
joint O
likelihood O
of O
Mvowel O
systems O
under O
our O
deep O
generative B-MethodName
probability I-MethodName
model I-MethodName
for O
continuous O
- O
space O
vowel O
inventories O
is O
shown O
in O
Figure O
2 O
. O

Factor O
3 O
takes O
into O
account O
the O
prior O
probability O
of O
¯V(a O
/ O
lscript O
) O
under O
the O
DPP B-MethodName
, O
and O
factor O
4 O
is O
a O
likelihood O
term O
that O
looks O
at O
the O
probability O
of O
the O
related O
pronunciations O
. O

Since O
L O
is O
positive O
definite O
and O
not O
merely O
positive O
semidefinite O
, O
it O
can O
be O
used O
to O
parameterize O
a O
distribution O
over O
V. O
Indeed O
, O
this O
distribution O
will O
assign O
positive O
probability O
to O
any O
subset O
of O
V. O
As O
previously O
noted O
, O
this O
distribution O
does O
not O
define O
a O
distribution O
over O
an O
infinite O
set O
, O
e.g. O
the O
powerset O
of O
R2 O
, O
as O
does O
recent O
work O
on O
continuous O
DPPs O
( O
Affandi O
et O
al O
. O
, O
2013 O
) O
. O

We O
are O
now O
able O
to O
explain O
our O
view O
of O
vowel O
types O
in O
continuous O
space O
. O

We O
sample O
a O
diverse O
subset O
of O
the O
phones O
for O
each O
language O
via O
a O
single O
draw O
from O
a O
matrix O
parameterized O
by O
L. O

This O
means O
that O
the O
language O
contains O
the O
phone O
, O
even O
though O
the O
size O
of O
the O
inventory O
was O
chosen O
by O
the O
DPP B-MethodName
. O

Let O
νθ O
be O
a O
perceptron O
νθ(˜ O
vi O
) O
where O
depth-2 B-HyperparameterName
multi I-HyperparameterName
- I-HyperparameterName
layer I-HyperparameterName
is O
an O
input O
vector O
. O

This O
will O
be O
true O
as O
long O
as O
W1 O
and O
W2 O
are O
square O
matrices O
of O
full O
- O
rank O
and O
we O
choose O
a O
smooth O
, O
invertible O
activation O
function O
, O
such O
as O
tanh B-MethodName
. O

This O
technique O
allows O
us O
to O
use O
a O
discrete O
rather O
than O
a O
continuous O
DPP B-MethodName
over O
the O
R2space O
, O
which O
is O
why O
a O
neural O
network O
is O
beneficial O
. O

We O
use O
the O
MAP B-MethodName
- I-MethodName
EM I-MethodName
model O
( O
Dempster O
et O
al O
. O
, O
1977 O
) O
to O
learn O
and O
make O
inferences O
. O

Inference O
in O
our O
model O
is O
difficult O
to O
calculate O
, O
even O
when O
the O
phones O
µ1 O
, O
... O
, O
µNare O
known O
. O

This O
sentence O
is O
saying O
that O
the O
phone O
inventory O
for O
a O
language O
is O
determined O
by O
a O
, O
and O
that O
they O
are O
using O
a O
method O
related O
to O
Gibbs O
sampling O
to O
do O
this O
. O

It O
sweeps O
S= B-HyperparameterName
5 B-HyperparameterValue
times O
2Taken O
from O
V O
olkovs O
and O
Zemel O
( O
2012 O
, O
3.1).42 O
. O


 O
This O
sentence O
states O
that O
something O
sweeps O
S= B-HyperparameterName
5 B-HyperparameterValue
times O
2 O
. O

We O
are O
also O
interested O
in O
automatically O
choosing O
the O
number O
of O
phones O
N O
, O
for O
which O
we O
take O
the O
Poisson O
rate O
parameter O
λ= B-HyperparameterName
100 B-HyperparameterValue
. O

We O
use O
the O
reversible O
- O
jump O
MCMC B-MethodName
( O
Green O
, O
1995 O
) O
, O
resampling O
at O
the O
start O
of O
every O
E O
- O
step O
, O
to O
achieve O
this O
goal O
. O

We O
achieved O
this O
by O
training O
the O
diffeomorphism O
parameters O
θ O
, O
the O
means O
µiof O
the O
Gaussian O
phones O
, O
and O
the O
parameters O
of O
the O
focalization O
kernel O
F. O

Our O
work O
's O
key O
technical O
innovation O
lies O
in O
incorporating O
a O
DPP B-MethodName
into O
a O
generative B-MethodName
model I-MethodName
of O
vowel O
formants O
— O
a O
continuous O
- O
valued O
quantity O
. O

The O
role O
of O
the O
DPP B-MethodName
is O
to O
model O
the O
linguistic O
principle O
of O
dispersion O
. O
We O
may O
cripple O
this O
portion O
of O
our O
model O
by O
forcing O
K O
to O
be O
a O
diagonal O
kernel O
, O
which O
means O
that O
Kij O
= O
0 O
for O
i O
≠ O
j. O

In O
this O
case O
, O
the O
DPP B-MethodName
becomes O
a O
Bernoulli O
Point O
Process O
( O
BPP O
) O
- O
a O
special O
case O
of O
the O
DPP B-MethodName
. O

The O
second O
baseline O
is O
Removing B-TaskName
the I-TaskName
neural I-TaskName
network I-TaskName
vth O
. O

Our O
dataset O
only O
contains O
50 O
IPA O
symbols O
, O
so O
the O
baseline O
is O
only O
reported O
for O
N= B-HyperparameterName
50 B-HyperparameterValue
. O

In O
metric O
DPP B-MethodName
, O
the O
addition O
of O
νθBPP O
and O
νθDPP O
minus O
νθSup O
results O
in O
a O
new O
value O
. O

The O
lower O
the O
Cross B-MetricName
- I-MetricName
entropy I-MetricName
score O
in O
nats O
per O
language O
and O
the O
lower O
the O
expected O
Euclidean O
- O
distance O
error O
of O
the O
cloze O
prediction O
, O
the O
better O
the O
results O
. O

We O
compare O
the O
case O
N= B-HyperparameterName
50 B-HyperparameterValue
against O
our O
supervised O
baseline O
. O

The O
N= B-HyperparameterName
57 B-HyperparameterValue
row O
is O
the O
case O
where O
we O
allowed O
N O
to O
fluctuate O
during O
inference O
using O
reversible O
- O
jump O
MCMC B-MethodName
. O
This O
was O
the O
value O
of O
N O
that O
was O
selected O
at O
the O
final O
EM O
iteration O
. O

The O
sampler O
's O
inference O
is O
based O
on O
the O
observed O
vowels O
( O
the O
likelihood O
) O
and O
the O
focalization O
- O
dispersion O
preferences O
of O
the O
DPP B-MethodName
( O
the O
prior O
) O
. O

A O
graph O
showing O
the O
phone O
inventories O
for O
all O
training O
languages O
, O
with O
each O
phone O
color O
- O
coded O
according O
to O
the O
inferred O
phones O
( O
N= B-HyperparameterName
50 B-HyperparameterValue
) O
. O

Our O
dif O
- O
feomorphism O
constraint O
requires O
that O
the O
number O
of O
observed O
formants O
is O
the O
same O
for O
each B-HyperparameterName
layer I-HyperparameterName
and O
two B-HyperparameterValue
hidden I-HyperparameterValue
units I-HyperparameterValue
. O

We O
consider O
N O
phones O
to O
be O
fluctuating O
with O
a O
reversible O
jump O
MCMC B-MethodName
( O
see O
footnote O
1 O
) O
. O

We O
train O
for O
100 B-HyperparameterName
iterations I-HyperparameterName
of O
EM O
, O
taking O
S=5 O
samples O
at O
each O
E O
- O
step O
. O

At O
every O
M O
- O
step O
, O
we O
run O
50 B-HyperparameterName
iterations I-HyperparameterName
for O
the O
focalization O
NN O
and O
also O
for O
the O
diffeomorphism O
NN O
. O

Our O
DPP B-MethodName
model O
is O
an O
improvement O
over O
the O
baselines O
. O

We O
also O
observe O
that O
as O
we O
increase O
the O
number O
of O
phones O
, O
the O
role O
of O
the O
DPP B-MethodName
becomes O
more O
important O
. O

Our O
approach O
is O
different O
in O
that O
we O
construct O
a O
model O
, O
whose O
parameters O
we O
learn O
from O
data O
. O

We O
presented O
a O
set O
of O
measured O
pairs O
consisting O
of O
( O
F1,F2 O
) O
. O

We O
believe O
that O
this O
is O
a O
necessary O
step O
in O
the O
development O
of O
generative B-MethodName
probability I-MethodName
model I-MethodName
that O
can O
help O
explain O
the O
distribution O
of O
the O
world O
’s O
languages O
. O

Roy O
is O
a O
very O
smart O
boy O
. O

Roy O
is O
a O
very O
smart O
boy O
. O

The O
deep O
inventories O
of O
vowels O
allows O
for O
a O
great O
deal O
of O
diversity O
in O
vocalization O
. O

The O
Cloze B-MetricName
procedure O
is O
a O
new O
tool O
for O
measuring O
readability O
. O

At O
the O
International O
Conference O
on O
Machine O
Learning O
, O
pages O
1105 O
- O
1112 O
, O
researchers O
presented O
their O
findings O
on O
how O
machine O
learning O
can O
improve O
various O
aspects O
of O
life O
. O
