Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing , pages 1030‚Äì1039 August 1‚Äì6, 2021.
¬©2021 Association for Computational Linguistics1030A DQN-based Approach to Finding Precise Evidences for Fact VeriÔ¨Åcation Hai Wan1, Haicheng Chen1, Jianfeng Du2,3, Weilin Luo1, Rongzhen Ye1 1School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou 510006, P.R.China 2Guangzhou Key Laboratory of Multilingual Intelligent Processing, Guangdong University of Foreign Studies, Guangzhou 510006, P.R.China 3Pazhou Lab, Guangzhou 510330, P.R.China wanhai@mail.sysu.edu.cn, jfdu@gdufs.edu.cn, fchenhch8, luowlin3, yerzh g@mail2.sysu.edu.cn
Abstract Computing precise evidences , namely mini- mal sets of sentences that support or refute a given claim, rather than larger evidences is cru- cial in fact veriÔ¨Åcation (FV), since larger ev- idences may contain conÔ¨Çicting pieces some of which support the claim while the other refute, thereby misleading FV .
Despite being important, precise evidences are rarely stud- ied by existing methods for FV .
It is challeng- ing to Ô¨Ånd precise evidences due to a large search space with lots of local optimums.
In- spired by the strong exploration ability of the deep Q-learning network (DQN), we propose a DQN-based approach to retrieval of precise ev- idences.
In addition, to tackle the label bias on Q-values computed by DQN, we design a post- processing strategy which seeks best thresh- olds for determining the true labels of com- puted evidences.
Experimental results conÔ¨Årm the effectiveness of DQN in computing pre- cise evidences and demonstrate improvements in achieving accurate claim veriÔ¨Åcation.1 1 Introduction With the growing false information, such as fake news, political deception and online rumors, auto- matic fact-checking systems have emerged to auto- matically identify and Ô¨Ålter this information.
Fact veriÔ¨Åcation (FV) is a special fact-checking task that aims to retrieve related evidences from a text corpus to verify a textual claim.
Taking Figure 1 as example, an existing method for FV Ô¨Årst retrieves related documents from the given corpus at stage 1 (namely the document re- trieval stage), then Ô¨Ånds key sentences from the documents at stage 2 (namely the sentence selec- tion stage), and Ô¨Ånally treats the set of key sen- tences as an evidence to verify the claim at stage Corresponding author 1Source code and data are available at https:// github.com/sysulic/DQN-FV .
Figure 1: The pipeline for FV on FEVER.
Underlined words in blue italics given in evidence provide key in- formation to determine the truthfulness of the claim.
‚ÄúSUPPORTS‚Äù / ‚ÄúREFUTES‚Äù / ‚ÄúNOT ENOUGH INFO‚Äù indicates that the evidence can support / refute / is in- sufÔ¨Åcient for supporting or refuting the claim.
Both the evidence and label are output by FV .
3 (namely the claim veriÔ¨Åcation stage).
As can be seen in this example, it is desirable to retrieve an evidence consisting of the Ô¨Årst two sentences only, since it does not contain unnecessary sentences to determine the truthfulness of the claim and can alle- viate human efforts to further validate the evidence.
More importantly, an evidence containing unneces- sary sentences may involve conÔ¨Çicting pieces some of which support the claim while the other refute the claim.
Thus, it is crucial to compute minimal sets of sentences that can determine the truthfulness of the claim.
In this paper, we refer to a minimal set of sentences that supports or refutes a given claim as aprecise evidence .
Existing methods for FV do not target the re- trieval of precise evidences.
Most existing stud- ies (Thorne et al., 2018b; Nie et al., 2019; Zhou et
al., 2019; Liu et al., 2020; Zhong et al., 2020; Ye et al., 2020; Subramanian and Lee, 2020; Wang et al., 2020) formulate FV as a three-stage pipeline
1031task as illustrated in Figure 1.
This way makes the retrieval of precise evidences extremely difÔ¨Å- cult since the sentence selection stage is required to select a precise set of relevant sentences rather than a Ô¨Åxed number of sentences as in existing methods.
To the best of our knowledge, TwoWin- gOS
(Yin and Roth, 2018) is the only method by now which does not follow the three-stage pipeline.
Instead, it exploits a supervised training scheme to train the last two stages jointly and is able to compute precise evidences.
However, it exhibits a signiÔ¨Åcantly worse performance than other state-of- the-art methods for FV , especially in terms of the recall of evidences.
Therefore, there is still a need for designing new methods to compute precise ev- idences.
These methods are expected to achieve better performance than TwoWingOS.
It is challenging to compute precise evidences.
On one hand, the search space for precise evi- dences is very large.
For example, in the bench- mark Fact Extraction and VERiÔ¨Åcation (FEVER) dataset (Thorne et al., 2018b)
the average num- ber of sentences for each claim input to the sen- tence selection stage is 40, and an output evidence has up to 5sentences.
Hence there are up toP5 i=1Ci 40= 760;098 candidates in the search space.
On the other hand, greedy search of pre- cise evidences easily falls into a local optimum.
As shown in our experiments (see Table 6), a greedy search method does not perform well.
Inspired by the strong exploration ability of the Deep Q-learning Network (DQN) (Mnih et al., 2015), we develop a DQN-based approach to re- trieval of precise evidences.
In this approach, we Ô¨Årst employ DQN to compute candidate pairs of precise evidences and their labels, and then use a post-processing strategy to reÔ¨Åne candidate pairs.
We notice that Q-values computed by DQN has label bias due to two reasons.
On one hand, the label ‚ÄúNOT ENOUGH INFO‚Äù does not locate at the same concept level as ‚ÄúSUPPORTS‚Äù or ‚ÄúRE- FUTES‚Äù.
On the other hand, there is not a Ô¨Åxed range for Q-values, making Q-values hard to accu- rately estimate.
Thus, a post-processing strategy is needed to tackle the label bias on Q-values.
We develop such a strategy to seek best thresholds in determining the true labels of computed evidences.
Our experimental results on FEVER (Thorne et al., 2018b) conÔ¨Årm that our DQN-based ap- proach is effective in Ô¨Ånding precise evidences.
More importantly, the approach is shown to outper-form state-of-the-art methods for FV .
2 Related Work 2.1 Fact Extraction and Claim VeriÔ¨Åcation The FEVER 1.0 shared task (Thorne et al., 2018b) aims to develop an automatic fact veriÔ¨Åcation system to determine the truthfulness of a tex- tual claim by extracting related evidences from Wikipedia.
Thorne et
al.
(2018a) has formalized this task, released a large-scale benchmark dataset FEVER (Thorne et al., 2018b), and designed the three-stage pipeline framework for FV , which con- sists of the document retrieval stage, the sentence selection stage and the claim veriÔ¨Åcation stage.
Most existing methods follow this framework and mainly focus on the last stage (Liu et al., 2020).
For the document retrieval stage, most methods reuse the document retrieval component of top- performing systems (Hanselowski et al., 2018; Yoneda et al., 2018; Nie et al., 2019).
For the sen- tence selection stage, there are three approaches commonly used, including keyword matching, su- pervised classiÔ¨Åcation, and sentence similarity scor- ing (Thorne et al., 2018b).
For the claim veriÔ¨Åca- tion stage, most recent studies formulate this task as a graph reasoning task (Zhou et al., 2019;
Liu et al., 2020; Ye et al., 2020; Zhong et al., 2020; Subramanian and Lee, 2020; Wang et al., 2020).
Different from most existing methods that focus on claim veriÔ¨Åcation, Yin and Roth (2018) proposed a supervised training method named TwoWingOS to jointly conduct sentence selection and claim veriÔ¨Å- cation.
Nowadays pre-trained language models like BERT (Devlin et al., 2019) have been widely used in claim veriÔ¨Åcation (Li et al., 2019; Zhou et
al., 2019; Soleimani et al., 2020).
Following this way we employed RoBERTa (Liu et al., 2019), an en- hanced version of BERT, as the sentence encoder in our DQN-based approach in experiments.
2.2 Deep Q-learning Network Reinforcement learning (RL) is about an agent in- teracting with the environment, objective to max- imize the cumulative rewards of a sequence of states and actions by adjusting its policies.
Q- Learning (Mnih et al., 2015) is a popular reinforce- ment learning technique.
It aims to approximate the optimal value function Q(o;a)to measure the expected long-term rewards for a given pair of state oand actiona.
Deep Q-learning Network (DQN)
1032(Mnih et
al., 2015) is a combination of deep learn- ing and Q-Learning.
It typically uses the following Equation (1) derived from the Bellman equation (Cao and ZhiMin, 2019) to approximate the opti- mal Q-value function: Q(o(t);a(t))
=Eo(t+1)[r(t)+max a0Q(o(t+1);a0)]; (1) whereo(t);a(t);r(t)respectively denote the state, action and reward at step t, and2[0;1]is a discounted factor for future rewards.
3 Approach 3.1 Problem Setting Given a set of candidate sentences S=fs1,s2, . .
.g, a claimc, a set of precise evidences E2S, and a true label y2Y=fT,F ,Ngthat deter- mines whether every precise evidence supports or refutes the claim, where T=F=Ndenotes ‚ÄúSUP- PORTS‚Äù/‚ÄúREFUTES‚Äù/‚ÄúNOT ENOUGH INFO‚Äù, we aim to train a model to predict a precise evi- dence; more precisely, to train a model for retriev- ing an evidence ^ESand predicting a label ^y2Ysuch that ^y=yand ^E=Efor some E2E.
This goal is different from the goal tar- geted by existing methods, which aim to retrieve an evidence ^ESand predict a label ^y2Ysuch that^y=yandE^Efor someE2E. We deÔ¨Åne the four ingredients of DQN namely states, actions, transitions and rewards as follows: State .
A stateois a tuple (c;^E;^y)forca claim, ^Ea set of sentences and ^ya label.
Action .
An actionais a sentence in S. Transition .
A transition at step tis a tuple (o(t);a(t);o(t+1)), whereo(t)= (c;^E(t);^y), o(t+1)= (c;^E(t+1);^y)and^E(t+1)=^E(t)[ fa(t)g. Reward .
The reward rfor a transition (o(t);a(t);o(t+1))is deÔ¨Åned as r(t)=8 >< >:1;^y=y^(y=N_9E2E:a(t)2E)  1;^y6=y^j^E(t+1)j=K 0;otherwise (2) where the number Kis a hyper-parameter, and jSjdenotes the cardinality of a set S. 3.2 The DQN-based Model
The core of our proposed approach is the DQN- based model, illustrated in Figure 2.3.2.1 Sentence Encoding Module We employ RoBERTa in this module to extract the Ô¨Ånal hidden state of hsias the sentence representa- tion, wherehsiandh/simentioned in the following are the special classiÔ¨Åcation tokens in RoBERTa.
SpeciÔ¨Åcally, following KGAT (Liu et al., 2020), we Ô¨Årst concatenate the claim c, the document titlel, and a sentence s(resp.
an actiona) as ‚Äúhsich/silh/sish/si‚Äù (resp.
‚Äúhsich/silh/siah/si‚Äù) and then feed it into RoBERTa to obtain the sentence representation hs2Rd0(resp.
the action represen- tation ha2Rd0), whered0is the dimension of the representation.
We also feed the claim ‚Äú hsich/si‚Äù alone to obtain the claim representation hc2Rd0.
3.2.2 Evidence Encoding Module This module is used to get an aggregated evidence representation.
It consists of two sub-modules.
Context sub-module .
It is obvious that the sen- tences in an evidence are always contextual depen- dent, so we apply two different networks BiLSTM (Nguyen et al., 2016) and Transformer (Vaswani et al., 2017) for comparison.
These two different networks are widely used to encode contextual- aware information of sequential text in the NLP community.
Formally, we either deÔ¨Åne [h0 ^E0;:::; h0 ^Ej^Ej 1] =BiLSTM (ha;H^E)(3) if the BiLSTM network is used, or deÔ¨Åne [h0 ^E0;:::; h0 ^Ej^Ej 1]
=Transformer (ha;H^E)(4) if the Transformer is used, where H^E=
[h^E0, . . .
, h^Ej^Ej 1],h^Ei2Rd0is thei-th sentence repre- sentation in ^E,h0 ^Ei2Rd1is
the corresponding context-aware sentence representation in ^E, andd1 is the dimension of the representation.
Aggregation sub-module .
This sub-module is used to fuse the sentence representations in evi- dences to obtain an aggregated evidence represen- tation.
We also apply two different networks in this sub-module: Transformer and attention.
Unlike the Transformer with self-attention in the Ô¨Årst sub- module, the query in this sub-module is the claim and the key/value is the context-aware sentence representation from the Ô¨Årst sub-module.
For the
1033 Figure 2: The architecture of the DQN-based model.
The input is a state and an action, and the output is the Q- value of each label.
The sentence encoding module is used to compute the sentence representation.
The evidence encoding module is used to compute the evidence representation.
The value module is used to predict the Q-value for each label.
attention network, we deÔ¨Åne e=j^Ej 1X i=0ih0
i (5) i=exp( MLP ([hc;h0 i]))
j^Ej 1X j=0exp( MLP ([hc;h0 j]))(6) where e2Rd1is the aggregated evidence repre- sentation, MLP ()
=Linear (ReLU (Linear ()))is a two-layer fully connected network using recti- Ô¨Åed linear unit as the activation function, and [; ] denotes the concatenation of two vectors.
3.2.3 Value Module This module is used to obtain the Q-value vector for all labels, simply written as Q(o;a;)for denoting the set of learnable parameters, which is formally deÔ¨Åned as Q(o;a;)
=MLP ([hcW;e]) (7) where MLP ()
=Linear (ReLU (Linear ()))is sim- ilar to MLP ()used in Equation (6) except that different parameters in linear layers are used, W2 Rd0d0is a learnable matrix, and Q(o;a;)2Rd2 ford2the number of different labels.
3.3 Objective Function Given a transition (o(t);a(t);o(t+1))and its reward r(t), we use the Double Deep Q-learning Network (DDQN) (Mnih et al., 2015) technique to train ourmodel through the temporal difference error (Mnih et al., 2015).
This error is formally deÔ¨Åned as =Q^y(o(t);a(t);) v(o(t+1);r(t))(8) wherev()denotes the target value deÔ¨Åned as v(o;r) =(
r; ifj^Ej=K r+^Q^y(o;a;^)otherwise(9) fora= arg max a2Sn^EQ^y(o;a;).
In the above equation, ^Q(;^)is the target net- work in DDQN, Q^ydenotes the Q-value of ^yfor ^ythe predicted label in o,^Eis the predicted ev- idence ino, and2[0;1]is a hyper-parameter representing the discount factor.
We use the Huber loss to minimise : L=1 jBjX ((o(t);a(t);o(t+1));r(t))2BL() (10) L() =8 >< >:1 22ifjj1 jj 1 2otherwise(11) whereBis a batch of transition-reward pairs.
3.4 Algorithms 3.4.1 Model Training Algorithm 1 shows how to train the DQN-based model.
First, we initialize three replay memories, the DQN-based model, and the target network in Line 1-3.
Then, in Line 9-17, we obtain the training
1034Algorithm 1: Model training for DQN, where the memory capacity M, the max- imum evidence size K, the maximum num- ber of epochs Tand the reset interval Care hyper-parameters.
1initialize a replay memory with a capacity Mfor each label:R^y=;;8^y2fT;F;Ng.
2initialize DQN Q(o;a;)with random weights .
3initialize the target network ^Q(o;a;^)with ^=. 4fore= 1!Tdo 5 shufÔ¨Çe the training set D. 6 foreach (c;y;E;S)2D do 7 initialize one state for each label: o(0) ^y= (c;^E(0);^y);8^y2fT;F;Ng, where ^E(0)=;. 8 fort= 0!K 1do 9 foreach ^y2fT;F;Ngdo 10 ifrandom ()<-greedy then 11 a(t)= random select (Sn^E(t)),
where ^E(t)comes fromo(t) ^y.
12 else 13 a(t)= arg max a2Sn^E(t)Q^y(o(t) ^y;a;), whereQ()is deÔ¨Åned in Eq.
(7) andQ^ydenotes the Q-value of ^y.
14 end 15 o(t+1) ^y
= (c;^E(t+1);^y), where ^E(t+1)=^E(t)[fa(t)gand ^E(t)comes fromo(t) ^y.
16 calculater(t)based on Eq.
(2).
17 store ((o(t) ^y;a(t);o(t+1) ^y);r(t)) intoRy.
18 end 19 sample a mini-batch of transition-reward pairs from RT,RF, RNand updateQ(o;a;)based on Eq.
(8)‚Äì(11).
20 for everyCsteps reset the target network ^Q(o;a;^)by^=. 21 endfor 22 end 23endfor 24returnQ(o;a;) transition-reward pairs by letting the DQN-based model interact with the environment in an -greedy exploration-exploitation way (Mnih et al., 2015).
Finally, in Line 19, we sample a mini-batch of transition-reward pairs to update the DQN-based model, while in Line 20, for every Csteps we reset the target network to the DQN-based model.
3.4.2 Candidate Retrieval Algorithm 2 shows how to retrieve a pair (candi- date list, score list) for each label, where the can-Algorithm 2: Candidate retrieval for a claimcfrom a setSof sentences, where K is the maximum evidence size.
1initialize ^E^y=
[];q^y= [];8^y2fT;F;Ng. 2initialize one state for each label: o(0) ^y= (c;^E(0);^y);8^y2fT;F;Ng, where ^E(0)=;.
3fort= 0!K 1do
4 foreach ^y2fT;F;Ngdo 5a(t)= arg max a2Sn^E(t)Q^y(o(t) ^y;a;) 6q(t)=Q^y(o(t) ^y;a(t)) 7o(t+1) ^y
= (c;^E(t+1);^y), where ^E(t+1)=^E(t)[fa(t)gand^E(t)comes fromo(t) ^y.
8 store ^E(t+1)into^E^yandq(t)intoq^y.
9 end 10endfor 11returnn (^E^y;q^y)o ^y2fT;F;Ng Algorithm 3: Making Ô¨Ånal prediction fromn (h^E(1) ^y;:::; ^E(K) ^yi;hq(0) ^y;:::;q(K 1) ^yi)o ^y2fT,F ,Ng, using thresholds T;F;Nfor different labels.
1letty= arg max 0tK 1q(t) y;8y2fT;F;Ng.
2let^E=^E(t^y+1) ^y , where ^y= arg max y2fT;Fgq(ty) y. 3ifq(tN) N>maxfq(tT) T;q(tF)
Fgand min 0tK 1q(t) N max ^y2fT;Fgq(t^y)
^y> Nthen 4 ^y0=N 5else ifq(tT)
T>q(tF)
Fthen 6 ifq(tT) T max ^y2fF;Ngq(tT)
^y> Tthen ^y0=T; 7 else ^y0=N; 8else 9 ifq(tF) F max ^y2fT;Ngq(tF)
^y> Fthen ^y0=F; 10 else ^y0=N; 11end 12return (^E;^y0) didate list stores progressively enlarged sentence sets, where each sentence set is a candidate of the predicted evidence, and the score list stores the strengths that the corresponding candidates support the label.
We enlarge the two-list pair for each label through a greedy-search way (Line 3-10).
SpeciÔ¨Å- cally, for each label, we Ô¨Årst select the action with the largest Q-value (Line 5), then update the state by adding the chosen action into its predicted ev- idence (Line 7), and Ô¨Ånally add the evidence and score into the corresponding list (Line 8).
1035Algorithm 4: Searching for best thresholds, where minq^yis short for mintq(t) ^yand maxq^yformax tq(t) ^y, for all ^y2fT;F;Ng.
1constructV=f(qT;qF;qN;y)gfrom the development set by Algorithm 2. 2initializeC^y
=L^y=L0
^y=
[];8^y2fT;F;Ng. 3foreach (qT;qF;qN;y)2Vdo 4 ifmaxqN>maxfmaxqT;maxqFgthen 5v= minqN maxfmaxqT;maxqFg 6 storevintoLNand(v;y)intoCN.
7 end 8end 9sortLNin ascending order.
10calculate the medians of adjacent values in LNand store them into L0 N. 11N= arg max 2L0 NX (v;y)2CN1((v>^y=N)_(v ^y6=N))
12foreach (qT;qF;qN;y)2Vdo 13 ifmaxqNmaxfmaxqT;maxqFgor minqN maxfmaxqT;maxqFgNthen 14t^y= arg max tq(t) ^y;8^y2fT;Fg 15 ifq(tT)
T>q(tF)
Fthen 16 v=q(tT) T maxfq(tT) F;q(tT)
Ng 17 storevintoLTand(v;y)intoCT.
18 else 19 v=q(tF) F maxfq(tF) T;q(tF)
Ng 20 storevintoLFand(v;y)intoCF.
21 end 22 end 23end 24foreach ^y2fT;Fgdo 25 sortL^yin ascending order.
26 calculate the medians of adjacent values in L^y and store them into L0 ^y.
27^y= arg max 2L0 ^yX
(v;y)2C^y1(v>^y= ^y)  1(v>^y=N) 28end 29return (T;F;N) 3.4.3 Final Prediction Algorithm 3 shows how to compute the target evidence-label pair from the (candidate list, score list) pairs obtained by Algorithm 2, where the thresholds are determined by Algorithm 4.
In this algorithm, we Ô¨Årst use the condition given by Al- gorithm 4 to predict N(Line 3), and then reÔ¨Åne the prediction of T(Line 6) and F(Line 9) in turn.
In Line 2, we focus on the evidences with the highest score for TandF, while we ignore the evidence forN, due to the following reasons: (1) there are no supporting sentences in the evidence for N; (2) we follow a strategy commonly used in existing methods for FV , i.e., focusing only on the evidence forTandF.Split SUPPORTS REFUTES NEI Train 80,035 29,775 35,639 Dev 6,666 6,666 6,666 Test 6,666 6,666 6,666 Table 1: Dataset statistics for FEVER 3.4.4 Threshold Searching Algorithm 4 shows how to search for the best thresholds ( T;F;N) to maximize the Label Accuracy (LA) over the development set.
We Ô¨Årst call Algorithm 2 to construct a set of tu-
ples(qT;qF;qN;y)from the development set, each of which corresponds to a development instance, whereqT,qFandqNare respectively the output score lists for the three labels T, F andN, andyis the corresponding true label (Line 1).
We then go through the following two stages.
The Ô¨Årst stage (Line 3-11) Ô¨Ånds a threshold Nthat can maximize LA for label N, where maximizing LA is amount to maximizing the difference between the number of correctly and incorrectly predicted instances.
The second stage (Line 12-28) Ô¨Ånds the thresholds T andFthat can maximize LA for label TandF, respectively, where those instances that satisfy the conditions for Nare neglected (Line 13).
4 Experiments 4.1 Experimental setting 4.1.1 Dataset Our experiments are conducted on the large-scale benchmark dataset FEVER (Thorne et al., 2018a), which consists of 185,455 annotated claims with a set of 5,416,537 Wikipedia documents from the June 2017 Wikipedia dump.
All claims are la- beled as ‚ÄúSUPPORTS‚Äù, ‚ÄúREFUTES‚Äù, or ‚ÄúNOT ENOUGH INFO‚Äù.
What‚Äôs more, each claim for ‚ÄúSUPPORTS‚Äù and ‚ÄúREFUTES‚Äù is accompanied by some evidences extracted from Wikipedia docu- ments.
The dataset partition is kept the same with Thorne et
al. (2018b) as shown in Table 1. 4.1.2 Evaluation Metrics
The task has Ô¨Åve evaluation metrics: 1) FEVER, the primary scoring metric that measures the accuracy of claim veriÔ¨Åcation with a requirement that the predicted evidences fully covers the ground-true evidences for SUPPORTS and REFUTES claims; 2) Label Accuracy (LA), the accuracy of claim veriÔ¨Åcation without considering the validity of the
1036Method T F N T-T -1.23361155390739 -1.26671668887138
0.0153777748346328 T-A -0.0631487071514129 0.0747150778770446 -1.48811344802379
BiLSTM-T 0.184351719915866 -0.64785711467266 -0.465365642681717
BiLSTM-A -0.0904324240982532 -0.795884847640991 -0.403448916971683
Table 2: The thresholds determined by Algo- rithm 4. T-T, T-A, BiLSTM-T, and BiLSTM-A de- note the architectures of the evidence encoding mod- ule, which are respectively Transformer-Transformer, Transformer-Attention, BiLSTM-Transformer, and BiLSTM-Attention.
predicted evidences; 3) Precision (Pre), the macro- precision of the evidences for SUPPORTS and RE- FUTES claims; 4) Recall, the macro-recall of the evidences for SUPPORTS and REFUTES claims; 5) F1, the F 1-score of the evidences for SUPPORTS and REFUTES claims.
We choose F1 as our main metric because it can directly show the perfor- mance of methods on retrieval of precise evidences.
4.1.3 Implementation Details Document retrieval .
The document retrieval stage is kept the same as previous work (Hanselowski et al., 2018; Zhou et
al., 2019; Liu et al., 2020; Ye et al., 2020).
Given a claim, the method Ô¨Årst utilizes the constituency parser from AllenNLP (Gardner et al., 2018) to extract potential entities from the claim.
Then it uses the entities as search queries to Ô¨Ånd the relevant documents via the online Me- diaWiki API2.
The convinced articles are reserved (Hanselowski et al., 2018).
Sentence selection and claim veriÔ¨Åcation .
We implement our DQN-based model with PyTorch and train it with the AdamW (Loshchilov and Hut- ter, 2019) optimizer while keeping the sentence en- coding module frozen and inheriting the RoBERTa implementation from Wolf et al.
(2020)3. Specif-
ically, the learning rate is 5e-6, the batch size is 128, the training epochs is 30, the iteration steps (or largest evidence size, i.e.,K) is 5, the discount factoris 0.95, and the layer number of the con- text sub-module is 3.
Prioritized experience replay memory (Schaul et al., 2016) with a capacity of 10,000 is used to store transitions.
The target net- work is reset when DQN is updated every 10 times.
The probability of -greedy policy starts at 0.9 and decays exponentially towards 0.05, and the rate of the decay is1 2000.
Table 2 shows the thresholds 2https://www.mediawiki.org/wiki/API: Main_page 3https://github.com/huggingface/ pytorch-transformersT;FandNcomputed by Algorithm 4.
All ex- periments were conducted on an NVIDIA GTX 2080ti 10GB GPU.
4.1.4
Baselines We compare our method with the following base- lines, including six methods that focus on claim veriÔ¨Åcation and one joint method TwoWingOS (Yin and Roth, 2018).
The six methods include: (1)GEAR (Zhou et al., 2019) uses two kinds of attentions to conduct reasoning and aggregation in a graph model; (2) KGAT (Liu et al., 2020)
employes the Kernel Graph Attention Network to capture Ô¨Åne-grained information over evidences for more accurate claim veriÔ¨Åcation; (3) DREAM (Zhong et al., 2020) introduces semantic structures for evidences obtained by semantic role labeling in claim veriÔ¨Åcation; (4) CorefBERT (Ye et al., 2020) extends KGAT and can explicitly model co-reference relationship in context; (5) HESM (Subramanian and Lee, 2020) is a framework that can encode and attend the claim and evidence sets at different levels of hierarchy; (6) DGAT (Wang et al., 2020) is a double graph attention network that performs well in multi-domain datasets.
The join method TwoWingOS (Yin and Roth, 2018) exploits a two-wing optimization strategy that opti- mizes sentence selection and claim veriÔ¨Åcation in a jointly supervised training scheme.
4.2 Results and Analysis As shown in Table 3, we implement four versions of the evidence encoding module and evaluate them on the DEV set and the blind TEST set.
The FEVER metric of the top six methods is calculated with the imprecise evidences, so we introduce the FEVER@5 metric for a fair comparison.
We ana- lyze our method from the following four aspects.
Comparison with the state-of-the-art methods .
Results in Table 3 show that all versions (except BiLSTM-A) with post-processing signiÔ¨Åcantly out- perform the state-of-the-art methods on FEVER, Pre, and F1, especially for T-A on F1, which shows the superiority of our method in retrival of pre- cise evidences.
However, none of the four ver- sions of our method can achieve the best result on FEVER@5, LA, and Recall.
The reason for low recall is that the number of sentences in precise evidences is less than that in imprecise evidences, which means other methods have a higher proba- bility to recall the ground-true evidences than ours.
Besides, the relatively low LA is caused by the
1037MethodDEV
TEST FEVER@5 FEVER LA Pre Recall F1 FEVER@5
FEVER LA Pre Recall F1 GEAR 70.69 - 74.84 24.08 86.72 37.69 67.10 - 71.60 - - 36.87 KGAT 76.11 - 78.29 27.79 94.37 42.34 70.38 - 74.07 25.21 87.47 39.14 DREAM - - - 26.60 87.33 40.79 70.60 - 76.85 25.63 85.57 39.45 CorefBERT - - - - - - 71.80 - - - - 39.14 HESM 73.44 - 75.77 - - - 71.48 - 74.64 - - 52.78 DGAT - - - - - - 66.91 - 71.79 - - - TwoWingOS - 56.16 78.90 47.73 53.81 50.59 - 54.33 75.99 44.68 49.91 47.15 OursT-T 72.83 71.55 78.1850.42 81.82 62.3970.16 68.91 75.7448.76 79.91 60.56(w./o.) 72.90 70.00 74.87 70.43 68.23 73.13 T-A 73.32 72.79 78.3554.75 79.92 64.9870.81 70.28 76.1452.24 77.93 62.55(w./o.) 73.29 72.60 78.12 70.82 70.18 76.00 BiLSTM-T 73.15 63.77 73.9148.06 71.06 57.3470.54 61.51 70.2045.97 69.43 55.32(w./o.) 73.19 55.39 63.55 70.81 53.21 61.68 BiLSTM-A 72.99 70.88 77.7935.50 76.54 48.5070.11 68.21 75.5333.76 74.50 46.46(w./o.) 73.20 65.65 71.21 70.55 63.38 69.32 Table 3: Performance on DEV set and blind TEST set of FEVER (%).
FEVER@5 and FEVER are computed based on imprecise and precise evidences, repectively.
The result obtained with/without post-processing (namely threshold searching and Ô¨Ånal prediction)
is displayed in each architecture‚Äôs Ô¨Årst/second row (‚Äúw.‚Äù/‚Äúo.‚Äù).
We directly output the evidence with the highest score in the candidate list and its corresponding label if post-processing is not performed.
Pre, Recall, and F1 keep unchanged because they are not affected by the post-processing.
‚Äò-‚Äô denotes a missing value.
# T-T T-A BiLSTM-T BiLSTM-A KGAT LA 78.18 78.35 73.91 77.79 78.29 LA* 82.82 82.48 84.93 83.95 79.08 Table 4: Comparison between our method and KGAT on LA (%).
LA and LA* are respectively evaluated on the DEV set and its subset constructed by selecting the samples where the ground-true evidences are success- fully recalled.
Method Avg.
Std.
Three-stage pipeline 4.00 0.07 Our method (T-A) 1.07 0.89 Table 5: Comparison of the number of unnecessary sen- tences in predicted evidences.
low Recall of precise evidences.
To further clarify this point, we evaluate our method on a subset of the DEV set where the ground-true evidences are recalled successfully.
Our method improves signif- icantly the performance on this subset, as shown in Table 4, which justiÔ¨Åes our point of view.
FEVER is affected by the LA and Recall, thereby the low FEVER@5 is also due to the low recall of precise evidences.
In addition, the results reported in Ta- ble 5 show that our method can signiÔ¨Åcantly reduce the number of unnecessary sentences in a predicted evidence.
Comparison between different versions .
As shown in Table 3, T-T and T-A perform respec- tively better than BiLSTM-T and BiLSTM-A on almost all metrics except that T-T is slightly worsewidth FEVER@5 FEVER LA Pre Recall F1 1 60.73 54.91 72.6952.76 58.57 55.51(w./o.) 50.09 46.55 53.00 2 60.74 54.94 72.6952.84 58.66 55.59(w./o.)
50.09 46.53 53.00 3 60.70 54.96 72.6952.84 58.67 55.60(w./o.) 50.10 46.54 53.00 4 60.67 54.95 72.6952.81 58.66 55.58(w./o.) 50.09 46.54 53.00 5 60.68 54.95 72.6952.84 58.68 55.61(w./o.)
50.09 46.54 53.00 Table 6: The beam-search result of KGAT on the DEV set (%).
The width ( k) means to select the top- kresults at each search step.
The result obtained with/without post-processing (namely threshold searching and Ô¨Ånal prediction)
is displayed in each width‚Äôs Ô¨Årst/second row (‚Äúw.‚Äù/‚Äúo.‚Äù).
We employed the KGAT source code re- leased by Liu et al.
(2020) to implement beam-search for Ô¨Ånding precise evidences and the evaluation data for KGAT was kept the same as ours.
than BiLSTM-A on FEVER@5, which suggests Transformer can encode better context-aware repre- sentations than BiLSTM in our context sub-module.
Moreover, we Ô¨Ånd that T-A performs better than T-T on almost all metrics except Recall and that BiLSTM-A is worse than BiLSTM-T on Pre and F1.
This contrary result shows that the performance of the aggregation sub-module is impacted by the context sub-module.
Thus, the choice between Transformer and Attention should depend on the context sub-module.
Overall, T-A achieves the best performance among all the four versions of our
1038# label claim ground-true evidencespredicted evidences GEAR KGAT
Our method (T-A) 1 FSavages was exclusively a German Ô¨Ålm.(Savages(2012 Ô¨Ålm), 3) (Savages(2012 Ô¨Ålm), 3) (Savages(2012 Ô¨Ålm), 3) (Savages(2012 Ô¨Ålm), 3) (Savages(band), 0) (Savages(2012 Ô¨Ålm), 6) (Savages(2012 Ô¨Ålm), 6) (Savages(2012 Ô¨Ålm), 0) (Savages(band), 2) (Savages(band), 5) (Savages(band), 4) (Savages(band), 0) 2 TEd Gein murdered people around PlainÔ¨Åeld, Wisconsin.(Ed Gein, 2) (Ed Gein, 1) (Ed Gein, 1) (Ed Gein, 2) (Ed Gein, 1) (Ed Gein, 0) (Ed Gein, 2) (Ed Gein, 1) (Ed Gein, 6) (Ed Gein, 0) (Ed Gein, 2) (Ed Gein(band), 2) (Ed Gein, 5) (Ed Gein, 4) 3 TMarnie is a Ô¨Ålm that was created in the United States.(Marnie(Ô¨Ålm), 0) (Marnie(Ô¨Ålm), 0) (Marnie(Ô¨Ålm), 0) (Marnie(Ô¨Ålm), 0) (Marnie, 0) (Marnie, 0) (Marnie(Ô¨Ålm), 5) (Marnie(Ô¨Ålm), 2) (Marnie(Ô¨Ålm), 2) (Marnie(Ô¨Ålm), 6) (Marnie(Ô¨Ålm), 6) (Marnie(dis...tion), 12) (Marnie(Ô¨Ålm), 5) 4 FFirst Motion Picture Unit produced zero Ô¨Ålms.(First ... Unit, 1) (First ... Unit, 0) (First ... Unit, 1) (First ... Unit, 1) (First ... Unit, 4) (First ... Unit, 4) (First ... Unit, 4) (First ... Unit, 4) (First ... Unit, 0) (First ... Unit, 1) (First ... Unit, 0) (First ... Unit, 0) (Zero(2016 Ô¨Ålm), 0) (First ... Unit, 2) (First ... Unit, 2) (First ... Unit, 8) (Zero(2016 Ô¨Ålm), 0) Table 7: Cases in FEVER.
We list the predicted evidences of GEAR, KGAT and our method.
(title, i) de- notes thei-th sentence in the corresponding wiki document.
In predicted evidences, the sentences highlighted inblue bold italics and underline are sentences in the target evidence while others in black are unnecessary ones.
proposed method.
Comparison on retrieval of precise evidences .
TwoWingOS is a supervised-learning method that can also Ô¨Ånd precise evidences.
Although it achieves slightly better performance on LA than ours, its F1 and other metrics are much worse, in- dicating that it performs worse than our method except for BiLSTM-A in retrieval of precise- evidences.
We also enhance KGAT to conduct beam-search for Ô¨Ånding precise evidences and re- port the results in Table 6.
The F1 score of KGAT is always higher than TwoWingOS but is still lower than our method except for BiLSTM-A. Comparison between the methods with and without post-processing .
It can be seen from Ta- ble 3 and Table 6 that, post-processing (namely threshold searching and Ô¨Ånal prediction from can- didates) consistently improves FEVER and LA.
Al- though with post-processing, our method (except T-A) achieves slightly lower scores on FEVER@5, KGAT still achieves signiÔ¨Åcantly higher scores on FEVER@5 as on other metrics.
These results show that post processing is very important in retrieval of precise evidences.
4.3 Case Study In Table 7 we provide some cases to demonstrate the effectiveness of our method (T-A) in retriev- ing precise evidences.
In case#1 and case#2, our method exactly Ô¨Ånds ground-true evidences with- out introducing any unnecessary sentence, whileGEAT and KGAT cannot.
In case#3 and case#4, our method generates less unnessary sentences in prdicted evidents than GEAT and KGAT do.
5 Conclusion and Future Work
In this paper, we have proposed a novel DQN-based approach to Ô¨Ånding precise evidences for fact veri- Ô¨Åcation.
It provides a method to solve the precise- evidence problem by Ô¨Årst employing a DQN to compute some candidates and then introducing a post-processing strategy to extract the target evi- dence and its label from the candidates.
Exper-
imental results show that the approach achieves state-of-the-art performance in terms of retrieval of precise evidences.
Besides, to the best of our knowledge, it is the Ô¨Årst attempt to employ DQN in the fact veriÔ¨Åcation task.
Future work will incorporate external knowledge into our approach to improve the retrieval recall.
Acknowledgments This work is supported by the Guangdong Province Science and Technology Plan projects (2017B010110011), the National Natural Science Foundation of China (No. 61876204, 61976232, and 51978675), the National Key R&D Pro- gram of China (No.2018YFC0830600), Guang-
dong Province Natural Science Foundation (No. 2018A030313086), All-China Federation of Re- turned Over-seas Chinese Research Project (No. 17BZQK216).
1039References LiChun Cao and ZhiMin.
2019.
An overview of deep reinforcement learning.
In CACRE , pages 17:1‚Äì 17:9.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.
BERT: pre-training of deep bidirectional transformers for language under- standing.
In NAACL-HLT , pages 4171‚Äì4186.
Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson F. Liu, Matthew E. Peters, Michael Schmitz, and Luke Zettlemoyer.
2018.
Allennlp:
A deep semantic natural language processing platform.
In NLP-OSS Workshop , pages 1‚Äì6.
Andreas Hanselowski, Hao Zhang, Zile Li, Daniil Sorokin, Benjamin Schiller, Claudia Schulz, and Iryna Gurevych.
2018.
UKP-athene: Multi-sentence textual entailment for claim veriÔ¨Åcation.
In FEVER , pages 103‚Äì108.
Tianda Li, Xiaodan Zhu, Quan Liu, Qian Chen, Zhi- gang Chen, and Si Wei. 2019.
Several experi- ments on investigating pretraining and knowledge- enhanced models for natural language inference.
CoRR , abs/1904.12104.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man- dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
2019.
Roberta: A robustly optimized BERT pretraining ap- proach.
CoRR , abs/1907.11692.
Zhenghao Liu, Chenyan Xiong, Maosong Sun, and Zhiyuan Liu. 2020.
Fine-grained fact veriÔ¨Åcation with kernel graph attention network.
In ACL, pages 7342‚Äì7351.
Ilya Loshchilov and Frank Hutter.
2019.
Decoupled weight decay regularization.
In ICLR .
V olodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A. Rusu, Joel Veness, Marc G. Bellemare, Alex Graves, Martin A. Riedmiller, Andreas Fid- jeland, Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, and Demis Hassabis.
2015.
Human-level con- trol through deep reinforcement learning.
Nature , 518(7540):529‚Äì533.
Ngoc-Khuong Nguyen, Anh-Cuong Le, and Hong Thai Pham.
2016.
Deep bi-directional long short-term memory neural networks for sentiment analysis of social data.
In IUKM , volume 9978, pages 255‚Äì268.
Yixin Nie, Haonan Chen, and Mohit Bansal.
2019.
Combining fact extraction and veriÔ¨Åcation with neu- ral semantic matching networks.
In AAAI , pages 6859‚Äì6866.
Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver. 2016.
Prioritized experience replay.
InICLR .Amir
Soleimani, Christof Monz, and Marcel Worring.
2020.
BERT for evidence retrieval and claim veriÔ¨Å- cation.
In ECIR , volume 12036, pages 359‚Äì366.
Shyam Subramanian and Kyumin Lee.
2020.
Hierar- chical evidence set modeling for automated fact ex- traction and veriÔ¨Åcation.
In EMNLP , pages 7798‚Äì 7809.
James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal.
2018a.
FEVER: a large-scale dataset for fact extraction and veriÔ¨Åcation.
In NAACL-HLT , pages 809‚Äì819.
James Thorne, Andreas Vlachos, Oana Cocarascu, Christos Christodoulopoulos, and Arpit Mittal.
2018b.
The fact extraction and VERiÔ¨Åcation (FEVER) shared task.
In FEVER , pages 1‚Äì9.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.
Attention is all you need.
In NeurIPS , pages 5998‚Äì6008.
Yongyue Wang, Chunhe Xia, Chengxiang Si, Beitong Yao, and Tianbo Wang.
2020.
Robust reasoning over heterogeneous textual information for fact veriÔ¨Åca- tion.
IEEE Access , 8:157140‚Äì157150.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pier- ric Cistac, Tim Rault, R ¬¥emi Louf, Morgan Funtow- icz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush.
2020.
Transformers: State-of-the-art natural language pro- cessing.
In EMNLP , pages 38‚Äì45.
Deming Ye, Yankai Lin, Jiaju Du, Zhenghao Liu, Peng Li, Maosong Sun, and Zhiyuan Liu. 2020.
Coref- erential reasoning learning for language representa- tion.
In EMNLP , pages 7170‚Äì7186.
Wenpeng Yin and Dan Roth.
2018.
Twowingos: A two- wing optimization strategy for evidential claim veri- Ô¨Åcation.
In EMNLP , pages 105‚Äì114.
Takuma Yoneda, Jeff Mitchell, Johannes Welbl, Pon- tus Stenetorp, and Sebastian Riedel.
2018.
UCL ma- chine reading group: Four factor framework for fact Ô¨Ånding (HexaF).
In FEVER , pages 97‚Äì102.
Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai Wang, and Jian Yin.
2020.
Reasoning over semantic-level graph for fact checking.
In ACL, pages 6170‚Äì6180.
Jie Zhou, Xu Han, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun. 2019.
GEAR: graph-based evidence aggregating and rea- soning for fact veriÔ¨Åcation.
In ACL, pages 892‚Äì901.
