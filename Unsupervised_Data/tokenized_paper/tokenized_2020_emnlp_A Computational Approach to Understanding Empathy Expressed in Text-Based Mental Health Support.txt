Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing , pages 5263–5276 , November 16–20 , 2020 . 
c 
2020 Association for Computational Linguistics5263A Computational Approach to Understanding Empathy Expressed in Text - Based Mental Health Support WARNING : This paper contains content related to suicide and self - harm . 
Ashish SharmaAdam S. Miner|~David C. Atkins}Tim Althoff Paul G. Allen School of Computer Science & Engineering , University of Washington |Department of Psychiatry and Behavioral Sciences , Stanford University ~Center for Biomedical Informatics Research , Stanford University } Department of Psychiatry and Behavioral Sciences , University of Washington fashshar , althoff g@cs.washington.edu 
asmpsyd@stanford.edu 
datkins@uw.edu 
Abstract Empathy is critical to successful mental health support . 
Empathy measurement has pre- dominantly occurred in synchronous , face - to- face settings , and may not translate to asyn- chronous , text - based contexts . 
Because mil- lions of people use text - based platforms for mental health support , understanding empa- thy in these contexts is crucial . 
In this work , we present a computational approach to un- derstanding how empathy is expressed in on- line mental health platforms . 
We develop a novel unifying theoretically - grounded frame- work for characterizing the communication of empathy in text - based conversations . 
We collect and share a corpus of 10k ( post , re- sponse ) pairs annotated using this empathy framework with supporting evidence for anno- tations ( rationales ) . 
We develop a multi - task RoBERTa - based bi - encoder model for identi- fying empathy in conversations and extracting rationales underlying its predictions . 
Experi- ments demonstrate that our approach can ef- fectively identify empathic conversations . 
We further apply this model to analyze 235k men- tal health interactions and show that users do not self - learn empathy over time , revealing op- portunities for empathy training and feedback . 
1 Introduction Approximately 20 % of people worldwide are suf- fering from a mental health disorder ( Holmes et al . , 2018 ) . 
Still , access to mental health care re- 
mains a global challenge with widespread short- ages of workforce ( Olfson , 2016 ) . 
Facing limited in - person treatment options and other barriers like stigma ( White and Dorman , 2001 ) , millions of peo- ple are turning to text - based peer support platforms such as TalkLife ( talklife.co ) to express emo- tions , share stigmatized experiences , and receive peer support ( Eysenbach et al . , 2004 ) . 
However , while peer supporters on these platforms are moti- vated and well - intentioned to help others seeking Figure 1 : Our framework of empathic conversations contains three empathy communication mechanisms – Emotional Reactions , Interpretations , and Explo- rations . 
We differentiate between no communication , weak communication , and strong communication of these factors . 
Our computational approach simultane- ously identiﬁes these mechanisms and the underlying rationale phrases ( highlighted portions ) . 
All examples in this paper have been anonymized using best prac- tices in privacy and security ( Matthews et al . , 2017 ) . 
support ( henceforth seeker ) , they are untrained and typically unaware of best - practices in therapy . 
In therapy , interacting empathically with seek- ers is fundamental to success ( Bohart et al . , 2002 ; Elliott et al . , 2018 ) . 
The lack of training or feed- back to layperson peer supporters results in missed opportunities to offer empathic textual responses . 
NLP systems that understand conversational empa- thy could empower peer supporters with feedback and training . 
However , the current understanding of empathy is limited to traditional face - to - face , speech - based therapy ( Gibson et al . , 2016 ; P ´ erez- Rosas et 
al . , 2017 ) due to lack of resources and methods for new asynchronous , text - based inter- 
5264actions ( Patel et al . , 2019 ) . 
Also , while previous NLP research has focused predominantly on em- pathy as reacting with emotions of warmth and compassion ( Buechel et al . , 2018 ) , a separate but key aspect of empathy is to communicate a cogni- tive understanding of others ( Selman , 1980 ) . 
In this work , we present a novel computational approach to understanding how empathy is ex- pressed in text - based , asynchronous mental health conversations . 
We introduce EPITOME , 1a concep- tual framework for characterizing communication of empathy in conversations that synthesizes and adapts the most prominent empathy scales from speech - based , face - to - face contexts to text - based , asynchronous contexts ( x3).EPITOME consists of three communication mechanisms of empathy : Emotional Reactions , Interpretations , and Explo- rations ( Fig . 1 ) . 
To facilitate computational modeling of empathy in text , we create a new corpus based on EPITOME . 
We collect annotations on a dataset of 10k ( post , response ) pairs from extensively - trained crowd- workers with high inter - rater reliability ( x4).2We develop a RoBERTa - based bi - encoder model for identifying empathy communication mechanisms in conversations ( x5 ) . 
Our multi - task model simul- taneously extracts the underlying supportive evi- dences , rationales ( DeYoung et al . , 2020 ) , for its predictions ( spans of input post ; e.g. , highlighted portions in Fig . 
1 ) which serve the dual role of ( 1 ) explaining the model ’s decisions , thus minimizing the risk of deploying harmful technologies in sensi- tive contexts , and ( 2 ) enabling rationale - augmented feedback for peer supporters . 
We show that our computational approach can effectively identify empathic conversations with underlying rationales ( 80 % acc . 
, 70 % macro- f1 ) and outperforms popular NLP baselines with a 4 - point gain in macro - f1 ( x6 ) . 
We apply our model to a dataset of 235k supportive conversa- tions on TalkLife and demonstrate that empathy is associated with positive feedback from seekers and the forming of relationships . 
Importantly , our results suggest that most peer supporters do not self - learn empathy with time . 
This points to criti- cal opportunities for training and feedback for peer supporters to increase the effectiveness of men- tal health support ( Miner et al . , 2019 ; Imel et al . , 1EmPathy InText - based , asynchr Onous MEntal health conversations 2Our dataset can be accessed from https://bit.ly/ 2Rwy2gx .2015 ) . 
Speciﬁcally , NLP - based tools could give ac- tionable , real - time feedback to improve expressed empathy , and we demonstrate this idea in a small- scale proof - of - concept ( x7 ) . 
2 Background 2.1 How to measure empathy ? 
Empathy is a complex multi - dimensional construct with two broad aspects related to emotion and cog- nition ( Davis et al . , 1980 ) . 
The “ emotion ” aspect relates to the emotional stimulation in reaction to the experiences and feelings expressed by a user . 
The “ cognition ” aspect is a more deliberate process of understanding and interpreting the experiences and feelings of the user and communicating that understanding to them ( Elliott et al . , 2018 ) . 
Here , we study expressed empathy in text - based mental health support – empathy expressed orcom- municated by peer supporters in their textual inter- actions with seekers ( cf . 
Barrett - Lennard ( 1981)).3 Table 1 lists existing empathy scales in psychology and psychotherapy research . 
Truax and Carkhuff ( 1967 ) focus only on communicating cognitive un- derstanding of others while Davis et al . 
( 1980 ) ; 
Watson et al . 
( 2002 ) also make use of expressing stimulated emotions . 
These scales , however , have been designed for in - person interactions and face - to - face therapy , of- ten leveraging audio - visual signals like expressive voice . 
In contrast , in text - based support , empathy must be expressed using textual response alone . 
Also , they are designed to operate on long , syn- chronous conversations and are unsuited for the shorter , asynchronous conversations of our context . 
In this work , we adapt these scales to text - based , asynchronous support . 
We develop a new compre- hensive framework for text - based , asynchronous conversations ( Table 1 ; x3 ) , use it to create a new dataset of empathic conversations ( x4 ) , a computa- tional approach for identifying empathy ( x5;x6 ) , & gaining insights into mental health platforms ( x7 ) . 
2.2 Computational Approaches for Empathy Computational research on empathy is based on speech - based settings , exploiting audio signals 3Note that expressed empathy may differ from the empathy perceived by seekers . 
However , obtaining perceived empathy ratings from seekers is challenging in sensitive contexts and in- volves ethical risks . 
Psychotherapy research indicates a strong correlation of expressed empathy with positive outcomes and frequently uses it as a credible alternative ( Robert et al . , 2011 ) . 
5265ContextApplicable to text - based peer - supportCommunication Mechanisms Emotional ReactionsInterpretations ( Cognitive)Explorations ( Cognitive)ScalesTruax and Carkhuff ( 1967 ) Face - to - face therapy 7 7 3 3 Davis et al . 
( 1980 ) 
Daily human interactions 7 3 3 7 Watson et al . 
( 2002 ) Face - to - face therapy 7 3 3 3MethodsBuechel et 
al . 
( 2018 ) Reaction to news stories 7 3 7 7 Rashkin et al . 
( 2019 ) Emotionally grounded convs . 
7 7 * 7 * 7 * P´erez - Rosas et al . 
( 2017 ) 
Motivational interviewing 7 7 3 3 EPITOMEText - based , asynchronous support3 3 3 3 Table 1 : E PITOME incorporates both emotional and cognitive aspects of empathy that were previously only stud- ied in face - to - face therapy and never computationally in text - based , asynchronous conversations . 
* Rashkin et 
al . 
( 2019 ) implicitly enable empathic conversations through grounding in emotions instead of communication . 
like pitch which are unavailable in text - based plat- forms ( Gibson et al . , 2016 ; P ´ erez - Rosas et al . , 2017 ) . 
Moreover , previous NLP research has pre- dominantly focused on empathy as reacting with emotions of warmth and compassion ( Buechel et al . , 2018 ) . 
For mental health support , however , communicating cognitive understanding of feelings and experiences of others is more valued ( Selman , 1980 ) . 
Recent work also suggests that grounding conversations in emotions implicitly makes them empathic ( Rashkin et al . , 2019 ) . 
Research in ther- apy , however , highlights the importance of express- ing empathy in interactions ( Truax and Carkhuff , 1967 ) . 
In this work , we present a computational approach to ( 1 ) understanding empathy expressed in textual , asynchronous conversations ; ( 2 ) address both emotional and cognitive aspects of empathy . 
3 Framework of Expressed Empathy To understand empathy in text - based , asyn- chronous , peer - to - peer support conversations , we develop EPITOME , a new conceptual framework of expressed empathy ( Fig . 1 ) . 
In close collaboration with clinical psychologists , we adapt and synthe- size existing empathy deﬁnitions and scales to text- based , asynchronous context . 
EPITOME consists of three communication mechanisms providing a com- prehensive outlook of empathy – Emotional Reac- tions , Interpretations , and Explorations . 
For each of these mechanisms , we differentiate between – ( 0 ) peers not expressing them at all ( no communi- cation ) , ( 1 ) peers expressing them to some weak degree ( weak communication ) , ( 2 ) peers expressing them strongly ( strong communication ) . 
Here , we describe our framework in detail using the following seeker post as context for all example responses : I am about to have an anxiety attack . 
Emotional Reactions . 
Expressing emotions such as warmth , compassion , and concern , experienced by peer supporter after reading seeker ’s post . 
Ex- pressing these emotions plays an important role in establishing empathic rapport and support ( Robert et al . , 2011 ) . 
A weak communication of emo- tional reactions alludes to these emotions without the emotions being explicitly labeled ( e.g. , Every- thing will be ﬁne ) . 
On the other hand , strong com- munication speciﬁes the experienced emotions ( e.g. , I feel really sad for you ) . 
Interpretations . 
Communicating an understand- ing of feelings and experiences inferred from the seeker ’s post . 
Such a cognitive understanding in responses is helpful in increasing awareness of hid- den feelings and experiences , and essential for de- veloping alliance between the seeker and peer sup- porter ( Watson , 2007 ) . 
A weak communication of interpretations contains a mention of the under- standing ( e.g. , I understand how you feel ) while a strong communication speciﬁes the inferred feel- ing or experience ( e.g. , This must be terrifying ) or communicates understanding through descriptions of similar experiences ( e.g. , I also have anxiety attacks at times which makes me really terriﬁed ) . 
Explorations . 
Improving understanding of the seeker by exploring the feelings and experiences not stated in the post . 
Showing an active inter- est in what the seeker is experiencing and feeling and probing gently is another important aspect of empathy ( Miller et al . , 2003 ; Robert et al . , 2011 ) . 
Aweak exploration is generic ( e.g. , What hap- pened ? ) 
while a strong exploration is speciﬁc and labels the seeker ’s experiences and feelings which the peer supporter wants to explore ( e.g. , Are you feeling alone right now ? ) . 
Consistent with existing scales , responses that 
5266only give advice ( Try talking to friends ) , only pro- vide factual information ( mindful meditation over- comes anxiety ) , or are offensive or abusive ( shut the f**k up ) 4are not empathic and are characterized as no communication of empathy in our framework . 
4 Data Collection To facilitate computational methods for empathy , we collect data based on E PITOME . 
4.1 Data Source We use conversations on the following two online support platforms as our data source : ( 1 ) TalkLife . 
TalkLife ( talklife.co ) is the largest global peer - to - peer mental health support network ( talklife.co/about ) . 
It enables seekers to have textual interactions with peer supporters through conversational threads . 
The dataset con- tains 6.4 M threads and 18 M interactions ( seeker post , response post pairs ) on TalkLife between May 2012 to Jan 2019 . 
( 2 ) Mental Health Subreddits . 
Reddit ( reddit . com ) hosts a number of sub - communities aka sub- reddits ( e.g. , r / depression ) . 
We use threads posted on 55 mental health focused subreddits ( Sharma et al . ( 2018 ) ) . 
This publicly accessible dataset con- tains 1.6 M threads and 8 M interactions on Reddit between Jan 2015 to Jan 2019 . 
We use the entire dataset for in - domain pre- training ( x5 ) and annotate a subset of 10k inter- actions on empathy . 
We further analyze empathy on a carefully ﬁltered dataset of 235k mental health interactions on TalkLife ( x7 ) . 
4.2 Annotation Task and Process Empathy is conceptually nuanced and linguistically diverse so annotating it accurately is difﬁcult in short - term crowdwork approaches . 
This is also reﬂected in prior work that found it challenging to annotate therapeutic constructs ( Lee et al . , 2019 ) . 
To ensure high inter - rater reliability , we designed a novel training - based annotation process . 
Crowdworkers Recruiting and Training . 
We re- cruited and trained eight crowdworkers on identify- ing empathy mechanisms in EPITOME . 
We lever- 
aged Upwork ( upwork.com ) , a freelancing plat- form that allowed us to hire and work interactively with crowdworkers . 
Each crowdworker was trained 4Our approach is focused on supporting peers who are try- ing to help seekers . 
This is different from toxic language iden- tiﬁcation tasks . 
Such content can be independently ﬂagged using existing techniques ( e.g. , perspectiveapi.com ) Data SourceNo Weak Strong Total Emotional ReactionsTalkLife 3656 2945 461 7062 Reddit 2034 899 148 3081 InterpretationsTalkLife 5533 178 1351 7062 Reddit 1645 115 1321 3081 ExplorationsTalkLife 5137 767 1158 7062 Reddit 2600 104 377 3081 Table 2 : Statistics of the collected empathy dataset . 
The crowdworkers were trained on E PITOME through a series of phone calls and manual / automated feedback on sample posts to ensure high quality annotations . 
through a series of phone calls ( 30 minutes to 1 hour in total ) and manual / automated feedback on 50 - 100 posts . 
Refer Appendix A for more details . 
Annotating Empathy . 
In our annotation task , crowdworkers were shown a pair of ( seeker post , response post ) and were asked to identify the pres- ence of the three communication mechanisms in EPITOME ( Emotional Reactions , Interpretations , and Explorations ) , one at a time . 
For each mech- anism , crowdworkers annotated whether the re- sponse post contained no communication , weak communication , or strong communication of empa- thy in the context of the seeker post . 
Highlighting Rationales . 
Along with the categor- ical annotations , crowdworkers were also asked to highlight portions of the response post that formed rationale behind their annotation . 
E.g , in the post “ That must be terrible ! 
I ’m here for you ” , the por- tion “ That must be terrible ” is the rationale for it being a strong communication of interpretations . 
Data Quality . 
Overall , our corpus has an average inter - annotator agreement of 0.6865 ( average over pairwise Cohen ’s of all pairs of crowdworkers ; each pair annotated > 50 posts in common ) which is higher than previously reported values for the an- notation of empathy in face - to - face therapy ( 0.60 in P ´ erez - Rosas et al . , 2017 ; Lord et al . , 2015).5 
Our ground - truth corpus contains 10,143 ( seeker post , response post ) pairs with annotated empathy labels from trained crowdworkers ( Table 2 ) . 
Privacy and Ethics . 
The TalkLife dataset was sourced with license and consent from the TalkLife platform . 
All personally identiﬁable information ( user and platform identiﬁers ) in both the datasets were removed . 
This study was approved by Univer- sity of Washington ’s Institutional Review Board . 
5We achieve an inter - annotator agreement of 0.69 for emo- tional reactions , 0.61 for interpretations , and 0.76 for explo- rations . 
5267In addition , we tried to minimize the risks of an- notating mental health related content by provid- ing crisis management resources to our annotators , following Sap et 
al . ( 2020 ) . 
This work does not make any treatment recommendations or diagnostic claims . 
5 Model With our collected dataset , we develop a computa- tional approach for understanding empathy . 
5.1 Problem Deﬁnition LetSi = si1;:::;s imbe a seeker post and Ri= ri1;:::;r inbe a corresponding response post . 
For the pair ( Si;Ri ) , we want to perform two tasks : Task 1 : Empathy Identiﬁcation . 
Identify how empathic Riis in the context of Si . 
For each of the three communication mechanisms in EPIT- OME ( Emotional Reactions , Interpretations , Explo- rations ) , we want to identify their level of commu- nication ( li ) inRi – no communication ( 0 ) , weak communication ( 1 ) , or strong communication ( 2 ) . 
Task 2 : Rationale Extraction . 
Extract rationales underlying the identiﬁed level li2fno , weak , stronggof each of the three communication mech- anism in EPITOME . 
The extracted rationale is a subsequence of words xiinRi . 
We represent this subsequence as a mask mi= ( mi1;:::;m in)over the words in Ri , wheremij2f0;1gis a boolean variable : 1 – rationale word ; 0 – non - rationale word . 
Correspondingly , xi = mi 
Ri . 5.2 Bi - Encoder Model with Attention We propose a multi - task bi - encoder model based on RoBERTa ( Liu et al . , 2019 ) for identifying empathy and extracting rationales ( Fig . 2 ) . 
We multi - task over the two tasks of empathy identiﬁcation and rationale extraction and train three independent but identical architectures for the three empathy com- munication mechanisms in EPITOME ( x3 ) . 
The bi - encoder architecture ( Humeau et al . , 2019 ) facil- itates a joint modeling of ( Si;Ri)pairs . 
Moreover , the use of attention helps in providing context from the seeker post , Si . 
We ﬁnd that such an approach is more effective than methods that concatenate Si withRiwith a [ SEP ] token to form a single input sequence ( x6 ) . 
Two Encoders . 
Our model uses two inde- pendently pre - trained transformer encoders from RoBERTa BASE – S - Encoder & R - Encoder – for en- coding seeker post and response post respectively . 
Figure 2 : We use two independently pre - trained RoBERTa - based encoders for encoding seeker post and response post respectively . 
We leverage attention be- 
tween them for generating seeker - context aware repre- sentation of the response post , used to perform the two tasks of empathy identiﬁcation and rationale extraction . 
S - Encoder encodes context from the seeker post whereas R - Encoder is responsible for understand- 
ing empathy in the response post . 
e(S ) 
i = S - Encoder ( [ CLS];Si;[SEP ] ) ( 1 ) e(R ) 
i = R - Encoder ( [ CLS];Ri;[SEP ] ) ( 2 ) where [ CLS ] and[SEP ] are special start and end tokens adapted from BERT ( Devlin et al . , 2019 ) . 
Domain - Adaptive Pre - training . 
Both the S- Encoder and R - Encoder are initialized using the weights learned by RoBERTa BASE . 
We further per- form a domain - adaptive pre - training ( Gururangan et al . , 2020 ) of the two encoders to adapt to conver- sational and mental health context . 
For this addi- tional pre - training of the two encoders , we use the datasets of 6.4 M seeker posts ( 182 M tokens ) and 18 M response ( 279 M tokens ) posts respectively sourced from TalkLife ( x4 ) . 
We use the masked language modeling task for pre - training ( 3 epochs , batch size = 8) . 
Attention Layer . 
We use a single - head atten- tion over the two encodings for generating seeker- context aware representation of the response post . 
Using the terminology of transformers ( Vaswani et al . , 2017 ) , our query is the response post encod- inge(R ) i , and the keys and the values are the seeker post encoding e(S ) 
i. 
Our attention is computed as : ai(e(R ) i;e(S ) i ) = softmax   e(R ) ie(S ) ip d ! 
e(S ) 
i(3 ) 
5268ModelEmotional ReactionsInterpretations Explorations acc . 
f1 acc . 
f1 acc . 
f1TalkLifeLog . 
Reg . 58.02 51.58 55.53 41.19 63.23 51.97 RNN 69.09 54.02 82.25 47.94 73.40 28.22 HRED 78.91 48.70 79.26 29.48 73.40 28.22 BERT 76.98 70.31 85.06 62.24 85.87 71.56 GPT-2 76.89 70.76 80.00 58.43 83.25 65.65 DialoGPT 76.71 70.42 85.67 66.60 83.95 66.34 RoBERTa 78.28 71.06 86.25 62.69 85.79 71.83 Our Model 79.93 74.29 87.50 67.46 86.92 73.47RedditLog . 
Reg . 41.69 42.69 70.58 49.77 67.08 46.63 RNN 71.63 42.85 76.21 51.76 85.58 30.74 HRED 71.11 44.10 79.65 54.16 85.58 30.74 BERT 72.13 50.41 82.16 61.20 89.35 56.54 GPT-2 76.69 71.65 82.32 62.27 88.25 58.28 DialoGPT 66.07 51.16 81.85 68.95 89.65 70.65 RoBERTa 76.99 70.35 82.16 61.38 90.58 63.41 Our Model 79.43 74.46 84.04 62.60 92.61 72.58 Table 3 : Empathy identiﬁcation task results . 
We ob- serve substantial gains over baselines with our seeker- context aware , mult - tasking approach . 
whered= 768 ( hidden size in RoBERTa BASE ) . 
We sum the encoded response e(R ) iwith its represen- tation transformed through attention ai(e(R ) 
i;e(S ) i ) to obtain a residual mapping ( He et al . , 2016 ) – h(R ) i , which forms the ﬁnal seeker - context aware representation of the response post . 
Empathy Identiﬁcation . 
For the task of identify- ing empathy , we use the ﬁnal representation of the [ CLS ] token in the response post ( h(R ) i[[CLS ] ] ) and pass it through a linear layer to get the predic- tions of the empathy level ^li(0 , 1 , or 2 ) of each empathy communication mechanism . 
Note that we train three independent models for the three communication mechanisms in E PITOME ( x3 ) . 
Extracting Rationales . 
For extracting ratio- nalesyiunderlying the predictions , we use ﬁ- nal representations of the individual tokens in Ri ( h(R ) i[ri1;:::;r 
in])and pass them through a linear layer for making boolean predictions , ^mi . 
Loss Function . 
We use cross - entropy between the true and predicted labels as the loss functions of our two tasks . 
The overall loss of our multi - task architecture is : L=EILEI+RELRE . 
Experimental Setup . 
We split both datasets into train , dev , and test sets ( 75:5:20 ) . 
We train our model for 4 epochs using a learning rate of 2e 5 , batch size of 32 , EI= 1 , andRE= 0:5(Refer Appendix B for ﬁne - tuning details).ModelEmotional ReactionsInterpretations Explorations T - f1 IOU T - f1 IOU T - f1 IOUTalkLifeLog . 
Reg . 47.44 63.27 46.92 32.97 47.18 62.25 RNN 62.80 58.22 67.26 57.31 63.29 64.65 HRED 60.56 55.01 64.26 70.92 61.54 70.85 BERT 61.29 51.20 61.06 67.33 62.50 64.80 GPT-2 47.39 51.27 64.06 81.12 66.71 78.21 DialoGPT 66.24 61.24 64.05 79.64 57.95 76.95 RoBERTa 59.12 63.82 60.08 84.85 60.05 78.21 Our Model 68.49 66.82 67.81 85.76 64.56 83.19RedditLog . 
Reg . 43.26 61.27 49.85 31.31 48.21 70.36 RNN 45.54 43.94 48.22 51.35 65.11 78.27 HRED 46.34 45.65 48.88 52.12 66.66 80.33 BERT . 
51.06 54.81 48.38 50.75 67.91 71.00 GPT-2 51.44 57.10 54.53 52.38 73.39 82.89 DialoGPT 51.83 49.37 54.43 55.85 73.43 85.20 RoBERTa 51.89 58.31 55.62 54.60 69.76 83.33 Our Model 53.57 64.83 57.40 55.90 71.56 84.48 Table 4 : Rationale extraction task results . 
We evaluate both at the level of tokens ( T - f1 ) and spans ( IOU - f1 ) . 
6 Results Next , we analyze how effectively we can identify empathy with underlying rationales using our com- putational approach . 
6.1 Overall Results We compare the performance of our approach with a range of models popularly used in related tasks ( e.g. , sentiment classiﬁcation , conversation anal- ysis ) . 
We quantify how challenging identifying empathy with underlying rationales is , how well do existing models perform , and what performance is achieved by our proposed approach . 
Baselines . 
Our baselines are : 1.Log . 
reg . 
( logis- tic regression over tf.idf vectors ) ; 
2.RNN ( two- layer recurrent neural network ) ; 3.HRED ( hier- archical recurrent encoder - decoder , often used for modeling conversations ( Sordoni et al . , 2015 ) ) ; 4 . BERT BASE ( Devlin et al . , 2019 ) ; 5.GPT-2 ( typi- cally used for language generation ( Radford et al . , 2019 ) ) ; 6.DialoGPT ( GPT-2 adapted to asyn- chronous conversations ( Zhang et al . , 2020 ) ) ; and 7.RoBERTa BASE ( Liu et al . , 2019 ) . 
Empathy Identiﬁcation Task . 
Table 3 reports the accuracy and macro - f1 scores of the three commu- nication mechanisms ( random baseline for each is 33 % accurate ; three levels ) . 
Log . 
reg . , RNN , and HRED struggle to identify empathy with noticeably low macro - f1 scores indicative of failures to distin- guish between the three levels of communication . 
Among the baseline transformer architectures , we obtain best performance using RoBERTa but ob- serve substantial gains over them with our approach 
5269ModelEmotional ReactionsInterpretations Explorations identiﬁcation rationale identiﬁcation rationale identiﬁcation rationale acc . 
f1 T - f1 IOU acc . 
f1 T - f1 IOU acc . 
f1 T - f1 IOUTalkLifeOur Model 79.93 74.29 68.49 66.82 87.50 67.46 67.81 85.76 86.92 73.47 64.56 83.19 -attention 79.00 73.02 59.59 63.49 87.41 66.97 67.12 79.20 84.86 63.45 59.42 73.82 -seeker post 79.37 73.52 61.08 62.58 86.04 63.23 65.56 77.23 86.16 70.80 60.05 81.87 -rationales 79.12 71.21 – * – * 87.01 66.71 – * – * 86.38 72.14 – * – * -pre - training 78.95 73.41 60.34 62.91 87.31 65.86 69.03 84.95 86.21 70.54 64.53 80.19RedditOur Model 79.43 74.46 53.57 64.83 84.04 62.60 57.40 55.90 92.61 72.58 71.56 84.48 -attention 75.51 52.66 51.79 59.83 83.26 62.25 54.90 52.79 91.98 64.75 68.81 81.91 -seeker post 79.15 71.47 45.87 58.56 83.57 62.41 55.59 55.51 91.67 64.59 68.73 81.56 -rationales 78.50 73.21 – * – * 83.26 62.13 – * – * 91.51 64.44 – * – * -pre - training 76.97 69.03 51.58 57.35 82.32 61.38 57.61 55.34 91.99 65.26 70.44 81.71 Table 5 : Ablation results . 
Most of our gains are due to context provided through attention and seeker post ; higher gains for the rationale extraction task . 
* Note that rationales can not be predicted after removing them from training . 
( +1.73 acc . , 
+4.02 macro - f1 over RoBERTa ) 
. 
We analyze the sources of these gains in x6.2 . 
Rationale Extraction Task . 
We perform both to- ken level and span level evaluation for this task . 
We use two metrics , commonly used in discrete rationale extraction tasks ( DeYoung et al . , 2020 ): 1.T - f1 ( token level f1 ) ; 2.IOU - f1 ( intersection over union overlap of predicted spans with ground truth spans ; threshold of 0.5 on the overlap for ﬁnd- ing true positives and the corresponding f1 ) . 
We ﬁnd that GPT-2 and DialoGPT perform better than BERT and RoBERTa likely due to appropriateness to the related task of generating free - text rationales ( Table 4 ) . 
Our approach obtains gains of +2.58 T - f1 and +6.45 IOU - f1 over DialoGPT , potentially due to the use of attention and seeker post ( x6.2 ) . 
6.2 Ablation Study We next analyze the components and training strate- gies in our approach through an ablation study . 
No Attention . 
Instead of using attention , we con- catenate the seeker post encoding ( e(S ) i ) with the response post encoding ( e(R ) i ) and use the concate- nated representation as input to the linear layer . 
No Seeker Post . 
We train without the S - Encoder , i.e. , by only encoding from the R - Encoder . 
No Rationales . 
We setREto 0 and only train on the empathy identiﬁcation task . 
No Domain - Adaptive Pre - training . 
We initialize by only using model weights from RoBERTa BASE . 
Results . 
Our most signiﬁcant gains come from us- ing attention and the seeker post ( Table 5 ) which greatly beneﬁts the rationale extraction task ( +4.88 T - f1 , +5.74 IOU - f1 ) . 
Also , using rationales and pre - training only leads to small performance im - provements . 
6.3 Error Analysis We qualitatively analyze the sources of our errors . 
For the empathy identiﬁcation task , we found that the model sometimes failed to identify short ex- pressions of emotions in responses that otherwise contained a lot of instructions ( e.g. , Sorry to hear that ! 
Try doing ... ) . 
Also , certain responses trying to universalize the situation ( e.g. , You are not alone ) got incorrectly identiﬁed as strong interpretations . 
Furthermore , a source of error for explorations was confusions due to questions that were not an ex- ploration of seeker ’s feelings or experiences ( e.g. , offers to talk - Do you want to talk ? ) . 
For the rationale extraction task , the model accu- rately extracts phrases that are commonly used for expressing empathy ( e.g. , this might be tough ) , but also sometimes incorrectly extracts single words from sentences indicating errors in disambiguat- ing word usage ( e.g. , ‘ what ’ in Tell them what you need gets extracted as an exploration , likely be- 
cause what is really common in explorations as in what happened ? ) . 
7 Model - based Insights into Mental Health Platforms We apply our model to study how empathy impacts online peer - to - peer support dynamics . 
To only fo- cus on conversations related to signiﬁcant mental health challenges and ﬁlter out common social me- dia interactions ( e.g. , Merry Christmas ) , we care- fully select 235k mental health related interactions on TalkLife using a seeker - reported indicator.6 6We focus analyzing TalkLife alone as Reddit lacks rich publicly available signals such as seeker liking the response . 
5270Seeker Post Original Response Re - written Response I can not do anything without get- ting blamed today . 
This day is getting worse and worse . 
Days end , tomorrow is a fresh start . 
I ’m sorry that today sucks , but tomorrow is a fresh start . 
An hour ago i was happy an hour later i ’m sad . 
Am i getting mad now?Try mindful meditation which can control anxi- etyThat ’s something I ’ve struggled with too , and it really pains me to hear that you ’re dealing with the same thing . 
Have you considered trying meditation ? 
I ’ve found it to be very helpful . 
Table 6 : Example re - written responses with our model - based feedback . 
Participants increased empathy from 0.8 to 3.0.blue = Strong emo . 
reactions , light red /dark red = Weak / Strong Interpretations , green = Strong explorations . 
We investigate ( 1 ) the levels of empathy on the platform , its variation over time , and examine the relationship of empathy with ( 2 ) conversation out- comes , ( 3 ) relationship forming , and ( 4 ) gender . 
( 1 ) Peer supporters do not self - learn empathy over time . 
Overall , we observe that empathy ex- pressed by peer supporters on the platform is low ( avg . total score7of 1.09 out of 6 ) . 
In addition , we ﬁnd that the emotional reactivity of users decreases over time ( 36 % decrease over three years ) and their levels of interpretations and explorations remain practically constant ( Fig . 3a ) . 
Further analyzing whether a user individually improves , worsens , or remains constant in their expression of empathy , we ﬁnd that 69 % users either worsen or stay con- stant in their empathy expressions and only 10 % improve by at least one point ( i.e. one level in our framework ) . 
This is also reﬂected in prior work on therapy that shows that without deliberate practice and speciﬁc feedback , even trained therapists often diminish in skills over time ( Goldberg et al . , 2016 ) . 
We ﬁnd this trend robust to potential confound- ing factors ( new users , user dropout ) and users of different groups ( low vs. high activity users , moder- ators ; Appendix C ) . 
This indicates that most users do not self - learn empathy and highlights the need of providing them feedback . 
( 2 ) High empathy interactions are received pos- itively by seekers . 
We analyze the correlation of empathic conversations with positive feedback , concretely with seeker ” liking ” the post . 
We ﬁnd that strong communications of empathy are re- ceived with 45 % more likes by seekers than no communication ( Fig . 
3b ) . 
Strong explorations get 44 % less likes but receive 47 % more replies than no explorations , leading to higher engagement . 
( 3 ) Relationship forming more likely after em- pathic conversations . 
Psychology research em- phasizes the importance of empathy in forming al- 
7Total empathy score is obtained by adding the level of communication across the three mechanisms . 
2015201620172018Year0.10.30.50.7Average levelof empathyERIPEX 01234+Total Empathy234567Seeker followedpeer - supporter ( % ) NoWeakStrongEmpathy Level10203040Responses likedby the seeker ( % ) ERIPEX F!FF!MM!FM!MGender ( Peer!Seeker)5060708090Responses withempathy 1 ( % ) ( a)(b)(c)(d)Figure 3 : ( a ) Peer - supporters do not self - learn empa- thy over time . 
Only users who joined in 2015 were included but similar trends hold for other user groups ; ( b ) Stronger communications of emotional reactions and interpretations are received positively by seekers . 
Stronger explorations get 47 % more replies ; ( c ) A lot more seekers follow peers after empathic interactions ; ( d ) Females are more empathic towards females . 
liance and relationship with seekers ( Watson , 2007 ) . 
Here , we operationalize relationship forming as seeker ” following ” the peer supporter after a con- versation ( within 24hrs ) . 
We ﬁnd that seekers are 79 % more likely to follow peer supporters after an empathic conversation ( total score of 1+vs . 0 ) than after a non - empathic one ( Fig . 3c ) . 
( 4 ) Females are more empathic with females than males are with males . 
Previous work has shown that seekers identifying as females receive more support in online communities ( Wang and Jurgens , 2018 ) . 
Here , we ask if empathic interac- tions are affected by the self - reported gender of seekers and peer supporters . 
We ﬁnd that female peer supporters are 32 % more empathic towards female seekers than males are towards male seek- ers ( Fig . 3d ) . 
Also , females are 6 % more empathic towards males than males are towards females . 
Implications for empathy - based feedback . 
These results suggest that our approach not only successfully measures empathy according to a 
5271principled framework ( x3 ) , but that the measured empathy components are important to online supportive conversations as indicated by the positive reactions from seekers and meaningful reﬂections of social theories . 
However , peer supporters on the platform express empathy rarely and this does not improve over time . 
This points to critical opportunities for empathy - based feedback to peer supporters for making their interactions with seekers more effective . 
Here , we demonstrate the potential of feedback in a simple proof - of- concept . 
When providing three participants ( none are co - authors ) simple feedback ( Appendix D ) based on EPITOME and our best - performing model , they were able to increase empathy in responses from 0.8 to 3.0 ( total empathy across the three mechanisms ) . 
Table 6 shows two such examples of re - written responses that improve in communicating cognitive understanding ( today sucks ) and are also better with emotional reactions ( I ’m sorry , it pains me ) and explorations ( Have you considered trying mindful meditation ? ) . 
8 Further Related Work Previous work in NLP for mental health has focused on analysis of effective conversation strategies ( Althoff et al . , 2016 ; P ´ erez - Rosas et al . , 2019 ; Zhang and Danescu - Niculescu - Mizil , 2020 ) , identiﬁcation of therapeutic actions ( Lee et al . , 2019 ) , and language development of coun- selors ( Zhang et al . , 2019 ) . 
Researchers have also analyzed linguistic accommodation ( Sharma and De Choudhury , 2018 ) , cognitive restruc- turing ( Pruksachatkun et al . , 2019 ) , and self- disclosure ( Yang et al . , 2019 ) . 
We extend these studies and analyze empathy which is key in coun- seling and mental health support . 
Previous re- search has analyzed empathy in health commu- nities ( Khanpour et al . , 2017 ) , face - to - face ther- apy ( Gibson et al . , 2016 ) , motivational interview- ing ( P ´ erez - Rosas et al . , 2017 ) , and emotionally- grounded conversations ( Rashkin et al . , 2019 ) . 
Small - scale studies on manually annotated datasets have also been conducted ( Morris and Picard , 2012 ; Lord et al . , 2015 ) . 
Our work develops a compu- tational method for identifying empathy in text- based , asynchronous mental health support which is grounded in psychology and psychotherapy re- search and provides deeper insights into mental health platforms . 
Recent work has also devel- oped proof - of - concept prototypes , such as Client - Bot ( Huang et al . , 2020 ) , for training users in coun- seling . 
Our approach is aimed towards develop- ing empathy - based feedback and training systems for peer supporters ( consistent with calls to action for improved treatment access and training ( Miner et al . , 2019 ; 
Imel et al . , 2015 ; Kazdin and Rabbitt , 2013 ) ) . 
9 Conclusion We developed a new framework , dataset , and com- putational method for understanding expressed em- pathy in text - based , asynchronous conversations on mental health platforms . 
Our computational approach effectively identiﬁes empathy with under- lying rationales . 
Moreover , the identiﬁed compo- nents are found to be important to mental health platforms and helpful in improving peer - to - peer support through model - based feedback . 
Acknowledgments We would like to thank TalkLife and Jamie Druitt for their support and for providing us access to a TalkLife dataset . 
We also thank the members of UW Behavioral Data Science group , UW NLP group , Zac E. Imel , and the anonymous review- ers for their feedback on this work . 
A.S. and T.A. were supported in part by NSF grant IIS-1901386 , Bill & Melinda Gates Foundation ( INV-004841 ) , an Adobe Data Science Research Award , the Allen Institute for Artiﬁcial Intelligence , and a Microsoft AI for Accessibility grant . 
A.S.M. was supported by grants from the National Institutes of Health , National Center for Advancing Translational Sci- ence , Clinical and Translational Science Award ( KL2TR001083 and UL1TR001085 ) and the Stan- ford Human - Centered AI Institute . 
D.C.A. was supported in part by a NIAAA K award ( K02 AA023814 ) . 
Conﬂict of Interest Disclosure . 
Dr. Atkins is a co- founder with equity stake in a technology company , Lyssn.io , focused on tools to support training , su- pervision , and quality assurance of psychotherapy and counseling . 
References Tim Althoff , Kevin Clark , and Jure Leskovec . 2016 . 
Large - scale analysis of counseling conversations : An application of natural language processing to mental health . 
TACL , 4:463–476 . 
5272Godfrey T Barrett - Lennard . 
1981 . 
The empathy cycle : Reﬁnement of a nuclear concept . 
Journal of coun- seling psychology , 28(2):91 . 
Arthur C Bohart , Robert Elliott , Leslie S Greenberg , and Jeanne C Watson . 
2002 . 
Empathy . 
J. C. Nor- cross ( Ed . ) , Psychotherapy relationships that work : Therapist contributions and responsiveness to pa- tients . 
Sven Buechel , Anneke Buffone , Barry Slaff , Lyle Un- gar , and Jo ˜ao Sedoc . 
2018 . 
Modeling empathy and distress in reaction to news stories . 
In EMNLP . 
Mark H Davis et 
al . 
1980 . 
A multidimensional ap- proach to individual differences in empathy . 
Journal of Personality and Social Psychology . 
Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 . 
Bert : Pre - training of deep bidirectional transformers for language understand- ing . 
In NAACL - HLT . 
Jay DeYoung , Sarthak Jain , Nazneen Fatema Rajani , Eric Lehman , Caiming Xiong , Richard Socher , and Byron C Wallace . 
2020 . 
Eraser : A benchmark to evaluate rationalized nlp models . 
In ACL . 
Robert Elliott , Arthur C Bohart , Jeanne C Watson , and David Murphy . 
2018 . 
Therapist empathy and client outcome : An updated meta - analysis . 
Psychother- apy , 55(4):399 . 
Gunther Eysenbach , John Powell , Marina Englesakis , Carlos Rizo , and Anita Stern . 
2004 . 
Health related virtual communities and electronic support groups : systematic review of the effects of online peer to peer interactions . 
Bmj , 328(7449):1166 . 
James Gibson , Do ˘gan Can , Bo Xiao , Zac E Imel , David C Atkins , Panayiotis Georgiou , and Shrikanth S Narayanan . 
2016 . 
A deep learning ap- proach to modeling empathy in addiction counseling . 
Interspeech . 
Simon B Goldberg , Tony Rousmaniere , Scott D Miller , Jason Whipple , Stevan Lars Nielsen , William T Hoyt , and Bruce E Wampold . 
2016 . 
Do psychother- apists improve with time and experience ? 
a longitu- dinal analysis of outcomes in a clinical setting . 
Jour- nal of counseling psychology , 63(1):1 . 
Suchin Gururangan , Ana Marasovi ´ c , Swabha Swayamdipta , Kyle Lo , Iz Beltagy , Doug Downey , and Noah A Smith . 
2020 . 
Do n’t stop pretraining : Adapt language models to domains and tasks . 
In ACL . 
Kaiming He , Xiangyu Zhang , Shaoqing Ren , and Jian Sun . 
2016 . 
Deep residual learning for image recog- nition . 
In CVPR . 
Emily A Holmes , Ata Ghaderi , Catherine J Harmer , Paul G Ramchandani , Pim Cuijpers , Anthony P Morrison , Jonathan P Roiser , Claudi LH Bockt- ing , Rory C O’Connor , Roz Shafran , et al . 
2018.The lancet psychiatry commission on psychologi- cal treatments research in tomorrow ’s science . 
The Lancet Psychiatry , 5(3):237–286 . 
Minlie Huang , Xiaoyan Zhu , and Jianfeng Gao . 
2020 . 
Challenges in building intelligent open - domain dia- log systems . 
ACM Transactions on Information Sys- tems ( TOIS ) , 38(3):1–32 . 
Samuel Humeau , Kurt Shuster , Marie - Anne Lachaux , and Jason Weston . 
2019 . 
Poly - encoders : Trans- former architectures and pre - training strategies for fast and accurate multi - sentence scoring . 
CoRR abs/1905.01969 . 
External Links : Link Cited by , 2:2 – 2 . Zac E Imel , Mark Steyvers , and David C Atkins . 
2015 . 
Computational psychotherapy research : Scaling up the evaluation of patient – provider interactions . 
Psy- chotherapy , 52(1):19 . 
Alan E Kazdin and Sarah M Rabbitt . 
2013 . 
Novel mod- els for delivering mental health services and reduc- ing the burdens of mental illness . 
Clinical Psycho- logical Science , 1(2):170–191 . 
Hamed Khanpour , Cornelia Caragea , and Prakhar Biyani . 2017 . 
Identifying empathetic messages in online health communities . 
In IJCNLP ) , pages 246 – 251 . 
Fei - Tzin Lee , Derrick Hull , Jacob Levine , Bonnie Ray , and Kathleen McKeown . 2019 . 
Identifying therapist conversational actions across diverse psychothera- peutic approaches . 
In Proceedings of the Sixth Work- shop on Computational Linguistics and Clinical Psy- chology , pages 12–23 . 
Yinhan Liu , Myle Ott , Naman Goyal , Jingfei Du , Man- dar Joshi , Danqi Chen , Omer Levy , Mike Lewis , Luke Zettlemoyer , and Veselin Stoyanov . 
2019 . 
Roberta : A robustly optimized bert pretraining ap- proach . 
arXiv preprint arXiv:1907.11692 . 
Sarah Peregrine Lord , Elisa Sheng , Zac E Imel , John Baer , and David C Atkins . 
2015 . 
More than re- ﬂections : empathy in motivational interviewing in- cludes language style synchrony between therapist and client . 
Behavior therapy , 46(3):296–303 . 
Tara Matthews , Kathleen O’Leary , Anna Turner , Manya Sleeper , Jill Palzkill Woelfer , Martin Shelton , Cori Manthorne , Elizabeth F Churchill , and Sunny Consolvo . 
2017 . 
Stories from survivors : Privacy & security practices when coping with intimate partner abuse . 
In CHI . 
William R Miller , Theresa B Moyers , Denise Ernst , and Paul Amrhein . 
2003 . 
Manual for the motiva- tional interviewing skill code ( misc ) . 
Unpublished manuscript . 
Albuquerque : Center on Alcoholism , Substance Abuse and Addictions , University of New Mexico . 
5273Adam S Miner , Nigam Shah , Kim D Bullock , Bruce A Arnow , Jeremy Bailenson , and Jeff Hancock . 
2019 . 
Key considerations for incorporating conversational ai in psychotherapy . 
Frontiers in psychiatry , 10 . 
Robert R Morris and Rosalind Picard . 
2012 . 
Crowd- sourcing collective emotional intelligence . 
arXiv preprint arXiv:1204.3481 . 
Mark Olfson . 
2016 . 
Building the mental health work- force capacity needed to treat adults with serious mental illnesses . 
Health Affairs , 35(6):983–990 . 
Sundip Patel , Alexis Pelletier - Bui , Stephanie Smith , Michael B Roberts , Hope Kilgannon , Stephen Trze- ciak , and Brian W Roberts . 
2019 . 
Curricula for em- pathy and compassion training in medical education : A systematic review . 
PloS one , 14(8 ) . 
Ver´onica P ´ erez - Rosas , Rada Mihalcea , Kenneth Resni- cow , Satinder Singh , and Lawrence An . 2017 . 
Un- derstanding and predicting empathic behavior in counseling therapy . 
In ACL . 
Ver´onica P ´ erez - Rosas , Xinyi Wu , Kenneth Resnicow , and Rada Mihalcea . 
2019 . 
What makes a good coun- selor ? 
learning to distinguish between high - quality and low - quality counseling conversations . 
In ACL . 
Yada Pruksachatkun , Sachin R Pendse , and Amit Sharma . 2019 . 
Moments of change : Analyzing peer- based cognitive support in online mental health fo- rums . 
In CHI . 
Alec Radford , Jeffrey Wu , Rewon Child , David Luan , Dario Amodei , and Ilya Sutskever . 2019 . 
Language models are unsupervised multitask learners . 
OpenAI Blog , 1(8):9 . 
Hannah Rashkin , Eric Michael Smith , Margaret Li , and Y - Lan Boureau . 
2019 . 
Towards empathetic open- domain conversation models : A new benchmark and dataset . 
In ACL . 
Elliot Robert , Arthur C Bohart , JC Watson , and LS Greenberg . 
2011 . 
Empathy . 
Psychotherapy , 48(1):43–49 . 
Maarten Sap , Saadia Gabriel , Lianhui Qin , Dan Juraf- sky , Noah A Smith , and Yejin Choi . 
2020 . 
Social bias frames : Reasoning about social and power im- plications of language . 
In ACL . 
Robert L Selman . 
1980 . 
Growth of interpersonal un- derstanding . 
Academic Press . 
Eva Sharma and Munmun De Choudhury . 
2018 . 
Men- tal health support and its relationship to linguistic accommodation in online communities . 
In CHI . 
Alessandro Sordoni , Yoshua Bengio , Hossein Vahabi , Christina Lioma , Jakob Grue Simonsen , and Jian- Yun Nie . 2015 . 
A hierarchical recurrent encoder- decoder for generative context - aware query sugges- tion . 
In CIKM .CB 
Truax and RR Carkhuff . 
1967 . 
Modern ap- plications in psychology . 
Toward effective coun- seling and psychotherapy : Training and practice . 
Hawthorne , NY , US : Aldine Publishing Co . 
Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , Łukasz Kaiser , and Illia Polosukhin . 2017 . 
Attention is all you need . 
In NeurIPS . 
Zijian Wang and David Jurgens . 
2018 . 
It ’s going to be okay : 
Measuring access to support in online commu- nities . 
In EMNLP . 
Jeanne C Watson . 
2007 . 
Facilitating empathy . 
Euro- pean Psychotherapy , 7(1):59–65 . 
Jeanne C Watson , Rhonda N Goldman , and Margaret S Warner . 
2002 . 
Client - centered and experiential psy- chotherapy in the 21st century : Advances in theory , research , and practice . 
PCCS Books . 
Marsha White and Steve M Dorman . 
2001 . 
Receiving social support online : implications for health educa- tion . 
Health education research , 16(6):693–707 . 
Diyi Yang , Zheng Yao , Joseph Seering , and Robert Kraut . 
2019 . 
The channel matters : Self - disclosure , reciprocity and social support in online cancer sup- port groups . 
In CHI . 
Justine Zhang and Cristian Danescu - Niculescu - Mizil . 
2020 . 
Balancing objectives in counseling conversa- 
tions : Advancing forwards or looking backwards . 
In ACL . 
Justine Zhang , Robert Filbin , Christine Morrison , Ja- clyn Weiser , and Cristian Danescu - Niculescu - Mizil . 
2019 . 
Finding your voice : The linguistic develop- ment of mental health counselors . 
In ACL . 
Yizhe Zhang , Siqi Sun , Michel Galley , Yen - Chun Chen , Chris Brockett , Xiang Gao , Jianfeng Gao , Jingjing Liu , and Bill Dolan . 
2020 . 
Dialogpt : Large - scale generative pre - training for conversational response generation . 
In ACL , system demonstration . 
5274A Data Collection Details A.1 Annotation Instructions For each ( seeker post , response post ) pair , the an- notators were asked the following four questions : 1.(Mental Health Related ) Is the seeker talk- ing about a mental health related issue or situ- ation in his / her post?8 Yes No 2.(Emotional Reactions ) 
Does the response ex- press or allude to warmth , compassion , con- cern or similar feelings of the responder to- wards the seeker ? 
No Yes , the response alludes to these feel- ings but the feelings are not explicitly expressed Yes , the response has an explicit mention of these feelings 3.(Interpretations ) 
Does the response commu- nicate an understanding of the seeker ’s expe- riences and feelings ? 
In what manner ? 
No Yes , the response communicates an un- derstanding of the seeker ’s experiences and/or feelings If the answer to the above question was ” Yes ” , the annotators were further asked to annotate one or more of the following : The response contains conjectures or speculations about the seeker ’s experi- ences and/or feelings The responder has reﬂected back on sim- ilar experiences of their own or others The responder has also described similar experiences of their own or others The response contains paraphrases of the seeker ’s experiences and/or feelings 4.(Explorations ) Does the response make an attempt to explore the seeker ’s experiences and feelings ? 
No 8We use this question for ﬁltering non - mental related posts from the data collection processYes , but the exploration is generic Yes , and the exploration is speciﬁc 
The detailed instructions can be found at https://mhannotate-test.cs . 
washington.edu/annotate/readme.html . 
A.2 Interactive Training of Crowdworkers The crowdworkers on Upwork were initially pro- vided with our entire annotation instructions and an interactive training system9containing ten ex- amples . 
After this initially automated training , we scheduled a 1hour long phone call with them to dis- cuss our annotation instructions and annotation in- terface . 
During the phone call , crowdworkers also asked questions on the annotation guidelines which greatly helped in addressing potential ambiguities . 
After the phone call , we assigned them 20 tasks each ( randomly chosen ; different for each crowd- worker ) . 
We manually evaluated the annotations on those 20 tasks . 
Based on the evaluation , we either decided to discontinue with the crowdworker ( there were two such crowdworkers ) or we provided them further manual feedback . 
Throughout the process , crowdworkers actively asked questions through the chat feature on Upwork . 
After the initial training phase , we also did spot checks on quality ( at least two times for each crowdworker ; 20posts each ) to provide them further feedback.10 B Reproducibility B.1 Implementation Details Code . 
Our codes are based on the huggingface library ( https://huggingface.co/ ) . 
We make them publicly available at https://github.com/ behavioral - data / Empathy - Mental - Health . 
Seed Value . 
For all our experiments , we used the seed value of 12 . 
B.2 Hyperparameter Fine - tuning We searched through the following space of hyper- parameters for ﬁne - tuning our model : learning rate = 1e-5 , 2e-5 , 5e-5 , 1e-4 , 5e-4 EI= 1 RE= 0.1 , 0.2 , 0.5 , 1 9This system contained prompts of manually written feed- back for both correct and incorrect annotations . 
10Crowdworkers only needed minor feedback on these posts . 
5275B.3 Runtime Analysis Domain - Adaptive Pre - training Time . 
We con- ducted domain - adaptive pre - training on four RTX 2080 Ti GPUs . 
Pre - training S - Encoder took around 22 hours . 
Pre - training R - Encoder took around 38 hours . 
Both are pre - trained for three epochs . 
Model Training Time . 
We trained our model on one RTX 2080 Ti GPU . 
The training approximately takes ﬁve minutes . 
Our model is trained for four epochs . 
B.4 Train , Dev , Test Splits We split both the datasets into train , dev , and test sets in the ratio of 75:5:20 . 
Table 7 contains the statistics of the train , dev , and test splits . 
B.5 Number of Parameters The total number of parameters of our model 
= 2 * number of parameters of RoBERTa BASE + param- eters in the linear layers 2 * 125 M + 2 * .5 M 
= 251 M B.6 Reddit dataset The entire Reddit dataset can be accessed through its archive on Google BigQuery at https://bigquery.cloud.google.com/table/ fh - bigquery : reddit_comments.2015_05?pli= 1 C Potential confounding factors in analysis of variation of empathy over time We note that such an analysis can be affected by several confounding factors such as old vs. new users , user dropout , and low activity of several users . 
To account for these factors , we stratify users by the year in which they started supporting on the platform ( 2015 , 2016 , 2017 ) and analyze the average levels of empathy during subsequent years in each stratum . 
We further ﬁlter users with < 10posts and only consider users who stay on the platform for at least a year . 
In addition , we analyze various user groups but observe similar trends ( Fig . 4 ) . 
D Proof - of - Concept Details : model - based feedback for making responses empathic We work with three computer science students with no training in counseling and give them ( seekerpost , response post ) pairs identiﬁed low in empathy by our approach ( total empathy score 1 ) . 
We show them – ( 1 ) the levels of empathy predicted by our model , ( 2 ) extracted rationales , ( 3 ) a templated feedback explaining where the response lacks and how it can be made more empathic ( based on the predicted levels , extracted rationales , deﬁnitions and examples in EPITOME ) . 
A sample feedback is shown below : Seeker Post : I ’m hurt so much that I do n’t really have feelings anymore Response Post : 
Yeah , I felt it once Feedback : 1.The response communicates an under- standing of the seeker ’s post to a weak degree in the portion “ I felt it once ” . 
The communication can be made stronger by talking about the seeker ’s feelings or ex- periences that you interpret after reading the post . 
Typically , they are expressed by saying “ This must be terrible ” , “ I know you are in a tough situation ” . 
2.It also lacks expressions of emotions of warmth , compassion , or concern and also does not attempt to explore the seeker ’s emotions or feelings . 
Typically , they are expressed by saying “ I am feeling sorry for you ” , “ What makes you feel depressed ? ” 
We ask them to rewrite the response post making use of the templated feedback . 
Overall , the partic- ipants were comfortable to rewrite the responses with an average difﬁculty of 1.92 out of 5 ( most difﬁcult is 5 ) and found the feedback useful in the rewriting process with an average usefulness rating of 3.5 out of 5 ( highly useful is 5 ) . 
5276 2015 2016 2017 2018 Year0.80.91.01.11.2Average level of empathy year users started supporting 2015 2016 2017(a ) 
Users with 10posts 2015 2016 2017 2018 Year0.80.91.01.11.2Average level of empathy year users started supporting 2015 2016 2017 ( b ) Users with 50posts 2015 2016 2017 2018 Year0.81.01.21.4Average level of empathy year users 
started supporting 2015 2016 2017 ( c ) Users with < 10posts 2015 2016 2017 
2018 Year0.51.01.52.0Average level of empathy year users started supporting 2015 2016 2017 ( d ) Moderators Figure 4 : Empathy over time analysis of various user groups . 
We ﬁnd similar trends across multiple groups . 
Train Dev Test Data SourceNo Weak Strong 
No Weak Strong 
No Weak Strong Emotional ReactionsTalkLife 52.02 % 41.55 % 6.43 % 49.44 % 44.66 % 5.90 % 52.28 % 41.27 % 6.45 % Reddit 65.80 % 29.52 % 4.68 % 66.87 % 26.88 % 6.25 % 66.98 % 27.39 % 5.63 % InterpretationsTalkLife 78.39 % 3.33 % 18.28 % 77.20 % 4.00 % 18.80 % 79.26 % 2.69 % 18.04 % Reddit 54.59 % 3.63 % 41.77 % 48.12 % 4.37 % 47.5 % 48.83 % 3.91 % 47.26 % ExplorationsTalkLife 72.87 % 10.56 % 16.57 % 73.88 % 10.11 % 16.01 % 73.40 % 11.09 % 15.51 % Reddit 83.41 % 3.80 % 12.79 % 89.94 % 62.89 % 9.44 % 85.60 % 3.13 % 11.27 % Table 7 : Train / Dev / Test Splits . 