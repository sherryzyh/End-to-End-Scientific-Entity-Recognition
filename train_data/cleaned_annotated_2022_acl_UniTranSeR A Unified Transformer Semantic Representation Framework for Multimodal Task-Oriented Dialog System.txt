UniTranSeR B-MethodName

: O

A O

Uniﬁed O

Transformer O

Semantic O

Representation O

Framework O

for O

Multimodal B-MethodName

Task I-MethodName

- I-MethodName

Oriented I-MethodName

Dialog I-MethodName

Systems I-MethodName

Zhiyuan O

Ma1 O

, O

Jianjun O

Li1 O

, O

Guohui O

Li1 O

, O

Yongjing O

Cheng2 O

1Huazhong O

University O

of O

Science O

and O

Technology O

( O

HUST O

) O

, O

China O

2National O

University O

of O

Defense O

Technology O

( O

NUDT O

) O

, O

China O

{ O

zhiyuanma,jianjunli,guohuili}@hust.edu.cn O

davidcheng1001@163.com O



Abstract O

As O

a O

more O

natural O

and O

intelligent O

interac- O

tion O

manner O

, O

multimodal B-MethodName

task I-MethodName

- I-MethodName

oriented I-MethodName

dia- I-MethodName

log I-MethodName

system I-MethodName

recently O

has O

received O

great O

atten- O

tion O

and O

many O

remarkable O

progresses O

have O

been O

achieved O

. O



Nevertheless O

, O

almost O

all O

ex- O

isting O

studies O

follow O

the O

pipeline O

to O

ﬁrst O

learn O

intra O

- O

modal O

features O

separately O

and O

then O

conduct O

simple O

feature O

concatenation O

or O

attention O

- O

based O

feature O

fusion O

to O

generate O

re- O

sponses O

, O

which O

hampers O

them O

from O

learning O

inter O

- O

modal O

interactions O

and O

conducting O

cross- O

modal O

feature O

alignment O

for O

generating O

more O

intention O

- O

aware O

responses O

. O



To O

address O

these O

issues O

, O

we O

propose O

UniTranSeR B-MethodName

, O

a O

Uni O

ﬁed O

Transformer O

Se O

mantic O

R O

epresentation O

frame- O

work O

with O

feature O

alignment O

and O

intention O

rea- O



soning O

for O

multimodal O

dialog O

systems O

. O



Specif- O



ically O

, O

we O

ﬁrst O

embed O

the O

multimodal O

features O

into O

a O

uniﬁed O

Transformer O

semantic O

space O

to O

prompt O

inter O

- O

modal O

interactions O

, O

and O

then O

de- O

vise O

a O

feature O

alignment O

and O

intention O

reason- O

ing O

( O

FAIR O

) O

layer O

to O

perform O

cross O

- O

modal O

en- O

tity O

alignment O

and O

ﬁne O

- O

grained O

key O

- O

value O

rea- O

soning O

, O

so O

as O

to O

effectively O

identify O

user O

’s O

in- O

tention O

for O

generating O

more O

accurate O

responses O

. O



Experimental O

results O

verify O

the O

effectiveness O

of O

UniTranSeR B-MethodName

, O

showing O

that O

it O

signiﬁcantly O

outperforms O

state O

- O

of O

- O

the O

- O

art O

approaches O

on O

the O

representative O

MMD B-DatasetName

dataset O

. O



1 O

Introduction O

The O

multimodal B-MethodName

task I-MethodName

- I-MethodName

oriented I-MethodName

dialog I-MethodName

systems I-MethodName

are O

designed O

to O

help O

users O

achieve O

speciﬁc O

goals O

such O

as O

clothing O

recommendation O

or O

restaurant O

reserva- O

tion O

, O

which O

is O

in O

growing O

demand O

in O

the O

current O

business O

environment O

. O



As O

a O

leading O

study O

, O

Saha O

et O

al O

. O



( O

2018 O

) O

released O

a O

multimodal B-DatasetName

dialog I-DatasetName

dataset I-DatasetName

( O

MMD B-DatasetName

) O

in O

the O

online O

retail O

domain O

. O



Based O

on O

such O

a O

benchmark O

dataset O

, O

many O

multimodal O

dialog O

mod- O

els O

incorporating O

domain O

knowledge O

have O

recently O

been O

proposed O

( O

Chauhan O

et O

al O

. O

, O

2019 O

; O

Zhang O

et O



al O

. O

, O



2019 O

, O

2021 O

) O

, O

which O

basically O

exploit O

taxonomy- O

based O

method O

( O

Liao O

et O

al O

. O

, O

2018 O

; O

Cui O

et O



al O

. O

, O

2019 O

) O

or O

attention O

- O

based O

method O

( O

Nie O

et O

al O

. O

, O

2019 O

; O

He O

et O

al O

. O

, O

2020 O

) O

to O

incorporate O

knowledge O

base O

( O

KB O

) O

information O

for O

better O

performance O

. O



Though O

achieving O

remarkable O

progress O

, O

existing O

multimodal B-MethodName

task I-MethodName

- I-MethodName

oriented I-MethodName

dialog I-MethodName

systems I-MethodName

still O

suf- O

fer O

from O

the O

following O

three O

limitations O

. O



Firstly O

, O

prior O

models O

only O

learn O

the O

intra O

- O

modal O

features O

( O

including O

textual O

features O

, O

visual O

features O

and O

do- O

main O

knowledge O

) O

separately O

before O

fusing O

them O

. O



Since O

these O

multimodal O

cues O

in O

general O

can O

enhance O

and O

complement O

each O

other O

, O

projecting O

them O

into O

a O

uniﬁed O

semantic O

space O

to O

learn O

the O

inter O

- O

modal O

features O

, O

with O

no O

doubt O

, O

can O

help O

improve O

the O

abil- O

ities O

of O

natural O

language O

understanding O

, O

which O

in O

turn O

will O

beneﬁt O

the O

response B-TaskName

generation I-TaskName

. O



Sec- O

ondly O

, O

prior O

models O

only O

conduct O

simple O

feature O

concatenation O

( O

Saha O

et O

al O

. O

, O

2018 O

; O

Nie O

et O

al O

. O

, O

2019 O

) O

or O

attention O

- O

based O

feature O

fusion O

( O

Cui O

et O



ter O

acquiring O

intra O

- O

modal O

representations O

, O

but O

with- O

out O

learning O

ﬁne O

- O

grained O

alignment O

between O

differ- O

ent O

modalities O

before O

fusion O

, O

which O

is O

not O

favorable O

to O

query O

knowledge O

for O

accurate O

multimodal B-TaskName

re- I-TaskName

sponse I-TaskName

generation I-TaskName

. O



Take O

the O

dialog O

in O

Figure O

1 O

as O

an O

example O

, O

when O

answering O

the O

user O

’s O

query O

on O

similar O

style O

of O

jackets O

, O

the O

model O

is O

expected O

to O

align O

the O

word O

“ O

jackets O

” O

with O

the O

corresponding O

vi- O

sual O

features O

for O

proper O

semantic O

complement O

and O

entity O

enhancement O

. O



Thirdly O

, O

prior O

models O

basi- O

cally O

lack O

the O

capability O

of O

entity O

- O

level O

reasoning O

, O

which O

prevents O

them O

from O

performing O

reasoning O

over O

crucial O

entities O

to O

guide O

intention O

- O

aware O

re- O

sponse O

generation O

. O



For O

example O

, O

in O

Figure O

1 O

, O

when O

the O

user O

asks O

“ O

show O

some O

similar O

jackets O

in O

black O

color O

” O

, O

the O

chatbot O

is O

expected O

to O

properly O

explore O

the O

pivot O

attribute O

“ O

black O

” O

that O

connects O

the O

start O

query O

cue O

“ O

jackets O

” O

with O

the O

target O

recommended O

product O

images O

. O



Speciﬁcally O

, O

the O

model O

needs O

to O

perform O

a O

2 O

- O

hop O

reasoning O

over O

triples O

( O

jacket_q O

, O

attribute O

, O

black_v O

) O

and(black_q O

, O

image O

, O

jacket_v O

) O

and O

obtain O

the O

intended O

4images O

. O



To O

address O

the O

aforementioned O

limitations O

, O

we O

propose O

a O

Uniﬁed B-MethodName

Transformer I-MethodName

Semantic I-MethodName

Repre- I-MethodName

sentation I-MethodName

framework O

with O

feature O

alignment O

and O

intention O

reasoning O

, O

UniTranSeR B-MethodName

for O

short O

. O



Specif- O



ically O

, O

to O

address O

the O

ﬁrst O

limitation O

, O

we O

stand O

on O

the O

shoulder O

of O

Vision O

- O

and O

- O

Language O

Pre O

- O

training O

( O

VLP O

) O

methods O

( O

Lu O

et O

al O

. O

, O

2019 O

; O

Li O

et O



al O

. O

, O

2019 O

; O

Chen O

et O

al O

. O

, O

2020 O

; O

Li O

et O

al O

. O

, O

2021 O

) O

to O

propose O

a O

uniﬁed O

- O

modal O

Transformer O

encoder O

, O

which O

is O

used O

to O

project O

all O

the O

multimodal O

features O

into O

a O

uniﬁed O

semantic O

space O

to O

prompt O

inter O

- O

modality O

interac- O

tions O

, O

with O

the O

objective O

of O

learning O

better O

repre- O

sentations O

. O



Based O

on O

the O

uniﬁed O

encoder O

, O

we O

fur- O

ther O

address O

the O

second O

limitation O

by O

designing O

a O

feature O

alignment O

module O

to O

perform O

cross O

- O

modal O

feature O

alignment O

. O



Finally O

, O

to O

address O

the O

third O

limitation O

, O

we O

devise O

a O

ﬁne O

- O

grained O

intention O

rea- O

soning O

module O

for O

capturing O

users O

’ O

real O

intentions O

, O

by O

leveraging O

a O

key O

- O

value O

attention O

based O

memory O

mechanism O

to O

perform O

multi O

- O

hop O

knowledge O

query O

for O

generating O

text O

or O

image O

responses O

. O



We O

conduct O

experiments O

on O

MMD B-DatasetName

, O

one O

of O

the O

most O

inﬂuential O

benchmark O

datasets O

for O

multimodal B-TaskName

dialog I-TaskName

generation I-TaskName

. O



We O

follow O

the O

mainstream O

eval- O

uation O

script O

of O

dialog B-TaskName

generation I-TaskName

and O

demonstrate O

that O

UniTranSeR B-MethodName

signiﬁcantly O

outperforms O

the O

cur- O

rent O

state O

- O

of O

- O

the O

- O

art O

baselines O

. O



Ablation O

study O

also O

shows O

the O

efﬁcacy O

of O

each O

component O

in O

improving O

the O

performance O

of O

dialog B-TaskName

generation I-TaskName

, O

and O

a O

furthercase O

study O

reveals O

that O

our O

model O

can O

effectively O

perform O

ﬁne O

- O

grained O

token O

- O

level O

feature O

alignment O

for O

multimodal B-TaskName

dialog I-TaskName

generation I-TaskName

. O



2 O

Related O

Work O

2.1 O



Unimodal B-MethodName

Dialog I-MethodName

Systems I-MethodName

Recent O

years O

has O

witnessed O

the O

remarkable O

success O

in O

textual O

dialog O

systems O

, O

which O

can O

be O

roughly O

divided O

into O

two O

categories O

: O

open O

- O

domain O

conver- O

sations O

with O

casual O

chi O

- O

chat O

( O

Song O

et O

al O

. O

, O

2020 O

; O

Gangal O

et O

al O

. O

, O

2021 O

; O



Chan O

et O

al O

. O

, O

2021 O

; O

Yang O

et O

al O

. O

, O

2021 O

) O

and O

task O

- O

oriented O

dialog O

systems O

( O

Pei O

et O

al O

. O

, O

2021 O

; O

Santra O

et O

al O

. O

, O

2021 O

; O

Wang O

et O

al O

. O

, O

2021 O

; O

Mi O

et O

al O

. O

, O

2021 O

; O

Madotto O

et O

al O

. O

, O

2021 O

; O

Gou O

et O

al O

. O

, O

2021 O

; O

Raghu O

et O

al O

. O

, O

2021 O

) O

, O

which O

are O

designed O

to O

help O

users O

achieve O

speciﬁc O

goals O

. O



Early O

efforts O

mainly O

adopt O

a O

sequence O

- O

to O

- O

sequence O

( O

Seq2Seq O

) O

architec- O

ture O

, O

but O

can O

not O

work O

well O

in O

KB O

retrieval O

and O

rea- O

soning O

. O



To O

alleviate O

this O

problem O

, O

copy O

mecha- O

nism O

( O

Eric O

and O

Manning O

, O

2017 O

) O

have O

been O

adopted O

and O

many O

memory O

augmented O

Seq2Seq O

models O

have O

been O

proposed O

( O

Bordes O

et O

al O

. O

, O

2017 O

; O



Wen O

et O

al O

. O

, O

2018 O

; O

Madotto O

et O

al O

. O

, O

2018 O

; O

Wu O

et O

al O

. O

, O

2019 O

; O

Reddy O

et O

al O

. O

, O

2019 O

; O

Qin O

et O

al O

. O

, O

2019 O

; O

Wang O

et O

al O

. O

, O

2020 O

; O

Qin O

et O

al O

. O

, O

2020 O

) O

, O

which O

achieve O

promising O

results O

. O



2.2 O

Multimodal B-MethodName

Dialog I-MethodName

Systems I-MethodName

With O

the O

ﬂourishing O

of O

social O

media O

platforms O

, O

massive O

amounts O

of O

multimedia O

data O

are O

gener- O

ated O

daily O

, O

which O

poses O

great O

demand O

for O

mul- B-MethodName

timodal I-MethodName

dialog I-MethodName

systems I-MethodName

. O



However O

, O

due O

to O

the O

lack O

of O

large O

- O

scale O

multimodal O

dialog O

datasets O

, O

re- O

searches O

in O

this O

domain O

have O

been O

limited O

. O



To O

this O

end O

, O

Saha O

et O

al O

. O



( O

2018 O

) O

provided O

a O

vertical O

re- O

tail O

domain O

dataset O

MMD B-DatasetName

to O

promote O

the O

research O

and O

proposed O

a O

multimodal B-MethodName

hierarchical I-MethodName

encoder- I-MethodName

decoder I-MethodName

model I-MethodName

( O

MHRED B-MethodName

) O

as O

a O

baseline O

. O



Based O

on O

MHRED B-MethodName

, O

Liao O

et O

al O

. O



( O

2018 O

) O

incorporated O

the O

style O

tips O

into O

a O

knowledge B-MethodName

- I-MethodName

aware I-MethodName

multimodal I-MethodName

di- I-MethodName

alog I-MethodName

model I-MethodName

( O

KMD B-MethodName

) O

. O



Cui O

et O



al O

. O



( O

2019 O

) O

designed O

a O

user B-MethodName

attention I-MethodName

- I-MethodName

guided I-MethodName

multimodal I-MethodName

dialog I-MethodName

system I-MethodName

( O

UMD B-MethodName

) O

by O

additionally O

considering O

the O

hierarchi- O

cal O

product O

taxonomy O

and O

user O

’s O

attention O

to O

prod- O

ucts O

. O



Chauhan O

et O

al O

. O



( O

2019 O

) O

introduced O

an O

ordi- B-MethodName

nal I-MethodName

and I-MethodName

attribute I-MethodName

aware I-MethodName

multimodal I-MethodName

dialog I-MethodName

system I-MethodName

( O

OAM B-MethodName

) O

by O

employing O

a O

novel O

position O

and O

attribute O

aware O

attention O

mechanism O

. O



Later O

, O

Nie O

et O

al O

. O



( O

2019 O

) O

proposed O

a O

multimodal B-MethodName

dialog I-MethodName

system I-MethodName

with I-MethodName

adaptive I-MethodName

decoders I-MethodName

( O

MAGIC B-MethodName

) O

, O

which O

can O

incorporate O

differ- O

ent O

forms O

of O

domain O

knowledge O

to O

generate O

differ- O

ent O

kinds O

of O

responses O

. O



Recently O

, O

combining O

with104 O



Transformer O

( O

Vaswani O

et O

al O

. O

, O

2017 O

) O

, O

He O

et O

al O

. O



( O

2020 O

) O

advanced O

a O

multimodal B-MethodName

dialog I-MethodName

system I-MethodName

via O

capturing O

context O

- O

aware O

dependencies O

of O

semantic O

elements O

( O

MATE B-MethodName

) O

for O

textual B-TaskName

response I-TaskName

generation I-TaskName

. O



Most O

existing O

multimodal B-MethodName

dialog I-MethodName

systems I-MethodName

learn O

intra O

- O

modal O

features O

separately O

for O

later O

feature O

con- O

catenation O

or O

fusion O

. O



Different O

from O

them O

, O

our O

pro- O

posed O

UniTranSeR B-MethodName

can O

project O

all O

the O

multimodal O

features O

into O

a O

uniﬁed O

semantic O

space O

to O

perform O

ﬁne O

- O

grained O

feature O

alignment O

and O

intention O

rea- O

soning O

, O

which O

can O

lead O

to O

more O

accurate O

responses O

. O



Vision O

- O

and O

- O

Language O

Pre O

- O

training O

( O

VLP O

) O

( O

Lu O

et O

al O

. O

, O

2019 O

; O

Li O

et O

al O

. O

, O

2021 O

) O

is O

another O

line O

of O

research O

relevant O

to O

our O

work O

, O

but O

different O

from O

ours O

in O

that O

it O

focuses O

more O

on O

boosting O

the O

performance O

of O

representation O

learning O

, O

while O

the O

multimodal O

dia- O

log O

systems O

focus O

more O

on O

multi O

- O

turn O

multimodal O

interaction O

between O

users O

and O

agents O

. O



3 O

Methodology O

The O

proposed O

UniTranSeR B-MethodName

mainly O

comprises O

three O

parts O

: O

Uniﬁed O

- O

modal O

Transformer O

Semantic O

( O

UTS O

) O

encoder O

( O

Sec O

. O

3.1 O

) O

, O

Feature O

Alignment O

and O

Inten- O

tion O

Reasoning O

( O

FAIR O

) O

layer O

( O

Sec O

. O

3.2 O

) O

, O

and O

Hi- O

erarchical O

Transformer O

Response O

( O

HTR O

) O

decoder O

( O

Sec O

. O

3.3 O

) O

, O

as O

shown O

in O

Figure O

2 O

. O



We O

deﬁne O

the O

multimodal B-TaskName

dialog I-TaskName

generation I-TaskName

task O

as O

gener- O

ating O

the O

most O

likely O

response O

sequence O

Y= O

fy1;y2;;yngand O

selecting O

top- O

kmost O

matched O

images O

, O

giving O

multimodal O

context O

utterances O

U= O

fu1;u2;:::;ujUjgand O



multimodal O

knowledge O

base O

Bas O

inputs O

. O



The O

probability O

of O

a O

textual O

response O

can O

be O

formally O

deﬁned O

as O

, O

P(YjU;B O

) O



= O

nY O

t=1P(ytjy1;:::;yt 1;U;B O

) O

( O

1)whereytrepresents O

the O

current O

token O

decoded O

by O

the O

HTR O

decoder O

. O



The O

UTS O

encoder O

is O

used O

to O

project O

all O

the O

mul- O

timodal O

features O

into O

a O

uniﬁed O

vector O

space O

for O

inter O

- O

modal O

interactions O

, O

while O

the O

FAIR O

layer O

is O

designed O

to O

align O

cross O

- O

modal O

hidden O

features O

, O

with O

textual O

features O

and O

visual O

features O

from O

previous O

UTS O

encoder O

as O

inputs O

. O



Similar O

to O

MAGIC B-MethodName

( O

Nie O

et O

al O

. O

, O

2019 O

) O

, O

our O

HTR O

decoder O

is O

designed O

to O

de- O

code O

three O

types O

of O

responses O

: O

general O

responses O

that O

refer O

to O

the O

highly O

frequent O

responses O

( O

e.g. O

, O

courtesy O

greetings O

) O

in O

the O

conversation O

, O

such O

as O

“ O

How O

can O

I O

help O

you O

? O

” O

; O

intention O

- O

aware O

responses O

that O

refer O

to O

the O

task O

- O

oriented O

utterances O

, O

such O

as O

“ O

Found O

some O

similar O

black O

leather O

- O

jackets O

for O

you O

” O

; O

and O

multimodal O

responses O

that O

refer O

to O

the O

intention- O

aware O

responses O

with O

image O

output O

. O



The O

response O

type O

is O

determined O

by O

a O

query O

vector O

Qfrom O

the O

FAIR O

layer O

, O

in O

which O

an O

intention O

classiﬁer O

is O

trained O

to O

decide O

which O

kind O

of O

response O

should O

be O

given O

out O

. O



3.1 O

UTS O

Encoder O

We O

ﬁrst O

use O

a O

text O

embedder O

and O

an O

image O

embed- O

der O

to O

extract O

textual O

features O

and O

visual O

features O

, O

respectively O

, O

and O

extract O

informative O

features O

from O

external O

knowledge O

by O

utilizing O

both O

text O

and O

image O

embedders O

. O



Afterwards O

, O

we O

feed O

these O

three O

kinds O

of O

features O

into O

a O

uniﬁed O

Transformer O

encoder O

for O

uniﬁed O

- O

modal O

semantic O

representation O

learning O

. O



Text O

Embedder O

. O



To O

learn O

textual O

intra O

- O

modal O

features O

, O

we O

use O

a O

BERT O

tokenizer O

to O

split O

the O

in- O

put O

sentence O

into O

words O

and O

exploit O

a O

single O

trans- O

former O

layer O

to O

obtain O

these O

words O

’ O

initial O

embed- O

dings O

. O



Note O

the O

self O

- O

attention O

mechanism O

in O

Trans- O

former O

is O

order O

- O

less O

. O



So O

, O

it O

is O

necessary O

to O

encode O

the O

words O

’ O

position O

as O

additional O

inputs O

. O



The O

ﬁnal105 O



representation O

for O

each O

word O

is O

derived O

via O

sum- O

ming O

up O

its O

word O

embedding O

and O

position O

embed- O

ding O

, O

followed O

by O

a O

layer O

normalization O

( O

LN O

) O

layer O

. O



Image O

Embedder O

. O



To O

learn O

visual O

intra O

- O

modal O

features O

, O

we O

use O

a O

contour O

slicer O

to O

cut O

the O

input O

images O

into O

patches O

and O

exploit O

ResNet-50 O

( O

He O

et O

al O

. O

, O

2016 O

) O

to O

extract O

these O

patches O

’ O

visual O

fea- O

tures O

. O



We O

notice O

that O

people O

usually O

focus O

on O

four O

parts O

of O

a O

clothing O

image O

: O

head O

, O

upper O

body O

, O

lower O

body O

, O

and O

feet O

, O

so O

we O

intuitively O

use O

an O

equal O

- O

height O

mode O

to O

slice O

an O

image O

into O

four O

patches O

, O

which O

efﬁciently O

solves O

the O

problem O

of O

region O

feature O

extraction O

, O

without O

using O

com- O

plex O

target O

detection O

networks O

such O

as O

Faster O

R- O

CNN O

( O

Ren O

et O

al O

. O

, O

2015 O

) O

. O



Then O

, O

we O

feed O

the O

patches O

into O

ResNet-50 O

to O

get O

the O

patches O

’ O

initial O

embed- O

dings O

. O



Similarly O

, O

we O

also O

encode O

the O

position O

features O

for O

each O

patch O

via O

a O

4 O

- O

dimensional O

vec- O

tor[image O

_ O

index;patch O



_ O

index;width;height O

] O

. O



Both O

visual O

and O

position O

features O

are O

then O

fed O

through O

a O

fully O

- O

connected O

( O

FC O

) O

layer O

, O

to O

be O

pro- O

jected O

into O

the O

same O

embedding O

space O

. O



The O

ﬁnal O

visual O

embedding O

for O

each O

patch O

is O

obtained O

by O

ﬁrst O

summing O

up O

the O

two O

FC O

outputs O

, O

and O

then O

passing O

them O

through O

an O

LN O

layer O

. O



Knowledge O

Embedder O

. O



To O

integrate O

informa- O

tive O

features O

from O

external O

knowledge1into O

the O

task O

- O

oriented O

dialog O

, O

we O

equip O

the O

product O

knowl- O

edge O

base O

for O

each O

utterance O

through O

searching O

a O

fashion O

item O

table O

provided O

by O

MMD B-DatasetName

. O



We O

then O

treat O

these O

searched O

knowledge O

entries O

into O

the O

same O

triplet O

format O

, O

i.e. O

, O

( O

product O

, O

match O

, O

product O

) O

, O

( O

product O

, O

attribute O

, O

value O

) O

, O

( O

product O

, O

celebrity O

, O

pas- O

sion_score O

) O

. O



Next O

, O

for O

the O

text O

and O

image O

elements O

of O

these O

triples O

, O

we O

use O

the O

text O

and O

image O

embed- O

ders O

to O

obtain O

their O

respective O

representations O

. O



Uniﬁed O

Transformer O

Encoder O

. O



After O

obtaining O

the O

multimodal O

initial O

embeddings O

, O

denoted O

as O

ht O

, O

hvandhkrespectively O

, O

we O

project O

them O

into O

a O

uniﬁed O

semantic O

space O

to O

obtain O

interactive O

repre- O

sentations O

by O

using O

a O

uniﬁed O

Transformer O

encoder O

. O



Speciﬁcally O

, O

in O

each O

utterance O

, O

the O

textual O

features O

, O

visual O

features O

and O

informative O

features O

correspond O

toltokens O

with O

“ O

[ O

TXT O

] O

” O

, O

4 O

tokens2with O

“ O

[ O

IMG O

] O

” O

and O

4 O

tokens3with O

“ O

[ O

KNG O

] O

” O

. O



In O

order O

to O

integrate O



dialog O

history O

of O

previous O

rounds O

, O

we O

initialize O

the O

current O



[ O

CLS]pby O

using O

the O

representation O

of O

the O

previous O

round O

[ O

CLS]p 1 O

. O



The O

output O

hidden O

state O

representations O

can O

then O

be O

phrased O

as O

: O

Hp O

= O

f  O



[ O

CLS]p 1hp O

t[TXT O

] O

hp O

v[IMG O

] O

hp O

k[KNG] O

( O

2 O

) O

wheref()denotes O

the O

Transformer O

encoder O

, O

Hp O

0 O

denotes O

the O

hidden O

state O

representation O

of O

the O

cur- O

rent O

round O



[ O

CLS]p O

, O

which O

is O

regarded O

as O

the O

con- O



textual O

semantic O

vector O

of O

the O

entire O

utterance O

in O

this O

round O

, O

Hp O

1 O

: O

ldenotes O

the O

representations O

for O

the O

text O

sequence O

, O

Hp O

l+1 O

: O

l+4denotes O

the O

representations O

for O

the O

patch O

sequence O

, O

and O

Hp O

l+5 O

: O

l+8denotes O

the O

representations O

for O

knowledge O

entries O

. O



Note O

the O

su- O

perscriptpis O

omitted O

for O

simplicity O

if O

no O

confusion O

occurs O

in O

the O

following O

discussion O

. O



To O

obtain O

better O

representations O

, O

we O

introduce O

the O

Masked O

Language O

Modeling O

( O

MLM O

) O

loss O

and O

Masked O

Patch O

Modeling O

( O

MPM O

) O

loss O

to O

train O

them O

. O



We O

denote O

the O

input O

words O

as O

w O

= O

fw1;:::;wlg O

, O

the O

image O

patches O

as O

v O



= O

fv1;:::;v O

4 O

g O

, O

the O

knowl- O

edge O

elements O

as O

k O

= O

fk1;:::;k O

4 O

g O

, O

and O

the O

mask O

indices O

asm2NL O

, O

where O

Nis O

the O

natural O

numbers O

andLis O

the O

length O

of O

masked O

tokens O

. O



In O

MLM O

, O

we O

randomly O

mask O

out O

the O

input O

words O

with O

a O

probabil- O

ity O

of O

15 O

% O

, O

and O

replace O

the O

masked O

ones O

wmwith O

a O

special O

token O

“ O

[ O

MASK O

] O

” O

, O

as O

illustrated O

in O

Figure O

3 O

. O



The O

goal O

is O

to O

predict O

these O

masked O

words O

by O

atten- O

tively O

integrating O

the O

information O

of O

their O

surround- O

ing O

wordswnm O

, O

image O

patches O

vand O

knowledge O

elementsk O

, O

by O

minimizing O

the O

following O

loss O

: O

LMLM( O

) O

= O

 E(w;v;k O

) O



UlogP  O

wmjwnm;v;k O

( O

3 O

) O

Similar O

to O

MLM O

, O

in O

MPM O

, O

we O

also O

randomly O

mask O

out O

the O

image O

patches O

and O

use O

zeros O

tensor O

to O

re- O

place O

them O

, O

as O

shown O

in O

Figure O

3 O

. O



Unlike O

textual O

words O

that O

can O

be O

categorized O

as O

discrete O

labels O

, O

visual O

features O

are O

high O

- O

dimensional O

and O

continu- O

ous O

tensors O

, O

thus O

can O

not O

be O

supervised O

via O

a O

nega- O

tive O

log O

- O

likelihood O

loss O

. O



Following O

UNITER B-MethodName

( O

Chen O

et O

al O

. O

, O

2020 O

) O

, O

we O

built O

the O

MPM O

loss O

as O

: O

LMPM( O

) O

= O

E(w;v;k O

) O



Ug  O

vmjvnm;w;k O

( O

4 O

) O

wherevmare O

masked O

image O

patches O

and O

vnmare O

remaining O

patches O

. O



Note O

here O

gis O

deﬁned O

as O

an106 O



L2 O

regression O

function O

, O

where O

g  O

vmjvnm;w;k O

= O

LX O

i=1 O







f O

v(i O

) O

m O

 hv(i O

) O

m O







2 O

2 O

( O

5 O

) O

3.2 O

The O

FAIR O

Layer O

To O

align O

the O

cross O

- O

modal O

features O

for O

accurate O

in- O

tention O

classiﬁcation O

and O

knowledge O

query O

, O

we O

de- O

vise O

a O

feature O

alignment O

and O

intention O

reasoning O

( O

FAIR O

) O

layer O

. O



In O

feature O

alignment O

, O

we O

use O

Image- O



Text O

Matching O

( O

ITM O

) O

and O

Word O

- O

Patch O

Alignment4 O

( O

WPA O

) O

to O

conduct O

a O

two O

- O

level O

alignment O

. O



That O

is O

, O

ITM O

is O

used O

to O

align O

text O

and O

image O

in O

sentence- O

level O

, O

while O

WPA O

is O

used O

to O

align O

each O

split O

word O

and O

each O

sliced O

patch O

in O

token O

- O

level O

. O



In O

intention O

reasoning O

, O

we O

fuse O

f([CLS O

] O

) O

and O

aligned O

entities O

’ O

hidden O

state O

representations O

to O

obtain O

a O

query O

vec- O

torQ O

, O

which O

is O

then O

used O

for O

intention O

classiﬁcation O

and O

knowledge O

query O

. O



3.2.1 O

Feature O

Alignment O

Image O

- O

Text O

Matching O

( O

ITM O

) O

. O



In O

ITM O

, O

we O

use O

the O

outputf([CLS O

] O

) O

of O

the O

uniﬁed O

Transformer O

encoder O

to O

compute O

the O

match O

probability O

of O

the O

sampled O

pair O

. O



Speciﬁcally O

, O

we O

feed O

f([CLS O

] O

) O

into O

an O

FC O

layer O

and O

a O

sigmoid O

function O

to O

predict O

a O

probability O

score O

P(w;v O

) O

, O

which O

is O

between O

0and O

1 O

. O



During O

training O

, O

we O

sample O

a O

positive O

or O

negative O

pair(w;v)from O

the O

dataset O

Dat O

each O

step O

. O



The O

negative O

pair O

is O

created O

by O

randomly O

replacing O

the O

image O

or O

text O

in O

the O

same O

batch O

. O



We O

employ O

a O

binary O

cross O

- O

entropy O

loss O

for O

optimization O

: O

LITM( O

) O



= O

 E(w;v)D[ylogP(w;v)+ O

( O

1 y O

) O

log O

( O

1 P(w;v))](6 O

) O

whereyis O

a O

binary O

truth O

label O

. O



Note O

here O

we O

only O

use O

ITM O

to O

train O

image O

- O

text O

pairs O

but O

without O

con- O

sidering O

the O

knowledge O

vector O

, O

because O

it O

has O

al- O



ready O

matched O

the O

textual O

sequence O

when O

being O

searched O

out O

. O



Word O

- O

Patch O

Alignment O

( O

WPA O

) O

. O



For O

more O

ﬁne- O

grained O

alignment O

between O

each O

word O

and O

image O

patch O

, O

we O

introduce O

a O

WPA O

technology O

, O

which O

is O

used O

to O

train O

the O

consistency O

and O

exclusiveness O

be- O

tween O

these O

cross O

- O

modal O

features O

to O

prompt O

align- O

ment O

. O



We O

use O

a O

WPA O

loss O

to O

supervise O

the O

process O

, O



which O

is O

deﬁned O

as O

: O

LWPA( O

) O

= O

 Xl O

i=1X4 O

j=1Tij O



( O

wi;vj)(7 O

) O

where O



denotes O

the O

cos()similarity O

function O

, O

T2Rl4is O

a O

ground O

truth O

table O

and O

each O

Tij2 O

T O

is O

a O

binary O

label O

0 O

or O

1 O

. O



During O

training O

, O

we O

sample O

positive O

or O

negative O

pairs O

( O

wi;vj)from O

each O

multi- O

modal O

utterance O

to O

construct O

a O

probability O

table O

, O

as O

shown O

in O

Figure O

2 O

. O



The O

above O

loss O

function O

LWPA O

is O

then O

used O

to O

update O

the O

parameters O

. O



During O

inference O

, O

we O

continue O

to O

fuse O

aligned O

entities O

’ O

hid- O

den O

state O

representation O

and O

f([CLS O

] O

) O

to O

obtain O

a O

uniﬁed O

query O

vector O

Q O

, O

which O

contains O

multimodal O

query O

information O

with O

entity O

enhancement O

, O

and O

will O

be O

used O

for O

subsequent O

intention O

reasoning O

. O



3.2.2 O

Intention O

Reasoning O

Intention O

Classify O

( O

IC O

) O

. O



Given O

the O

query O

vector O

Q O

, O

this O

component O

aims O

to O

understand O

the O

users O

’ O

intention O

and O

thereafter O

determine O

which O

type O

of O

response O

should O

be O

generated O

. O



To O

be O

clear O

, O

there O

are O

a O

total O

of O

17types O

labeled O

in O

the O

MMD B-DatasetName

dataset O

, O

and O

each O

user O

’s O

utterance O

is O

labeled O

with O

a O

speciﬁc O

intention O

type O

. O



Following O

MAGIC B-MethodName

, O

we O

customize O

the O

type O

of O

response O

speciﬁcally O

for O

each O

intention O

, O

as O

shown O

in O

Table O

1 O

. O



Subsequently O

, O

we O

leverage O

an O

MLP O

layer O

to O

predict O

Q O

’s O

probability O

distribution O

and O

select O

the O

highest O

probability O

to O

generate O

a O

re- O

sponse O

. O



Besides O

, O

a O

cross O

- O

entropy O

loss O

is O

applied O

to O

optimizing O

the O

intention O

classiﬁer O

: O

LIC( O

) O



= O

XjUj O

i=1X17 O

j=1I O

ijlogP(IijjQ)(8 O

) O

whereP(IijjQ)denotes O

the O

probability O

of O

being O

predicted O

as O

intention O

Iij O

, O

andI O

ijis O

a O

ground O

truth O

label O

. O



The O

intention O

classiﬁer O

is O

trained O

by O

the O

loss O

functionLIC()to O

update O

parameter O

 O

, O

and O

ﬁnally O

outputs O

a O

reliable O

intention O

prediction O

result O



Iin O

the O

inference O

phase O

. O



Knowledge O

Query O

( O

KQ O

) O

. O



Given O

the O

predicted O

intention O

result O

I O

, O

this O

component O

ﬁrst O

determines O

whether O

knowledge O

query O

is O

required O

based O

on O

Ta- O

ble O

1 O

. O



If O

required O

, O

we O

adopt O

a O

key O

- O

value O

mem- O

ory O

mechanism O

to O

query O

all O

embedded O

knowledge O

triples5 O

. O



Speciﬁcally O

, O

these O

embedded O

knowledge O

triples O

are O

divided O

into O

key O

parts O

and O

value O

parts O

, O

which O

are O

respectively O

denoted O

as O

vector O

Kand O

vector O

V. O

Note O

here O

Kis O

obtained O

through O

a O

linear O



fusion O

of O

the O

embedded O

head O

- O

entities O

and O

relations O

. O



The O

knowledge O

query O

process O

is O

as O

follows O

: O



i= O

Softmax  O

QTKi O

( O

9 O

) O

VT O

= O

XjMj O

i=1 O



iVi O

( O

10 O

) O

where O



idenotes O

the O

attentive O

probability O

score O

for O

Ki O

, O

jMjis O

the O

number O

of O

knowledge O

triples O

, O

and O

VTis O

a O

weighted O

sum O

of O

Vi O

, O

which O

will O

be O

used O

for O

textual O

decoding O

in O

an O

intention O

- O

aware O

response O

. O



Multi O

- O

hop O

Recommend O

( O

MR O

) O

. O



Given O

the O

pre- O

dicted O

intention O

result O

Iand O

one O

- O

hop O

query O

re- O



sultVT O

, O

this O

component O



ﬁrst O

needs O

to O

determine O

whether O

an O

image O

recommendation O

is O

required O

based O

on O

Table O

1 O

. O



If O

required O

, O

we O

continue O

to O

use O

VTas O

a O

query O

vector O

to O

perform O

another O

hop O

query O

over O

the O

entire O

knowledge O

base O

, O

which O

implies O

that O

the O

product O

images O

will O

be O

recommended O

, O

if O

the O

key O

parts O

of O

their O

corresponding O

triples O

have O

high O

similarity O

to O

VT O

. O



Speciﬁcally O

, O



i= O

Softmax  O

VT O

TKi O

( O

11 O

) O

After O

deriving O



i O

, O

we O

use O

VI O

= O

fqig O

, O

an O

image O

pointer O

vector O

, O

to O

select O

images O

with O

top O



ifor O

recommendation O

, O

where O

qi=1;ifVi=11512 O

0;otherwise(12 O

) O



and11512is O

a O

column O

vector O

with O

each O

element O

equal O

to O

1 O

, O

which O

denotes O

for O

the O

special O

token O

[ O

URL O

] O

of O

the O

image O

’s O

link O

. O



Note O

here O

512 B-HyperparameterValue

is O

the O

embedding B-HyperparameterName

size I-HyperparameterName

in O

our O

uniﬁed O

Transformer O

encoder O

. O



It O

is O

not O

difﬁcult O

to O

see O

that O

UniTranSeR B-MethodName

can O

extend O

the O

above O

one O

- O

hop O

knowledge O

query O

to O

multi O

- O

hop O

by O

iteratively O

performing O

attention O

- O

based O

key O

- O

value O

reasoning O

and O

ultimately O

achieve O

multi O

- O

hop O

image O

recommendation O

. O



3.3 O

HTR O

Decoder O

As O

mentioned O

earlier O

, O

we O

used O

a O

hierarchy O

mech- O

anism O

to O

decode O

different O

types O

of O

response O

se- O

quences O

, O

including O

general O

responses O

, O

intention- O

aware O

responses O

and O

multimodal O

responses O

. O



They O

share O

the O

same O

uni O

- O

directional O

Transformer O

layer O

, O

but O

the O

semantic O

representations O

fed O

to O

this O

de- O

coder O

are O

different O

. O



Speciﬁcally O

, O

for O

general O

re- O

sponses O

, O

we O

just O

take O

the O

sentence O

- O

level O

represen- O

tationsf([CLS O

] O

) O

as O

input O

. O



For O

intention O

- O

aware O

re- O

sponses O

, O

we O

take O

the O

concatenation O

of O

f([CLS O

] O

) O

and O

attentive O

vector O

VTfollowed O

by O

an O

FC O

layer O

as O

input O

. O



For O

multimodal O

responses O

, O

we O

take O

the O

input O

for O

the O

intention O

- O

aware O

responses O

, O

as O

well O

as O

VI O

, O

the O

image O

pointer O

vector O

, O

as O

input O

. O



4 O

Experimental O

Setup O

4.1 O

Datasets O

and O

Metrics O

To O

evaluate O

the O

performance O

of O

UniTranSeR B-MethodName

, O

we O

conduct O

experiments O

on O

the O

widely O

- O

used O

bench- O

mark O

dataset O

MMD B-DatasetName

contributed O

by O

Saha O

et O

al O

. O



( O

2018 O

) O

. O



The O

MMD B-DatasetName

dataset O

consists O

of O

over O

150k O

conversations O

between O

users O

and O

chatbots O

in O

the O

retail O

domain O

, O

and O

each O

conversation O

describes O

a O

complete O

online O

shopping O

process O

. O



During O

the O

con- O

versations O

, O

the O

user O

proposes O

his O

/ O

her O

requirements O

in O

multimodal O

utterances O

and O

the O

chatbot O

introduces O

different O

products O

step O

by O

step O

until O

they O

make O

a O

deal O

. O



In O

our O

experiments O

, O

we O

follow O

Nie O

et O

al O

. O



( O

2019 O

) O

to O

partition O

MMD B-DatasetName

. O



The O

statistics O

the O

dataset O

after O

partition O

are O

presented O

in O

Table O

2 O

, O

and O

more O

detailed O

statistics O

can O

be O

found O

in O

Appendix O

A.4 O

. O



Following O

several O

previous O

work O

( O

Nie O

et O

al O

. O

, O

2019 O

; O

He O

et O

al O

. O

, O

2020 O

; O

Zhang O

et O

al O

. O

, O

2021 O

) O

, O

we O

use O

Bleu- B-MetricName

n I-MetricName

, O

Nist B-MetricName

and O

Recall@ B-MetricName

kto I-MetricName

evaluate O

our O

model O

over O

two O

basic O

tasks O

separately O

, O

i.e. O

, O

text O

task O

and O

image O

task O

. O



For O

the O

text O

task O

, O

we O

employ O

the O

proposed O

HTR O

decoder O

to O

produce O

all O

general O

responses O

and O

intention O

- O

aware O

responses O

. O



As O

the O

length O

of O

20.07 O

% O

target O

responses O

in O

MMD B-DatasetName

is O

less O

than4 O

, O

such O

as O

“ O

Hello O

! O

” O



and“Thanks O

a O

lot O

! O

” O

, O

we O

follow O

Nie O

et O

al O

. O



( O

2019 O

) O

to O

calculate O

Bleu- B-MetricName

n I-MetricName

by O


varying O

n B-HyperparameterName

from O

1 B-HyperparameterValue

to O

4 B-HyperparameterValue

. O



Note O

higher O

Bleu O

and O

Nist O

scores O

indicate O

that O

more O

n O

- O

gram O

overlaps O

exist O

between O

the O

predicted O

and O

target O

responses O

, O

and O

hence O

are O

more O

favorable O

. O



For O

the O

image O

task O

, O

we O

adopt O

Recall@ B-MetricName

kto I-MetricName

evaluate O

the O

efﬁcacy O

of O

image O

response O

, O

where O

k B-HyperparameterName

is O

varied O

from O

1 B-MetricValue

to O

3 B-MetricValue

. O



Note O

the O

image O

response O

is O

correct O

only O

if O

the O

positive O

image O

is O

recommended O

in O

the O

top- O

kproduct O

images O

. O



4.2 O

Baselines O

We O

compare O

our O

model O

with O

the O

following O

state O

- O

of- O

the O

- O

art O

baselines O

. O



•MHRED B-MethodName

( O

Saha O

et O

al O

. O

, O

2018)6is O

the O

ﬁrst O

base- O

line O

work O

to O

integrate O

the O

visual O

features O

into O

a O

hierarchical O

encoder O

- O

decoder O

model O

for O

their O

constructed O

MMD B-DatasetName

dataset O

. O



•KMD B-MethodName

( O

Liao O

et O

al O

. O

, O

2018 O

) O

incorporates O

the O

style O

tips O

into O

the O

memory O

augmented O

neural O

model O

and O

adopts O

deep O

reinforcement O

learning O

to O

boost O

the O

performance O

. O



•UMD B-MethodName

( O

Cui O

et O

al O

. O

, O

2019)7proposes O

a O

user O

attention O

- O

guided O

multimodal O

dialog O

system O

by O

considerring O

the O

hierarchical O

product O

taxon- O

omy O

and O

the O

user O

’s O

attention O

to O

products O

. O



•OAM B-MethodName

( O

Chauhan O

et O

al O

. O

, O

2019 O

) O

proposes O

a O

novel O

ordinal O

and O

attribute O

aware O

attention O

mecha- O

nism O

for O

multimodal B-TaskName

dialog I-TaskName

generation I-TaskName

. O



•MAGIC B-MethodName

( O

Nie O

et O

al O

. O

, O

2019)8adopts O

the O

adap- O

tive O

decoders O

with O

intention O

understanding O

to O

explicitly O

generate O

three O

types O

of O

responses O

. O



•MATE B-MethodName

( O

He O

et O

al O

. O

, O

2020)9utilizes O

a O

multi- O

modal O

element O

- O

level O

encoder O

to O

integrate O

dia- O

log O

context O

and O

leverages O

a O

knowledge O

- O

aware O

two O

- O

stage O

decoder O

for O

response B-TaskName

generation I-TaskName

, O

and O

achieves O

state O

- O

of O

- O

the O

- O

art O

performance O

. O



6https://github.com/amritasaha1812/MMD_Code O

7https://github.com/ChenTsuei/UMD O

8https://acmmultimedia.wixsite.com/magic O

. O



9https://github.com/githwd2016/MATE/tree/dev4.3 O

Implementation O

Details O

Following O

Saha O

et O

al O

. O



( O

2018 O

) O

and O

Nie O

et O

al O

. O



( O

2019 O

) O

, O

we O

utilize O

two O

- O

turn O

utterances O

prior O

to O

the O

target O

response O

as O

the O

context O

, O

and O

set O

the O

vocabulary O

size O

to26;422 O

. O



In O

our O

trainings O

, O

the O

batch B-HyperparameterName

size I-HyperparameterName

is O

set O

to O

64 B-HyperparameterValue

, O

learning B-HyperparameterName

rate I-HyperparameterName

is O

set O

to O

1e 4 B-HyperparameterValue

and O



the O

max O

number O

of O

training B-HyperparameterName

epoches I-HyperparameterName

is O

set O

to O

1e4 B-HyperparameterValue

. O



Adam O

optimizer O

is O

used O

to O

optimize O

all O

models O

. O



All O

experiments O

are O

conducted O

with O

PyTorch O

. O



More O

details O

about O

hyper- O

parameter O

settings O

can O

be O

found O

in O

Appendix O

A.1 O

. O



5 O

Evaluation O

Results O

5.1 O

Response O

Quality O

Evaluation O

Automatic O

Evaluation O

Following O

KMD B-MethodName

, O

UMD B-MethodName

and O

MAGIC B-MethodName

, O

we O

evaluate O

model O

performance O

auto- O

matically O

from O

two O

aspects O

: O

text O

response O

and O

im- O

age O

response O

. O



From O

the O

results O

in O

Table O

3 O

, O

we O

can O

observe O

that O

our O

model O

UniTranSeR B-MethodName

achieves O

the O

state O

- O

of O

- O

the O

- O

art O

performance O

on O

both O

tasks O

. O



Speciﬁ- O

cally O

, O

in O

text O

task O

, O

UniTranSeR B-MethodName

exhibits O

the O

highest O

Bleu B-MetricName

- I-MetricName

n I-MetricName

with O

varying O

n B-HyperparameterName

from O

1 B-HyperparameterValue

to O

4 B-HyperparameterValue

compared O

with O

other O

baselines O

, O

indicating O

that O

our O

model O

can O

gen- O

erate O

responses O

closer O

to O

the O

golden O

ones O

. O



More- O

over O

, O

our O

model O

outperforms O

MATE B-MethodName

, O

a O

recent O

model O

that O

can O

capture O

context O

- O

aware O

dependencies O

of O

se- O

mantic O

elements O

, O

by O

26.3% B-MetricValue

in O

Bleu-4 B-MetricName

score O

, O

which O

veriﬁes O

the O

effectiveness O

of O

our O

model O

in O

learning O

cross O

- O

modal O

feature O

alignment O

and O

conduct O

inten- O

tion O

reasoning O

to O

generate O

more O

accurate O

and O

infor- O

mative O

responses O

. O



In O

image O

task O

, O

an O

extremely O

dif- O

ﬁcult O

performance O

improvement O

can O

be O

observed O

, O

which O

further O

veriﬁes O

the O

superiority O

of O

our O

model O

. O



Human O

Evaluation O



The O

human O

evaluation O

mainly O

focuses O

on O

four O

aspects O

: O

ﬂuency O

, O

relevance O

, O

correctness O

, O

and O

informativeness O

, O

which O

are O

all O

im- O

portant O

for O

task O

- O

oriented O

dialogue O

systems O

( O

Cui O

et O

al O

. O

, O

2019 O

; O

Nie O

et O

al O

. O

, O

2019 O

; O

He O

et O

al O

. O

, O

2020 O

) O

. O



We O

ﬁrst O

randomly O

selected O

200dialogs O

from O

the O

MMD B-DatasetName

datasets O

, O

and O

used O

different O

models O

to O

generate O

re- O

sponses O

, O

including O

UMD B-MethodName

, O

OAM B-MethodName

, O

MAGIC B-MethodName

, O

MATE B-MethodName



and O

UniTranSeR. B-MethodName

Then O

, O

we O

hired O

human O

experts O

to O

score O

the O

responses O

and O

golden O

responses O

in O

blind O

review O

on O

a O

scale O

from O

1to5 O

, O

which O

simulated O

a O

real O

- O

life O

multimodal O

task O

- O

oriented O

conversation O

scenario O

. O



By O

calculating O

the O

average O

score O

of O

the O

above O

metrics O

, O

we O

obtained O

the O

ﬁnal O

manual O

evalua- O

tion O

results O

, O

as O

shown O

in O

Table O

4 O

. O



It O

can O

be O

observed O

that O

UniTranSeR B-MethodName

consistently O

outperforms O

the O

other O

four O

models O

on O

all O

metrics O

, O

which O

is O

in O

line O

with O

the O

results O

of O

automatic O

evaluation O

. O



5.2 O

Ablation O

Study O

In O

this O

part O

, O

we O

perform O

ablation O

experiments O

to O

evaluate O

the O

effectiveness O

of O

each O

component O

. O



We O

focus O

on O

ﬁve O

crucial O

components O

and O

set O

them O

ac- O

cordingly O

: O

1 O

) O

w/o O

UTS O

Encoder O

denotes O

that O

we O

use O

a O

BiGRU O

to O

replace O

the O

uniﬁed O

- O

modal O

Transformer O

encoder O

for O

multimodal O

encoding O

; O

2 O

) O

w/o O

HTR O

De- O

coder O

denotes O

that O

we O

use O

a O

Uni O

- O

directional O

GRU O

to O

replace O

the O

hierarchical O

Transformer O

decoder O

for O

response B-TaskName

generation I-TaskName

; O

3 O

) O

w/o O

ITM O

denotes O

that O

we O

remove O

theLITMloss O

to O

make O

the O

parameters O

not O

updated O

; O

4 O

) O

w/o O

WPA O

denotes O

that O

we O

remove O

the O

LWPA O

loss O

and O

just O

regard O

the O

sentence O

- O

level O

rep- O

resentationf([CLS O

] O

) O

as O

query O

vector O

Qto O

query O

knowledge O

; O

5 O

) O

w/o O

IR O

Module O

denotes O

that O

we O

re- O

move O

the O

IC O

and O

KQ O

components O

and O

just O

adopt O

the O

context O

vector O

f([CLS O

] O

) O

to O

generate O

responses10 O

; O

From O

Table O

5 O

, O

we O

can O

observe O

that O

removing O

each O

component O

will O

result O

in O

a O

performance O

degrada- O

tion O

. O



Speciﬁcally O

, O

w/o O

IR O

Module O

causes O

54.96 B-MetricValue

% I-MetricValue

drops O

in O

Bleu-4 B-MetricName

score O

and O

54.18 B-MetricValue

% I-MetricValue

drops O

in O

Nist B-MetricName



score O

, O

which O

veriﬁes O

the O

great O

efﬁcacy O

of O

intention O

classify O

and O

knowledge O

query O

components O

. O



More- O

over O

, O

w/o O

WPA O

, O

w/o O

ITM O

and O

w/o O

UTS O

Encoder O

respectively O

cause O

28.54 B-MetricValue

% I-MetricValue

, O

20.48 B-MetricValue

% I-MetricValue

and O

14.37 B-MetricValue

% I-MetricValue

drops O

in O

Nist B-MetricName

score O

, O

which O

further O

demonstrates O

the O

effectiveness O

of O

cross O

- O

modal O

feature O

alignment O

and O

uniﬁed O

- O

modal O

semantic O

encoding O

. O



5.3 O

Case O

Study O

and O

Visualization O

To O

better O

illustrate O

the O

advantage O

of O

our O

model O

and O

understand O

what O

the O

feature O

alignment O

module O

has O

learned O

, O

we O

visualize O

several O

examples O

of O

text O

- O

to- O

image O

attention O

, O

as O

shown O

in O

Figure O

4 O

. O



It O

can O

be O

ob- O

served O

that O

our O

model O

is O

able O

to O

capture O

ﬁne O

- O

grained O

entity O

alignment O

between O

different O

modalities O

. O



The O

reason O

may O

be O

that O

: O

1 O

) O

We O

adopt O

a O

uniﬁed O

- O

modal O

Transformer O

semantic O

encoder O

, O

which O

enables O

to O

map O

different O

modalities O

of O

semantic O

cues O

into O

a O

same O

vector O

space O

to O

prompt O

inter O

- O

modality O

inter- O

actions O

for O

better O

representations O

; O

2 O

) O

Based O

on O

the O

obtained O

representations O

, O

the O

WPA O

technology O

can O

help O

supervise O

ﬁne O

- O

grained O

word O

- O

patch O

alignment O

, O

which O

is O

beneﬁcial O

to O

identifying O

user O

’s O

real O

inten- O

tion O

and O

generate O

more O

intention O

- O

aware O

responses O

. O



6 O

Conclusion O

In O

this O

paper O

, O

we O

propose O

a O

Uniﬁed B-MethodName

Transformer I-MethodName

Semantic I-MethodName

Representation I-MethodName

framework O

with O

feature O

alignment O

and O

intention O

reasoning O

, O

referred O

to O

Uni- B-MethodName

TranSeR. I-MethodName



Speciﬁcally O

, O

we O

project O

the O

multimodal O

features O

into O

a O

uniﬁed O

semantic O

space O

by O

utilizing O

a O

Transformer O

encoder O

to O

prompt O

inter O

- O

modal O

inter- O

actions O

. O



We O

further O

design O

a O

feature O

alignment O

and O

intention O

reasoning O

layer O

to O

conduct O

cross O

- O

modal O

feature O

alignment O

and O

ﬁne O

- O

grained O

intention O

rea-110 O



soning O

, O

with O

the O

objective O

of O

generating O

more O

accu- O

rate O

and O

intention O

- O

aware O

responses O

. O



Experiments O

on O

the O

representative O

MMD B-DatasetName

dataset O

demonstrate O

the O

effectiveness O

and O

superior O

performance O

of O

our O

UniTranSeR B-MethodName

model O

in O

both O

automatic O

and O

human O

evaluation O

. O



References O

Antoine O

Bordes O

, O

Y O

- O

Lan O

Boureau O

, O

and O

Jason O

Weston O

. O



2017 O

. O



Learning O

end O

- O

to O

- O

end O

goal O

- O

oriented O

dialog O

. O



In5th O

International O

Conference O

on O

Learning O

Rep- O

resentations O

, O

ICLR O

2017 O

, O

Toulon O

, O

France O

, O

April O

24- O

26 O

, O

2017 O

, O

Conference O

Track O

Proceedings O

. O



OpenRe- O

view.net O

. O



Zhangming O

Chan O

, O

Lemao O

Liu O

, O

Juntao O

Li O

, O

Haisong O

Zhang O

, O

Dongyan O

Zhao O

, O

Shuming O

Shi O

, O

and O

Rui O

Yan O

. O

2021 O

. O



Enhancing O

the O

open O

- O

domain O

dialogue O

eval- O

uation O

in O

latent O

space O

. O



In O

Findings O

of O

the O

Associ- O

ation O

for O

Computational O

Linguistics O

: O

ACL O

/ O

IJCNLP O

2021 O

, O

Online O

Event O

, O

August O

1 O

- O

6 O

, O

2021 O

, O

volume O

ACL O

/ O

IJCNLP O

2021 O

of O

Findings O

of O

ACL O

, O

pages O

4889 O

– O

4900 O

. O



Association O

for O

Computational O

Linguistics O

. O



Hardik O

Chauhan O

, O

Mauajama O

Firdaus O

, O

Asif O

Ekbal O

, O

and O

Pushpak O

Bhattacharyya O

. O



2019 O

. O



Ordinal O

and O

attribute O

aware O

response B-TaskName

generation I-TaskName

in O

a O

multimodal O

dialogue O

system O

. O



In O

Proceedings O

of O

the O

57th O

Conference O

of O

the O

Association O

for O

Computational O

Linguistics O

, O

ACL O

2019 O

, O

Florence O

, O

Italy O

, O

July O

28- O

August O

2 O

, O

2019 O

, O

Vol- O

ume O

1 O

: O

Long O

Papers O

, O

pages O

5437–5447 O

. O



Association O

for O

Computational O

Linguistics O

. O



Yen O

- O

Chun O

Chen O

, O

Linjie O

Li O

, O

Licheng O

Yu O

, O

Ahmed O

El O

Kholy O

, O

Faisal O

Ahmed O

, O

Zhe O

Gan O

, O

Yu O

Cheng O

, O

and O

Jingjing O

Liu O

. O

2020 O

. O



UNITER B-MethodName

: O

universal O

image O

- O

text O

representation O

learning O

. O



In O

Computer O

Vision O

- O

ECCV O

2020 O

- O

16th O

European O

Conference O

, O

Glasgow O

, O

UK O

, O

Au- O

gust O

23 O

- O

28 O

, O

2020 O

, O

Proceedings O

, O

Part O

XXX O

, O

volume O

12375 O

of O

Lecture O

Notes O

in O

Computer O

Science O

, O

pages O

104–120 O

. O



Springer O

. O



Chen O

Cui O

, O

Wenjie O

Wang O

, O

Xuemeng O

Song O

, O

Minlie O

Huang O

, O

Xin O

- O

Shun O

Xu O

, O

and O

Liqiang O

Nie O

. O

2019 O

. O



User O

attention O

- O

guided O

multimodal O

dialog O

systems O

. O



In O

Pro- O

ceedings O

of O

the O

42nd O

International O

ACM O

SIGIR O

Con- O

ference O

on O

Research O

and O

Development O

in O

Informa- O

tion O

Retrieval O

, O

SIGIR O

2019 O

, O

Paris O

, O

France O

, O

July O

21- O

25 O

, O

2019 O

, O

pages O

445–454 O

. O

ACM O

. O



Mihail O

Eric O

and O

Christopher O

D. O

Manning O

. O



2017 O

. O



A O

copy O

- O

augmented O

sequence O

- O

to O

- O

sequence O

architecture O

gives O

good O

performance O

on O

task O

- O

oriented O

dialogue O

. O



InProceedings O

of O

the O

15th O

Conference O

of O

the O

Euro- O

pean O

Chapter O

of O

the O

Association O

for O

Computational O

Linguistics O

, O

EACL O

2017 O

, O

Valencia O

, O

Spain O

, O

April O

3 O

- O

7 O

, O

2017 O

, O

Volume O

2 O

: O

Short O

Papers O

, O

pages O

468–473 O

. O



As- O

sociation O

for O

Computational O

Linguistics O

. O



Varun O

Gangal O

, O

Harsh O

Jhamtani O

, O

Eduard O

H. O

Hovy O

, O

and O

Taylor O

Berg O

- O

Kirkpatrick O

. O

2021 O

. O



Improving O

auto- O

mated O

evaluation O

of O

open O

domain O

dialog O

via O

diversereference O

augmentation O

. O



In O

Findings O

of O

the O

Associ- O

ation O

for O

Computational O

Linguistics O

: O

ACL O

/ O

IJCNLP O

2021 O

, O

Online O

Event O

, O

August O

1 O

- O

6 O

, O

2021 O

, O

volume O

ACL O

/ O

IJCNLP O

2021 O

of O

Findings O

of O

ACL O

, O

pages O

4079 O

– O

4090 O

. O



Association O

for O

Computational O

Linguistics O

. O



Yanjie O

Gou O

, O

Yinjie O

Lei O

, O

Lingqiao O

Liu O

, O

Yong O

Dai O

, O

and O

Chunxu O

Shen O

. O

2021 O

. O



Contextualize O

knowledge O

bases O

with O

transformer O

for O

end O

- O

to O

- O

end O

task O

- O

oriented O

dialogue O

systems O

. O



In O

Proceedings O

of O

the O

2021 O

Con- O

ference O

on O

Empirical O

Methods O

in O

Natural O

Language O

Processing O

, O

EMNLP O

2021 O

, O

Virtual O

Event O

/ O

Punta O

Cana O

, O

Dominican O

Republic O

, O

7 O

- O

11 O

November O

, O

2021 O

, O

pages O

4300–4310 O

. O



Association O

for O

Computational O

Linguistics O

. O



Kaiming O

He O

, O

Xiangyu O

Zhang O

, O

Shaoqing O

Ren O

, O

and O

Jian O

Sun O

. O

2016 O

. O



Deep O

residual O

learning O

for O

image O

recog- O

nition O

. O



In O

2016 O

IEEE O

Conference O

on O

Computer O

Vi- O

sion O

and O

Pattern O

Recognition O

, O

CVPR O

2016 O

, O

Las O

Ve- O

gas O

, O

NV O

, O

USA O

, O

June O

27 O

- O

30 O

, O

2016 O

, O

pages O

770–778 O

. O



IEEE O

Computer O

Society O

. O



Weidong O

He O

, O

Zhi O

Li O

, O

Dongcai O

Lu O

, O

Enhong O

Chen O

, O

Tong O

Xu O

, O

Baoxing O

Huai O

, O

and O

Jing O

Yuan O

. O



2020 O

. O



Multi- O

modal O

dialogue O

systems O

via O

capturing O

context O

- O

aware O

dependencies O

of O

semantic O

elements O

. O



In O

MM O

’ O

20 O

: O

The O

28th O

ACM O

International O

Conference O

on O

Multi- O

media O

, O

Virtual O

Event O

/ O

Seattle O

, O

WA O

, O

USA O

, O

October O

12 O

- O

16 O

, O

2020 O

, O

pages O

2755–2764 O

. O

ACM O

. O



Liunian O

Harold O

Li O

, O

Mark O

Yatskar O

, O

Da O

Yin O

, O

Cho O

- O

Jui O

Hsieh O

, O

and O

Kai O

- O

Wei O

Chang O

. O



2019 O

. O



Visualbert B-MethodName

: O



A O

simple O

and O

performant O

baseline O

for O

vision O

and O

lan- O

guage O

. O



CoRR O

, O

abs/1908.03557 O

. O



Wei O

Li O

, O

Can O

Gao O

, O

Guocheng O

Niu O

, O

Xinyan O

Xiao O

, O

Hao O

Liu O

, O

Jiachen O

Liu O

, O

Hua O

Wu O

, O

and O

Haifeng O

Wang O

. O



2021 O

. O



UNIMO B-MethodName

: O

towards O

uniﬁed O

- O

modal O

understand- O

ing O

and O

generation O

via O

cross O

- O

modal O

contrastive O

learn- O

ing O

. O



In O

Proceedings O

of O

the O

59th O

Annual O

Meeting O

of O

the O

Association O

for O

Computational O

Linguistics O

and O

the O

11th O

International O

Joint O

Conference O

on O

Natural O

Language O

Processing O

, O

ACL O

/ O

IJCNLP O

2021 O

, O

( O

Volume O

1 O

: O

Long O

Papers O

) O

, O

Virtual O

Event O

, O

August O

1 O

- O

6 O

, O

2021 O

, O

pages O

2592–2607 O

. O



Association O

for O

Computational O

Linguistics O

. O



Lizi O

Liao O

, O

Yunshan O

Ma O

, O

Xiangnan O

He O

, O

Richang O

Hong O

, O

and O

Tat O

- O

Seng O

Chua O

. O



2018 O

. O



Knowledge O

- O

aware O

multi- O

modal O

dialogue O

systems O

. O



In O

2018 O

ACM O

Multimedia O

Conference O

on O

Multimedia O

Conference O

, O

MM O

2018 O

, O

Seoul O

, O

Republic O

of O

Korea O

, O

October O

22 O

- O

26 O

, O

2018 O

, O

pages O

801–809 O

. O

ACM O

. O



Jiasen O

Lu O

, O

Dhruv O

Batra O

, O

Devi O

Parikh O

, O

and O

Stefan O

Lee O

. O

2019 O

. O



Vilbert B-MethodName

: O

Pretraining O

task O

- O

agnostic O

visi- O

olinguistic O

representations O

for O

vision O

- O

and O

- O

language O

tasks O

. O



In O

Advances O

in O

Neural O

Information O

Process- O

ing O

Systems O

32 O

: O

Annual O

Conference O

on O

Neural O

Infor- O

mation O

Processing O

Systems O

2019 O

, O

NeurIPS O

2019 O

, O

De- O

cember O

8 O

- O

14 O

, O

2019 O

, O

Vancouver O

, O

BC O

, O

Canada O

, O

pages O

13–23 O

. O



Andrea O

Madotto O

, O

Zhaojiang O

Lin O

, O

Zhenpeng O

Zhou O

, O

Se- O

ungwhan O

Moon O

, O

Paul O

A. O

Crook O

, O

Bing O

Liu O

, O

Zhou O

Yu,111 O



Eunjoon O

Cho O

, O

Pascale O

Fung O

, O

and O

Zhiguang O

Wang O

. O

2021 O

. O



Continual O

learning O

in O

task O

- O

oriented O

dialogue O

systems O

. O



In O

Proceedings O

of O

the O

2021 O

Conference O

on O

Empirical O

Methods O

in O

Natural O

Language O

Processing O

, O

EMNLP O

2021 O

, O

Virtual O

Event O

/ O

Punta O

Cana O

, O

Domini- O

can O

Republic O

, O

7 O

- O

11 O

November O

, O

2021 O

, O

pages O

7452 O

– O

7467 O

. O



Association O

for O

Computational O

Linguistics O

. O



Andrea O

Madotto O

, O

Chien O

- O

Sheng O

Wu O

, O

and O

Pascale O

Fung O

. O



2018 O

. O



Mem2seq B-MethodName

: O

Effectively O

incorporating O

knowl- O

edge O

bases O

into O

end O

- O

to O

- O

end O

task O

- O

oriented O

dialog O

sys- O

tems O

. O



In O

Proceedings O

of O

the O

56th O

Annual O

Meeting O

of O

the O

Association O

for O

Computational O

Linguistics O

, O

ACL O

2018 O

, O

Melbourne O

, O

Australia O

, O

July O

15 O

- O

20 O

, O

2018 O

, O

Vol- O

ume O

1 O

: O

Long O

Papers O

, O

pages O

1468–1478 O

. O



Association O

for O

Computational O

Linguistics O

. O



Fei O

Mi O

, O

Wanhao O

Zhou O

, O

Lingjing O

Kong O

, O

Fengyu O

Cai O

, O

Minlie O

Huang O

, O

and O

Boi O

Faltings O

. O

2021 O

. O



Self O

- O

training O

improves O

pre O

- O

training O

for O

few O

- O

shot O

learning O

in O

task- O

oriented O

dialog O

systems O

. O



In O

Proceedings O

of O

the O

2021 O

Conference O

on O

Empirical O

Methods O

in O

Natural O

Lan- O

guage O

Processing O

, O

EMNLP O

2021 O

, O

Virtual O

Event O

/ O

Punta O

Cana O

, O

Dominican O

Republic O

, O

7 O

- O

11 O

November O

, O

2021 O

, O

pages O

1887–1898 O

. O



Association O

for O

Computa- O

tional O

Linguistics O

. O



Liqiang O

Nie O

, O

Wenjie O

Wang O

, O

Richang O

Hong O

, O

Meng O

Wang O

, O

and O

Qi O

Tian O

. O



2019 O

. O



Multimodal O

dialog O

sys- O

tem O

: O

Generating O

responses O

via O

adaptive O

decoders O

. O



In O

Proceedings O

of O

the O

27th O

ACM O

International O

Confer- O



ence O

on O

Multimedia O

, O

MM O

2019 O

, O

Nice O

, O

France O

, O

Octo- O

ber O

21 O

- O

25 O

, O

2019 O

, O

pages O

1098–1106 O

. O



ACM O

. O



Jiahuan O

Pei O

, O

Pengjie O

Ren O

, O

and O

Maarten O

de O

Rijke O

. O

2021 O

. O



A O

cooperative O

memory O

network O

for O

personalized O

task O

- O

oriented O

dialogue O

systems O

with O

incomplete O

user O

proﬁles O

. O



In O

WWW O

’ O

21 O

: O

The O

Web O

Conference O

2021 O

, O

Virtual O

Event O

/ O

Ljubljana O

, O

Slovenia O

, O

April O

19 O

- O

23 O

, O

2021 O

, O

pages O

1552–1561 O

. O



ACM O

/ O

IW3C2 O

. O



Libo O

Qin O

, O

Yijia O

Liu O

, O

Wanxiang O

Che O

, O

Haoyang O

Wen O

, O

Yangming O

Li O

, O

and O

Ting O

Liu O

. O



2019 O

. O



Entity O

- O

consistent O

end O

- O

to O

- O

end O

task O

- O

oriented O

dialogue O

system O

with O

KB O

retriever O

. O



In O

Proceedings O

of O

the O

2019 O

Conference O

on O

Empirical O

Methods O

in O

Natural O

Language O

Processing O

and O

the O

9th O

International O

Joint O

Conference O

on O

Nat- O

ural O

Language O

Processing O

, O

EMNLP O

- O

IJCNLP O

2019 O

, O

Hong O

Kong O

, O

China O

, O

November O

3 O

- O

7 O

, O

2019 O

, O

pages O

133 O

– O

142 O

. O



Association O

for O

Computational O

Linguistics O

. O



Libo O

Qin O

, O

Xiao O

Xu O

, O

Wanxiang O

Che O

, O

Yue O

Zhang O

, O

and O

Ting O

Liu O

. O

2020 O

. O



Dynamic O

fusion O

network O

for O

multi- O

domain O

end O

- O

to O

- O

end O

task O

- O

oriented O

dialog O

. O



In O

Proceed- O

ings O

of O

the O

58th O

Annual O

Meeting O

of O

the O

Association O

for O

Computational O

Linguistics O

, O

ACL O

2020 O

, O

Online O

, O

July O

5 O

- O

10 O

, O

2020 O

, O

pages O

6344–6354 O

. O

Association O

for O

Computational O

Linguistics O

. O



Dinesh O

Raghu O

, O

Atishya O

Jain O

, O

Mausam O

, O

and O

Sachindra O

Joshi O

. O

2021 O

. O



Constraint O

based O

knowledge O

base O

distil- O

lation O

in O

end O

- O

to O

- O

end O

task O

oriented O

dialogs O

. O



In O

Find- O

ings O

of O

the O

Association O

for O

Computational O

Linguis- O



tics O

: O

ACL O

/ O

IJCNLP O

2021 O

, O

Online O

Event O

, O

August O

1- O

6 O

, O

2021 O

, O

volume O

ACL O

/ O

IJCNLP O

2021 O

of O

Findings O

ofACL O

, O

pages O

5051–5061 O

. O



Association O

for O

Computa- O

tional O

Linguistics O

. O



Revanth O

Reddy O

, O

Danish O

Contractor O

, O

Dinesh O

Raghu O

, O

and O

Sachindra O

Joshi O

. O



2019 O

. O



Multi O

- O

level O

memory O

for O

task O

oriented O

dialogs O

. O



In O

Proceedings O

of O

the O

2019 O

Con- O

ference O

of O

the O

North O

American O

Chapter O

of O

the O

Asso- O

ciation O

for O

Computational O

Linguistics O

: O

Human O

Lan- O

guage O

Technologies O

, O

NAACL O

- O

HLT O

2019 O

, O

Minneapo- O

lis O

, O

MN O

, O

USA O

, O

June O

2 O

- O

7 O

, O

2019 O

, O

Volume O

1 O

( O

Long O

and O

Short O

Papers O

) O

, O

pages O

3744–3754 O

. O



Association O

for O

Computational O

Linguistics O

. O



Shaoqing O

Ren O

, O

Kaiming O

He O

, O

Ross O

B. O

Girshick O

, O

and O

Jian O

Sun O

. O

2015 O

. O



Faster B-MethodName

R I-MethodName

- I-MethodName

CNN I-MethodName

: O

towards O

real O

- O

time O

object B-TaskName

detection I-TaskName

with O

region O

proposal O

networks O

. O



In O

Advances O

in O

Neural O

Information O

Processing O

Systems O

28 O

: O

Annual O

Conference O

on O

Neural O

Information O

Pro- O

cessing O

Systems O

2015 O

, O

December O

7 O

- O

12 O

, O

2015 O

, O

Mon- O

treal O

, O

Quebec O

, O

Canada O

, O

pages O

91–99 O

. O



Amrita O

Saha O

, O

Mitesh O

M. O

Khapra O

, O

and O

Karthik O

Sankara- O

narayanan O

. O



2018 O

. O



Towards O

building O

large O

scale O

mul- O

timodal O

domain O

- O

aware O

conversation O

systems O

. O



In O

Pro- O

ceedings O

of O

the O

Thirty O

- O

Second O

AAAI O

Conference O

on O

Artiﬁcial O

Intelligence O

, O

( O

AAAI-18 O

) O

, O

the O

30th O

innova- O

tive O

Applications O

of O

Artiﬁcial O

Intelligence O

( O

IAAI-18 O

) O

, O

and O

the O

8th O

AAAI O

Symposium O

on O

Educational O

Ad- O

vances O

in O

Artiﬁcial O

Intelligence O

( O

EAAI-18 O

) O

, O

New O

Or- O

leans O

, O

Louisiana O

, O

USA O

, O

February O

2 O

- O

7 O

, O

2018 O

, O

pages O

696–704 O

. O



AAAI O

Press O

. O



Bishal O

Santra O

, O

Potnuru O

Anusha O

, O

and O

Pawan O

Goyal O

. O

2021 O

. O



Hierarchical O

transformer O

for O

task O

oriented O

dia- O

log O

systems O

. O



In O

Proceedings O

of O

the O

2021 O

Conference O

of O

the O

North O

American O

Chapter O

of O

the O

Association O

for O

Computational O

Linguistics O

: O

Human O

Language O

Technologies O

, O

NAACL O

- O

HLT O

2021 O

, O

Online O

, O

June O

6 O

- O

11 O

, O

2021 O

, O

pages O

5649–5658 O

. O



Association O

for O

Computa- O

tional O

Linguistics O

. O



Haoyu O

Song O

, O

Yan O

Wang O

, O

Wei O

- O

Nan O

Zhang O

, O

Zhengyu O

Zhao O

, O

Ting O

Liu O

, O

and O

Xiaojiang O

Liu O

. O

2020 O

. O



Proﬁle O

consistency O

identiﬁcation O

for O

open O

- O

domain O

dialogue O

agents O

. O



In O

Proceedings O

of O

the O

2020 O

Conference O

on O

Empirical O

Methods O

in O

Natural O

Language O

Process- O

ing O

, O

EMNLP O

2020 O

, O

Online O

, O

November O

16 O

- O

20 O

, O

2020 O

, O

pages O

6651–6662 O

. O



Association O

for O

Computational O

Linguistics O

. O



Ashish O

Vaswani O

, O

Noam O

Shazeer O

, O

Niki O

Parmar O

, O

Jakob O

Uszkoreit O

, O

Llion O

Jones O

, O

Aidan O

N. O

Gomez O

, O

Lukasz O

Kaiser O

, O

and O

Illia O

Polosukhin O

. O

2017 O

. O



Attention O

is O

all O

you O

need O

. O



In O

Advances O

in O

Neural O

Information O

Pro- O

cessing O

Systems O

30 O

: O

Annual O

Conference O

on O

Neural O

Information O

Processing O

Systems O

2017 O

, O

December O

4- O

9 O

, O

2017 O

, O

Long O

Beach O

, O

CA O

, O

USA O

, O

pages O

5998–6008 O

. O



Jian O

Wang O

, O

Junhao O

Liu O

, O

Wei O

Bi O

, O

Xiaojiang O

Liu O

, O

Ke- O

jing O

He O

, O

Ruifeng O

Xu O

, O

and O

Min O

Yang O

. O



2020 O

. O



Dual O

dynamic O

memory O

network O

for O

end O

- O

to O

- O

end O

multi O

- O

turn O

task O

- O

oriented O

dialog O

systems O

. O



In O

Proceedings O

of O

the O

28th O

International O

Conference O

on O

Computational O

Linguistics O

, O

COLING O

2020 O

, O

Barcelona O

, O

Spain O

( O

On- O

line O

) O

, O

December O

8 O

- O

13 O

, O

2020 O

, O

pages O

4100–4110 O

. O

Inter- O

national O

Committee O

on O

Computational O

Linguistics.112 O



Jianhong O

Wang O

, O

Yuan O

Zhang O

, O

Tae O

- O

Kyun O

Kim O

, O

and O

Yun- O

jie O

Gu O

. O

2021 O

. O



Modelling O

hierarchical O

structure O

be- O

tween O

dialogue O

policy O

and O

natural O

language O

genera- O

tor O

with O

option O

framework O

for O

task O

- O

oriented O

dialogue O

system O

. O



In O

9th O

International O

Conference O

on O

Learn- O

ing O

Representations O

, O

ICLR O

2021 O

, O

Virtual O

Event O

, O

Aus- O

tria O

, O

May O

3 O

- O

7 O

, O

2021 O

. O



OpenReview.net O

. O



Haoyang O

Wen O

, O

Yijia O

Liu O

, O

Wanxiang O

Che O

, O

Libo O

Qin O

, O

and O

Ting O

Liu O

. O



2018 O

. O



Sequence O

- O

to O

- O

sequence O

learning O

for O

task O

- O

oriented O

dialogue O

with O

dialogue O

state O

repre- O

sentation O

. O



In O

Proceedings O

of O

the O

27th O

International O

Conference O

on O

Computational O

Linguistics O

, O

COLING O

2018 O

, O

Santa O

Fe O

, O

New O

Mexico O

, O

USA O

, O

August O

20 O

- O

26 O

, O

2018 O

, O

pages O

3781–3792 O

. O



Association O

for O

Computa- O

tional O

Linguistics O

. O



Chien O

- O

Sheng O

Wu O

, O

Richard O

Socher O

, O

and O

Caiming O

Xiong O

. O



2019 O

. O



Global O

- O

to O

- O

local O

memory O

pointer O

networks O

for O

task O

- O

oriented O

dialogue O

. O



In O

7th O

International O

Confer- O

ence O

on O

Learning O

Representations O

, O

ICLR O

2019 O

, O

New O

Orleans O

, O

LA O

, O

USA O

, O

May O

6 O

- O

9 O

, O

2019 O

. O



OpenReview.net O

. O



Ze O

Yang O

, O

Wei O

Wu O

, O

Huang O

Hu O

, O



Can O

Xu O

, O

Wei O

Wang O

, O

and O

Zhoujun O

Li O

. O



2021 O

. O



Open O

domain O

dialogue B-TaskName

genera- I-TaskName

tion I-TaskName

with O

latent O

images O

. O



In O

Thirty O

- O

Fifth O

AAAI O

Con- O

ference O

on O

Artiﬁcial O

Intelligence O

, O

AAAI O

2021 O

, O

Thirty- O

Third O

Conference O

on O

Innovative O

Applications O

of O

Ar- O

tiﬁcial O

Intelligence O

, O

IAAI O

2021 O

, O

The O

Eleventh O

Sym- O

posium O

on O

Educational O

Advances O

in O

Artiﬁcial O

Intel- O



ligence O

, O

EAAI O

2021 O

, O

Virtual O

Event O

, O

February O

2 O

- O

9 O

, O

2021 O

, O

pages O

14239–14247 O

. O



AAAI O

Press O

. O



Haoyu O

Zhang O

, O

Meng O

Liu O

, O

Zan O

Gao O

, O

Xiaoqiang O

Lei O

, O

Yin- O

glong O

Wang O

, O

and O

Liqiang O

Nie O

. O

2021 O

. O



Multimodal O

di- O

alog O

system O

: O

Relational O

graph O

- O

based O

context O

- O

aware O

question B-TaskName

understanding I-TaskName

. O



In O

MM O

’ O

21 O

: O

ACM O

Multime- O

dia O

Conference O

, O

Virtual O

Event O

, O

China O

, O

October O

20 O

- O

24 O

, O

2021 O

, O

pages O

695–703 O

. O

ACM O

. O



Zheng O

Zhang O

, O

Lizi O

Liao O

, O

Minlie O

Huang O

, O

Xiaoyan O

Zhu O

, O

and O

Tat O

- O

Seng O

Chua O

. O

2019 O

. O



Neural O

multimodal O

be- O

lief O

tracker O

with O

adaptive O

attention O

for O

dialogue O

sys- O

tems O

. O



In O

The O

World O

Wide O

Web O

Conference O

, O

WWW O

2019 O

, O

San O

Francisco O

, O

CA O

, O

USA O

, O

May O

13 O

- O

17 O

, O

2019 O

, O

pages O

2401–2412 O

. O



ACM.113 O



A O

Appendices O

A.1 O

Hyperparameters O

Setting O

The O

hyperparameters O

used O

for O

MMD O

dataset O

are O

shown O

in O

Table O

6 O

. O



A.2 O

Description O

of O

Special O

Tokens O



The O

special O

tokens O

used O

in O

our O

experiments O

are O

shown O

in O

Table O

7 O

. O



A.3 O

Loss O

Function O

Our O

total O

loss O

function O

LTotal O

comprises O

three O

parts O

: O

UTS O

encoder O

loss O

LE O

, O

FAIR O

layer O

loss O

LFand O

HTR O

decoder O

lossLD O

, O

which O

can O

be O

calculated O

as O

follows O

: O



LTotal O

= O



ELE+ O



FLF+ O



DLD O

( O

13 O

) O

where O



E B-HyperparameterName

, O



F B-HyperparameterName

and O



D B-HyperparameterName

are O

hyperparameters O

, O

and O

are O

initialized O

equally O

, O

i.e. O

, O

0.33 B-HyperparameterValue

, O
0.33 B-HyperparameterValue

and O
0.33 B-HyperparameterValue

. O



Then O

, O

we O

tune O

them O

on O

the O

veriﬁcation O

set O

to O

obtain O

a O

better O

weight O

setting O

of O

0.30 B-HyperparameterValue

, O
0.35 B-HyperparameterValue

and O
0.35 B-HyperparameterValue

. O



The O

UTS O

encoder O

loss O

LEcontains O

two O

parts O

: O

LMLM O

andLMPM O

, O

LE O

= O

LMLM O



+ O

LMPM O

( O

14 O

) O

the O

FAIR O

layer O

loss O

contains O

three O

parts O

: O

LITM O

, O

LWPA O

andLIC O

: O



LF O

= O

LITM+LWPA O

+ O

LIC O

( O

15 O

) O

and O

the O

HTR O

decoder O

loss O

is O

divided O

into O

two O

types O

: O

the O

textual O

decoding O

loss O

LTXT O

for O

text O

task O

and O

image O

recommend O

loss O

LIMGfor O

image O

task O

, O

which O

is O

consistent O

with O

previous O

work O

( O

Nie O

et O

al O

. O

, O

2019 O

) O

. O



LD O

= O

LTXT+LIMG O

( O

16) O


A.4 O

Dateset O

Statistics O

A O

detailed O

statistics O

of O

the O

MMD B-DatasetName

dataset O

is O

pre- O

sented O

in O

Table O

8 O

. O



A.5 O

Error O

Analysis O

To O

better O

understand O

the O

limitations O

of O

our O

model O

, O

we O

conduct O

an O

error O

analysis O

on O

UniTranSeR. B-MethodName



We O

randomly O

select O

100responses O

generated O

by O

Uni- B-MethodName

TranSeR I-MethodName

that O

achieve O

low O

human O

evaluation O

scores O

in O

the O

test O

set O

of O

MMD B-DatasetName

. O



We O

report O

several O

reasons O

for O

the O

low O

scores O

, O

which O

can O

roughly O

be O

classiﬁed O

into O

four O

categories O

. O



( O

1 O

) O

KB O

information O

in O

the O

generated O

responses O

is O

incorrect O

( O

38 O

% O

) O

, O

especially O

when O

the O

corresponding O

equipped O

knowledge O

base O

is O

large O

and O

complex O

. O



( O

2 O

) O

The O

sentence O

structure O

of O

the O

generated O

responses O

is O

incorrect O

and O

there O

are O

serious O

grammatical O

and O

semantic O

errors O

( O

24 O

% O

) O

. O



( O

3 O

) O

The O

model O

makes O

incomplete O

response O

when O

there O

are O

multiple O

intentions O

contained O

in O

users O

’ O

ut- O

terances O

( O

21 O

% O

) O

. O



( O

4 O

) O

The O

model O

selects O

incorrect O

product O

images O

since O

different O

products O

have O

simi- O

lar O

attributes O

( O

17%). O


