The O
2018 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
was O
held O
in O
Brussels O
, O
Belgium O
from O
October O
31 O
to O
November O
4 O
. O
The O
proceedings O
from O
the O
conference O
were O
published O
in O
a O
volume O
consisting O
of O
1 O
0 O
pages O
. O

The O
man O
who O
was O
elected O
president O
was O
a O
very O
good O
speaker O
. O


 O
The O
man O
who O
was O
elected O
president O
was O
a O
very O
good O
speaker O
. O


 O
The O
man O
who O
was O
elected O
president O
was O
a O
very O
good O
speaker O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
dedicated O
to O
preserving O
the O
privacy O
of O
Neural B-TaskName
Representations I-TaskName
. O

Please O
enter O
a O
text O
. O

This O
article O
discusses O
how O
deep O
learning O
systems O
for O
Natural O
Language O
Processing O
( O
NLP O
) O
can O
be O
attacked O
in O
order O
to O
protect O
privacy O
. O

We O
study O
a O
specific O
type O
of O
attack O
where O
an O
attacker O
tries O
to O
recover O
information O
about O
the O
input O
text O
by O
eavesdropping O
on O
the O
hidden O
representations O
of O
a O
neural O
text O
classifier O
. O

A O
situation O
like O
this O
could O
happen O
when O
a O
neural O
network O
's O
computation O
is O
split O
up O
between O
multiple O
devices O
, O
for O
example O
when O
some O
hidden O
representation O
is O
calculated O
by O
a O
user O
's O
device O
and O
then O
sent O
to O
a O
cloud O
- O
based O
model O
. O

We O
can O
measure O
the O
privacy O
of O
a O
hidden 
representation O
by O
how O
accurately O
an O
attacker O
can O
predict O
specific O
private O
information O
from O
it O
. O
This O
tradeoff O
between O
privacy O
and O
utility O
of O
neural O
representations O
is O
characterized O
by O
how O
much O
information O
is O
revealed O
. O

We O
finally O
propose O
several O
defense O
methods O
based O
on O
modified O
training O
objectives O
and O
demonstrate O
that O
they O
improve O
the O
privacy O
of O
neural O
representations O
. O

The O
following O
sentence O
presents O
an O
adversarial O
scenario O
that O
characterizes O
the O
privacy O
of O
neural O
representations O
for O
NLP O
tasks O
, O
as O
well O
as O
defense O
methods O
designed O
to O
improve O
the O
privacy O
of O
those O
representations O
. O

A O
deep B-MethodName
neural I-MethodName
network I-MethodName
uses O
intermediate O
hidden O
representations O
to O
extract O
features O
from O
its O
input O
. O

The O
representations O
being O
trained O
should O
contain O
features O
that O
are O
useful O
for O
the O
final O
prediction O
in O
order O
to O
be O
accurate O
. O

However O
, O
the O
information O
that O
a O
user O
wants O
to O
keep O
private O
, O
such O
as O
personal O
data O
, O
can O
be O
encoded O
and O
exploited O
for O
adversarial O
usages O
. O

We O
study O
a O
type O
of O
attack O
that O
targets O
neural O
representations O
. O
The O
attacker O
eavesdrops O
on O
the O
hidden O
representations O
of O
novel O
input O
examples O
that O
are O
not O
in O
the O
training O
set O
and O
tries O
to O
recover O
information O
about O
the O
content O
of O
the O
input O
text O
. O

A O
typical O
scenario O
where O
such O
attacks O
would O
occur O
is O
when O
the O
computation O
of O
a O
deep O
neural O
net O
latent O
representation O
is O
sent O
over O
a O
channel O
. O

Figure O
1 O
illustrates O
the O
general O
setting O
where O
an O
attacker O
tries O
to O
guess O
the O
private O
input O
desired O
by O
the O
user O
. O

The O
main O
classifier O
predicts O
a O
label O
y O
from O
a O
text O
x O
, O
and O
the O
attacker O
tries O
to O
recover O
some O
private O
information O
z O
that O
is O
contained O
in O
x. O

The O
latent O
representation O
used O
by O
the O
main O
classifier O
is O
shared O
between O
several O
devices O
, O
as O
Li O
et O
al O
. O
( O
2017 O
) O
found O
. O

For O
example O
, O
if O
a O
user O
wants O
to O
find O
the O
topic O
of O
a O
text O
, O
their O
device O
would O
compute O
a O
representation O
of O
the O
text O
and O
send O
it O
to O
a O
cloud O
- O
based O
neural O
network O
. O

This O
is O
illustrated O
in O
Figure O
1 O
. O

Private O
information O
can O
be O
found O
in O
the O
text O
through O
key O
phrases O
. O

However O
, O
it O
can O
also O
be O
something O
that O
is O
not O
said O
directly O
, O
but O
is O
understood O
. O

For O
example O
, O
it O
is O
possible O
to O
predict O
the O
author O
's O
demographic O
information O
, O
such O
as O
age O
and O
gender O
, O
with O
more O
accuracy O
than O
if O
one O
were O
to O
guess O
randomly O
. O
This O
can O
be O
done O
by O
looking O
at O
linguistic O
cues O
in O
the O
text O
itself O
( O
Rosenthal O
and O
McKeown O
, O
2011 O
; O
Preot O
¸iuc O
- O
Pietro O
et O
al O
. O
, O
2015 O
) O
. O

Some O
of O
the O
private O
information O
correlates O
with O
the O
output O
labels O
, O
and O
therefore O
the O
network O
will O
learn O
it O
. O

There O
is O
a O
tradeoff O
between O
the O
utility O
of O
the O
representation O
and O
its O
privacy O
in O
such O
a O
case O
. O

This O
could O
be O
the O
case O
. O

It O
is O
necessary O
to O
sacrifice O
some O
accuracy O
in O
order O
to O
satisfy O
privacy O
requirements O
. O

However O
, O
not O
all O
private O
information O
is O
relevant O
for O
predicting O
the O
text O
label O
. O

Even O
though O
private O
information O
might O
be O
learned O
incidentally O
, O
_ O
_ O
_ O
_ O
. O

Since O
an O
attacker O
has O
access O
to O
the O
hidden O
representations O
, O
they O
may O
be O
able O
to O
exploit O
them O
to O
gain O
information O
about O
the O
input O
, O
which O
raises O
privacy O
concerns O
. O

The O
main O
focus O
of O
this O
paper O
is O
to O
explore O
the O
following O
situation O
: O
( O
1 O
) O
A O
main O
classifier O
uses O
a O
deep O
network O
to O
predict O
a O
label O
from O
textual O
data O
; O
( O
2 O
) O
An O
attacker O
eavesdrops O
on O
the O
hidden O
layers O
of O
the O
network O
and O
tries O
to O
recover O
information O
about O
the O
input O
text O
of O
unseen O
examples O
. O

In O
contrast O
to O
work O
that O
protecting O
the O
privacy O
of O
examples O
from O
the O
training O
set O
, O
we O
instead O
protect O
the O
privacy O
of O
unseen O
examples O
provided O
, O
for O
example O
, O
by O
a O
user O
. O

An O
example O
of O
a O
potential O
application O
would O
be O
a O
spam O
detection O
service O
that O
does O
not O
access O
user O
data O
. O

The O
emails O
sent O
to O
users O
are O
only O
represented O
by O
their O
vector O
representations O
. O

The O
vector O
representations O
should O
not O
be O
able O
to O
provide O
information O
about O
the O
user O
's O
contacts O
or O
correspondents O
in O
order O
to O
protect O
the O
user O
from O
proﬁling O
. O

This O
paper O
makes O
the O
following O
contributions O
: O


 O
1 O
. O
We O
propose O
a O
metric O
to O
measure O
the O
privacy O
of O
the O
neural O
representation O
of O
an O
input O
for O
Natural O
Language O
Processing O
tasks O
. O

The O
metric O
is O
based O
on O
the O
ability O
of O
an O
attacker O
to O
recover O
information O
about O
the O
input O
from O
the O
latent O
representation O
. O

We O
present O
defense O
methods O
designed O
to O
protect O
against O
this O
type O
of O
attack O
. O

The O
methods O
are O
based O
on O
modiﬁed O
training O
objectives O
and O
lead O
to O
an O
improved O
privacy O
- O
accuracy O
tradeoff O
. O

In O
the O
scenario O
we O
propose O
, O
each O
example O
consists O
of O
a O
triple O
( O
x;y;z O
) O
, O
where O
x O
is O
a O
natural O
language O
text O
, O
y O
is O
a O
single O
label O
( O
e.g. O
topic O
or O
sentiment O
) O
, O
and O
z O
is O
a O
vector O
of O
private O
information O
contained O
in O
x. O

Our O
base O
setting O
consists O
of O
two O
entities O
: O
( O
i O
) O
a O
main O
classifier O
whose O
role O
is O
to O
learn O
to O
predict O
y O
from O
x O
, O
( O
ii O
) O
an O
attacker O
who O
learns O
to O
predict O
z O
from O
the O
latent O
representation O
of O
x O
used O
by O
the O
main O
classifier O
. O

This O
setting O
is O
illustrated O
in O
Figure O
1 O
. O

We O
evaluate O
the O
utility O
of O
a O
specific O
model O
by O
proceeding O
in O
three O
phases O
: O
Phase O
1 O
. O

Training O
of O
the O
attacker O
on O
the O
generated O
dataset O
; O


 O
The O
main O
classifier O
is O
trained O
on O
( O
x O
, O
y O
) O
pairs O
and O
its O
accuracy O
is O
evaluated O
. O
In O
phase O
2 O
, O
a O
dataset O
of O
pairs O
( O
r(x),z O
) O
is O
generated O
for O
the O
attacker O
, O
where O
r O
is O
the O
representation O
function O
of O
the O
main O
classifier O
( O
r O
is O
defined O
in O
section O
2.1 O
) O
. O
In O
phase O
3 O
, O
the O
attacker O
is O
trained O
on O
the O
generated O
dataset O
. O

The O
privacy O
of O
the O
attacker O
's O
network O
is O
measured O
by O
training O
and O
evaluating O
its O
performance O
. O

In O
the O
following O
section O
, O
we O
describe O
the O
main O
classifier O
and O
the O
attacker O
's O
model O
in O
more O
detail O
. O

We O
chose O
a O
standard O
LSTM B-MethodName
architecture I-MethodName
as O
our O
base O
model O
for O
sequence O
classification O
. O

LSTM O
- O
based O
architectures O
have O
been O
found O
to O
be O
effective O
for O
many O
NLP O
tasks O
, O
such O
as O
sentiment B-TaskName
classification O
( O
Wang O
et O
al O
. O
, O
2016 O
) O
and O
text B-TaskName
classification O
( O
Zhou O
et O
al O
. O
, O
2016 O
) O
. O

First O
, O
an O
LSTM O
encoder O
computes O
a O
fixed O
- O
size O
representation O
r(x O
) O
from O
a O
sequence O
of O
tokens O
x= O
( O
x1;x2;:::;x O
n O
) O
projected O
to O
an O
embedding O
space O
. O

We O
denote O
the O
parameters O
used O
to O
construct O
r O
with O
r O
. O

The O
parameters O
of O
the O
LSTM O
and O
word O
embeddings O
are O
both O
included O
. O

The O
encoder O
output O
r(x O
) O
is O
fed O
as O
input O
to O
a O
feedforward O
network O
with O
parameters O
p O
that O
predicts O
the O
label O
y O
of O
the O
text O
, O
with O
a O
softmax O
output O
activation O
. O

In O
a O
standard O
setting O
, O
the O
model O
is O
trained O
to O
minimize O
the O
negative O
log O
- O
likelihood O
of O
the O
labels O
y O
, O
which O
is O
given O
by O
Lm(r;p O
) O
. O

This O
is O
the O
equation O
for O
the O
log O
- O
likelihood O
of O
the O
training O
data O
, O
given O
the O
model O
parameters O
r O
and O
p. O

Assuming O
that O
the O
parameters O
of O
the O
main O
model O
are O
fixed O
, O
we O
train O
the O
attacker O
's O
classifier O
. O

We O
create O
a O
new O
dataset O
consisting O
of O
pairs O
( O
r(x);z(x O
) O
) O
, O
where O
r(x O
) O
is O
the O
hidden O
representation O
used O
by O
the O
main O
model O
and O
z(x O
) O
is O
a O
vector O
of O
private O
categorical O
variables O
. O

This O
sentence O
is O
discussing O
a O
vector O
of O
binary O
variables O
that O
represent O
information O
about O
the O
author O
. O

In O
our O
experiments O
, O
we O
use O
the O
same O
training O
examples O
for O
the O
main O
model O
and O
the O
ablated O
model O
. O

The O
classifier O
of O
the O
attacker O
and O
the O
classifier O
of O
the O
3classifier O
. O

However O
, O
since O
the O
attacker O
has O
access O
to O
the O
representation O
function O
r O
, O
parameterized O
by O
r O
, O
they O
can O
generate O
a O
dataset O
from O
any O
corpus O
containing O
the O
private O
variables O
they O
want O
to O
recover O
. O

In O
other O
words O
, O
it O
is O
not O
necessary O
for O
them O
to O
have O
access O
to O
the O
original O
training O
corpus O
in O
order O
to O
train O
their O
classifier O
. O

The O
attacker O
creates O
a O
second O
neural O
network O
and O
trains O
it O
on O
a O
new O
dataset O
that O
includes O
the O
original O
inputs O
and O
outputs O
as O
well O
as O
the O
desired O
outputs O
. O

This O
classifier O
uses O
a O
sigmoid O
output O
activation O
to O
compute O
the O
probabilities O
of O
each O
binary O
variable O
in O
z O
given O
the O
input O
x O
and O
parameters O
a. O

This O
sentence O
is O
saying O
that O
the O
feedforward O
function O
is O
equal O
to O
the O
function O
r(x O
) O
. O

The O
goal O
of O
the O
training O
is O
to O
minimize O
the O
negative O
log O
- O
likelihood O
of O
z O
: O
La(a O
) O
. O

The O
probability O
of O
z(i O
) O
given O
r(x(i O
) O
) O
and O
alpha O
is O
the O
sum O
of O
log O
P(z(i O
) O
given O
r(x(i O
) O
) O
; O
alpha O
) O
for O
all O
i. O

Assuming O
that O
the O
K O
variables O
in O
z O
are O
independent O
, O
the O
equation O
can O
be O
simplified O
to O
: O


 O
N O


 O
X O


 O
i=1 O


 O
K O


 O
X O


 O
j=1 O


 O
logP(z(i O
) O


 O
jjr(x(i O
) O
) O
; O


 O
a O


 O
) O
; O

Since O
the O
attacker O
only O
acts O
upon O
its O
own O
parameters O
to O
optimize O
this O
loss B-MetricName
, O
the O
parameters O
used O
to O
construct O
rare O
fixed O
. O

We O
use O
the O
attacker O
's O
classifier O
performance O
as O
a O
measure O
of O
privacy O
. O

If O
an O
eavesdropper O
can O
easily O
recover O
information O
about O
the O
input O
document O
, O
then O
its O
accuracy B-MetricName
is O
high O
. O

If O
the O
accuracy B-MetricName
of O
a O
model O
is O
low O
, O
it O
may O
be O
due O
to O
the O
fact O
that O
the O
input O
representation O
does O
not O
contain O
enough O
information O
to O
reconstruct O
the O
data O
, O
and O
mainly O
contains O
information O
that O
is O
useful O
to O
predict O
the O
output O
. O
The O
performance O
of O
a O
single O
attacker O
is O
not O
generally O
enough O
evidence O
to O
conclude O
that O
the O
input O
representation O
is O
robust O
to O
an O
attack O
. O

It O
should O
be O
able O
to O
withstand O
any O
type O
of O
reconstruction O
method O
. O

In O
this O
paper O
we O
only O
experiment O
with O
a O
feedforward O
network O
reconstructor O
, O
which O
is O
a O
powerful O
learner O
. O

We O
propose O
several O
training O
method O
modifications O
aimed O
at O
obfuscation O
in O
the O
following O
sections O
. O

Obtaining O
private O
information O
from O
the O
hidden O
representation O
r(x O
) O
. O

The O
goal O
of O
these O
modifications O
is O
to O
reduce O
the O
amount O
of O
information O
between O
randzto O
make O
the O
prediction O
of O
zhard O
. O

The O
Mutual B-MetricName
Information I-MetricName
( O
MI B-MetricName
) O
between O
randz O
would O
be O
an O
obvious O
choice O
for O
that O
measure O
. O

However O
, O
it O
is O
difficult O
to O
compute O
MI B-MetricName
because O
the O
continuous O
distribution O
of O
rand O
does O
not O
lend O
itself O
well O
to O
stochastic O
optimization O
. O

There O
are O
three O
ways O
to O
defend O
against O
adversarial O
attacks O
. O

We O
will O
now O
present O
three O
training O
methods O
that O
will O
help O
protect O
against O
the O
type O
of O
attack O
described O
in O
the O
previous O
section O
. O

The O
first O
two O
methods O
are O
based O
on O
two O
neural O
networks O
with O
objective O
functions O
that O
are O
in O
competition O
with O
each O
other O
( O
Section O
3.1 O
) O
. O

The O
last O
method O
is O
meant O
at O
discouraging O
the O
model O
from O
clustering O
together O
train- O
. O

For O
example O
, O
consider O
two O
classes O
with O
similar O
private O
variables O
z(Section O
3.2 O
) O
. O

, O
2014 O
) O
. O


 O
We O
propose O
that O
the O
training O
of O
the O
main O
classifier O
be O
framed O
as O
a O
two O
- O
agent O
process O
: O
the O
main O
agent O
and O
an O
Adversarial I-MethodName
generator O
. O
This O
is O
similar O
to O
the O
setting O
of O
Generative B-MethodName
Adversarial I-MethodName
Networks I-MethodName
( O
GAN B-MethodName
, O
Goodfellow O
et O
. O
, O
2014 O
) O
. O

( O
al O
. O
, O
2014 O
) O
. O

The O
generator O
learns O
to O
reconstruct O
examples O
from O
the O
hidden O
representation O
, O
and O
the O
main O
agent O
learns O
to O
perform O
its O
main O
task O
while O
also O
making O
the O
generator O
's O
task O
more O
difficult O
. O

We O
try O
out O
two O
different O
types O
of O
generators O
: O
one O
that O
predicts O
the O
binary O
attributes O
z(x O
) O
that O
stand O
in O
for O
reconstructing O
x(Section O
3.1.1 O
) O
, O
and O
one O
that O
directly O
optimizes O
the O
likelihood O
of O
the O
training O
examples O
based O
on O
characters O
( O
Section O
3.1.2 O
) O
. O

The O
goal O
of O
Adversarial B-TaskName
Classiﬁcation I-TaskName
is O
to O
learn O
a O
function O
that O
can O
accurately O
classify O
data O
points O
into O
one O
of O
two O
classes O
, O
despite O
the O
fact O
that O
there O
is O
some O
inherent O
variability O
or O
noise O
in O
the O
data O
. O

We O
use O
a O
duplicate O
adversarial O
classifier O
, O
with O
parameters O
θ0a O
, O
that O
tries O
to O
predict O
z O
from O
r(x O
) O
. O

It O
is O
trained O
at O
the O
same O
time O
as O
the O
main O
classifier O
. O

The O
training O
examples O
are O
generated O
as O
needed O
, O
and O
they O
change O
over O
time O
as O
the O
main O
classifier O
updates O
its O
own O
parameters O
. O

This O
classifier O
simulates O
an O
attack O
while O
it O
is O
training O
. O

We O
change O
the O
main O
classifier O
's O
objective O
function O
to O
include O
a O
penalty O
when O
the O
adversarial O
classifier O
is O
good O
at O
reconstructing O
. O

The O
main O
classifier O
's O
goal O
is O
to O
update O
its O
parameters O
in O
a O
way O
that O
confuses O
the O
attacker O
who O
is O
trying O
to O
create O
a O
duplicate O
. O

The O
adversarial O
classifier O
optimizes O
La0(x;y;z;0 O
a)= logP(zjr(x);0 O
a O
) O
; O
for O
a O
single O
data O
point O
( O
x;y;z O
) O
. O

The O
main O
classifier O
optimizes O
Lm(x;y;z;r;p)=  O
, O
whereas O
_ O
_ O
_ O
_ O
_ O
. O

P(yjx;r;p O
) O
is O
the O
probability O
of O
y O
given O
x O
, O
r O
, O
and O
p. O

I O
would O
like O
to O
drink O
a O
cup O
of O
coffee O


 O
I O
would O
like O
to O
have O
a O
cup O
of O
coffee O
. O

The O
first O
term O
of O
this O
equation O
is O
the O
log O
- O
likelihood O
of O
the O
labels O
. O

The O
second O
term O
is O
designed O
to O
fool O
the O
adversary O
. O

The O
parameters O
that O
can O
be O
adjusted O
to O
optimize O
a O
machine O
learning O
model O
are O
called O
hyperparameters O
. O

Greater O
than O
zero O
and O
less O
than O
one O
. O

You O
can O
control O
how O
important O
each O
term O
is O
. O

The O
losses O
of O
both O
classifiers O
in O
a O
GAN O
are O
interdependent O
, O
but O
their O
parameters O
are O
distinct O
: O
the O
adversary O
can O
only O
update O
parameters O
a O
and O
the O
main O
classifier O
can O
only O
update O
parameters O
rand O
p. O

The O
duplicate O
adversarial O
classifier O
is O
the O
same O
as O
the O
classifier O
used O
to O
evaluate O
privacy O
after O
the O
main O
model O
has O
been O
trained O
and O
its O
parameters O
are O
fixed O
. O

However O
, O
the O
two O
classifiers O
are O
completely O
distinct O
: O
the O
former O
is O
used O
during O
the O
training O
of O
the O
main O
model O
( O
Phase O
1 O
) O
to O
take O
privacy O
into O
account O
, O
whereas O
the O
latter O
is O
used O
to O
evaluate O
the O
privacy O
of O
the O
final O
model O
( O
Phase O
3 O
) O
, O
as O
is O
described O
in O
Section O
2 O
. O

The O
generation O
of O
adversaries O
. O

We O
use O
a O
character O
- O
based I-MethodName
LSTM I-MethodName
language O
model O
as O
our O
second O
type O
of O
generator O
. O
This O
model O
is O
trained O
to O
reconstruct O
full O
training O
examples O
. O

For O
a O
single O
example O
( O
x O
; O
y O
) O
, O
the O
hidden O
state O
of O
the O
LSTM O
is O
initialized O
with O
r(x O
) O
, O
which O
is O
computed O
by O
the O
main O
model O
. O

The O
generator O
creates O
the O
most O
efficient O
possible O
output O
given O
the O
input O
values O
of O
x O
, O
y O
, O
z O
, O
and O
r. O

the I-HyperparameterName
log O
probability O
of I-HyperparameterName
x O
given O
the I-HyperparameterName
parameters O
of I-HyperparameterName
the I-HyperparameterName
LSTM O
generator O
and O
the I-HyperparameterName
previous O
character O
xi-1 O
is O
equal O
to O
the I-HyperparameterName
summation O
of I-HyperparameterName
the I-HyperparameterName
log O
probabilities O
of I-HyperparameterName
each O
character O
in I-HyperparameterName
the I-HyperparameterName
document I-HyperparameterName
given O
the I-HyperparameterName
parameters O
of I-HyperparameterName
the I-HyperparameterName
LSTM O
generator O
, O
where O
C B-HyperparameterName
is O
the I-HyperparameterName
length B-HyperparameterName
of I-HyperparameterName
the I-HyperparameterName
document I-HyperparameterName
in I-HyperparameterName
number I-HyperparameterName
of I-HyperparameterName
characters I-HyperparameterName
. O

The O
generator O
has O
no O
control O
over O
r(x O
) O
and O
can O
only O
optimize O
the O
objective O
by O
updating O
its O
own O
parameters O
. O

The O
main O
model O
is O
lost O
, O
but O
it O
is O
modified O
as O
follows O
. O

The O
likelihood O
of O
x O
given O
y O
, O
r O
, O
and O
p O
is O
equal O
to O
epsilon O
. O

The O
probability O
of O
y O
given O
x O
, O
r O
, O
and O
p. O

In O
other O
words O
, O
this O
means O
that O


 O
This O
means O
that O

The O
logarithm O
of O
x O
, O
y O
, O
z O
, O
and O
r. O

The O
first O
term O
maximizes O
the O
likelihood O
of O
the O
y O
labels O
, O
while O
the O
second O
term O
maximizes O
the O
loss O
of O
the O
generator O
, O
making O
reconstruction O
more O
difficult O
. O

As O
described O
in O
the O
previous O
section O
, O
the O
loss O
function O
is O
used O
to O
de- O
scribe O
the O
amount O
of O
information O
that O
is O
lost O
. O

I O
'm O
not O
sure O
what O
you O
're O
asking O
for O
. O

The O
relative O
importance O
of O
both O
terms O
can O
be O
controlled O
. O

Since O
the O
main O
classifier O
has O
no O
control O
over O
the O
parameters O
of O
the O
adversarial O
generator O
, O
the O
only O
way O
it O
can O
optimize O
the O
second O
term O
is O
by O
updating O
r O
. O

A O
key O
property O
of O
this O
defense O
method O
is O
that O
it O
is O
not O
aware O
of O
what O
the O
private O
variables O
z O
are O
. O

This O
means O
that O
it O
could O
prevent O
someone O
from O
accessing O
private O
information O
stored O
in O
the O
neural O
representation O
. O

From O
a O
broader O
perspective O
, O
the O
goal O
of O
this O
defense O
method O
is O
to O
make O
the O
hidden O
representation O
r(x O
) O
more O
specific O
to O
the O
task O
at O
hand O
( O
sentiment O
or O
topic B-TaskName
prediction I-TaskName
) O
and O
to O
avoid O
learning O
anything O
that O
is O
not O
relevant O
to O
it O
. O

This O
sentence O
means O
that O
there O
are O
three O
point O
two O
things O
. O

The O
last O
strategy O
we O
employ O
to O
make O
the O
task O
of O
the O
attacker O
harder O
is O
based O
on O
the O
intuition O
that O
private O
variables O
zare O
easier O
to O
predict O
from O
rwhen O
the O
main O
model O
learns O
implicitly O
to O
cluster O
exam- O
ples O
with O
similar O
zin O
the O
same O
regions O
of O
the O
representa- O
tion O
space O
. O

We O
add O
a O
term O
to O
the O
training O
objective O
of O
the O
main O
model O
that O
penalizes O
pairs O
of O
examples O
that O
have O
similar O
reconstructions O
and O
hidden O
representations O
in O
the O
same O
region O
of O
space O
. O

We O
use O
the O
following O
modified O
loss O
for O
a O
single O
example O
: O
Lm(x O
; O
y O
; O
z O
; O
ϵr O
; O
ϵp O
) O
= O
−logP(y|x O
; O
ϵr O
; O
ϵp O
) O
. O

I O
live O
in O
a O
house O


 O
I O
have O
a O
house O

We O
can O
paraphrase O
this O
sentence O
as O
follows O
: O
" O
Given O
another O
example O
sampled O
uniformly O
from O
the O
training O
set O
, O
( O
x0 O
, O
z0 O
) O
, O
we O
can O
compute O
the O
distance O
between O
x O
and O
x0 O
, O
as O
well O
as O
the O
distance O
between O
z O
and O
z0 O
. O
" O

A O
hyperparameter O
controls O
the O
importance O
of O
the O
second O
term O
, O
and O
the O
normalized O
Hamming O
distance O
is O
between O
0 O
and O
1 O
. O

Our O
experiments O
are O
designed O
to O
measure O
the O
privacy B-MetricName
- I-MetricName
utility I-MetricName
tradeoff I-MetricName
of O
neural O
representations O
in O
text B-TaskName
classification O
tasks O
, O
and O
to O
evaluate O
if O
the O
proposed O
defense O
methods O
have O
a O
positive O
impact O
on O
it O
. O

We O
first O
describe O
the O
datasets O
we O
used O
and O
the O
experimental O
protocol O
, O
then O
we O
discuss O
the O
results O
. O

We O
found O
that O
without O
taking O
defense O
into O
account O
, O
the O
adversary O
can O
recover O
private O
information O
more O
accurately O
than O
a O
most O
frequent O
class O
baseline O
. O

We O
found O
that O
the O
defenses O
we O
implemented O
have O
a O
positive O
effect O
on O
the O
accuracy B-MetricName
- I-MetricName
privacy I-MetricName
tradeoff I-MetricName
. O

We O
experiment O
with O
two O
text O
classification O
tasks O
: O
sentiment B-TaskName
analysis I-TaskName
and O
topic B-TaskName
classification O
. O

The O
sizes O
of O
the O
datasets O
are O
summarized O
in O
Table O
1 O
. O

We O
use O
the O
Trustpilot B-DatasetName
dataset O
for O
Sentiment B-TaskName
Analysis I-TaskName
. O

This O
corpus O
contains O
reviews O
with O
a O
sentiment O
score O
on O
a O
five O
- O
point O
scale O
and O
self O
- O
reported O
information O
about O
the O
users O
. O

We O
use O
five O
subcorpora O
that O
correspond O
to O
five O
areas O
: O
Denmark O
, O
France O
, O
Germany O
, O
the O
United O
Kingdom O
, O
and O
the O
United O
States O
. O

We O
use O
the O
birth O
year O
and O
gender O
of O
the O
author O
of O
the O
review O
as O
private O
information O
when O
filtering O
examples O
. O

As O
in O
Hovy O
( O
2015 O
) O
and O
Hovy O
and O
Søgaard O
( O
2015 O
) O
, O
we O
bin O
the O
age O
of O
the O
author O
into O
two O
categories O
( O
' O
under O
35 O
' O
and O
' O
over O
45 O
' O
) O
. O

We O
finally O
split O
each O
subcorpus O
into O
80 O
% O
, O
10 O
% O
, O
and O
10 O
% O
training O
, O
development O
, O
and O
test O
sets O
respectively O
. O

In O
addition O
to O
the O
standard O
experimental O
setting O
, O
we O
also O
input O
demographic O
variables O
( O
gender O
and O
age O
) O
into O
the O
main O
model O
. O

We O
achieve O
this O
by O
adding O
two O
additional O
tokens O
to O
the O
beginning O
of O
the O
input O
text O
, O
one O
for O
each O
variable O
. O

According O
to O
Hovy O
( O
2015 O
) O
, O
those O
variables O
can O
be O
used O
to O
improve O
text B-TaskName
classification O
. O

We O
would O
also O
like O
to O
evaluate O
whether O
it O
is O
easier O
for O
the O
attacker O
if O
the O
variables O
to O
be O
predicted O
are O
explicitly O
in O
the O
input O
, O
as O
opposed O
to O
when O
this O
information O
is O
only O
implied O
in O
the O
input O
. O

This O
setting O
simulates O
a O
situation O
where O
private O
information O
can O
be O
used O
by O
the O
model O
to O
improve O
classification O
, O
but O
should O
not O
be O
exposed O
too O
obviously O
. O

In O
the O
following O
section O
, O
we O
will O
only O
use O
the O
raw O
text O
as O
input O
, O
denoted O
as O
RAW O
, O
and O
the O
setting O
where O
the O
demographic O
variables O
are O
also O
used O
as O
input O
, O
denoted O
as O
+ O
DEMO O
. O

We O
classify O
topics O
in O
two O
genres O
of O
documents O
: O
news O
articles O
and O
blog O
posts O
. O

We O
use O
two O
datasets O
- O
the O
AG B-DatasetName
news O
corpus O
( O
Del O
Corso O
et O
al O
. O
, O
2005 O
) O
and O
the O
English O
part O
of O
the O
Deutsche B-DatasetName
Welle I-DatasetName
( O
DW B-DatasetName
) O
news O
corpus O
( O
Pappas O
and O
Popescu O
- O
Belis O
, O
2017 O
) O
- O
for O
topic O
classification O
of O
news O
articles O
. O

We O
use O
the O
concatenation O
of O
the O
' O
title O
' O
and O
' O
description O
' O
fields O
as O
the O
input O
to O
the O
classifier O
for O
the O
AG B-DatasetName
corpus I-DatasetName
, O
following O
Zhang O
et O
al O
. O
( O
2015 O
) O
. O
We O
construct O
the O
dataset O
by O
extracting O
documents O
belonging O
to O
the O
four O
most O
frequent O
topics O
. O

We O
split O
the O
corpus O
into O
three O
sets O
: O
a O
training O
set O
( O
80 O
% O
) O
, O
a O
development O
set O
( O
10 O
% O
) O
, O
and O
a O
test O
set O
( O
10 O
% O
) O
. O

We O
use O
the O
text O
field O
as O
input O
for O
the O
DW B-DatasetName
dataset O
and O
the O
standard O
split O
. O

We O
only O
kept O
documents O
that O
belonged O
to O
the O
20 O
most O
frequent O
topics O
. O

The O
attacker O
is O
trying O
to O
see O
which O
named O
entities O
appear O
in O
the O
input O
text O
by O
looking O
at O
the O
coefficients O
in O
z(x O
) O
. O

For O
both O
datasets O
, O
we O
associated O
each O
example O
with O
the O
list O
of O
named O
entities O
that O
occur O
in O
it O
, O
using O
the O
named O
entity O
recognition O
system O
from O
the O
NLTK O
package O
( O
Bird O
et O
al O
. O
, O
2009 O
) O
. O

We O
only O
keep O
examples O
containing O
at O
least O
one O
of O
the O
five O
most O
frequent O
named O
entities O
with O
type O
' O
person O
' O
. O

Since O
each O
selected O
named O
entity O
usually O
appears O
in O
very O
few O
articles O
, O
this O
filtering O
is O
necessary O
to O
avoid O
a O
very O
unbalanced O
dataset O
. O

We O
used O
the O
blog O
authorship O
corpus O
that O
was O
presented O
by O
Schler O
et O
al O
. O

The O
2006 O
collection O
of O
blog O
posts O
were O
associated O
with O
the O
age O
and O
gender O
of O
the O
authors O
, O
as O
provided O
by O
the O
authors O
themselves O
. O

Since O
the O
blog O
posts O
did O
not O
have O
a O
topic O
annotation O
, O
we O
ran O
the O
LDA O
algorithm O
on O
the O
entire O
collection O
, O
with O
10 O
topics O
. O

The O
LDA O
outputs O
a O
distribution O
of O
topics O
for O
each O
blog O
post O
. O

We O
only O
selected O
posts O
that O
had O
a O
single O
dominating O
topic O
, O
and O
we O
discarded O
the O
other O
posts O
. O

We O
placed O
people O
into O
two O
groups O
based O
on O
age O
, O
those O
under O
20 O
and O
those O
over O
30 O
. O

We O
used O
the O
author O
's O
age O
and O
gender O
as O
the O
private O
variables O
. O

There O
is O
a O
very O
uneven O
distribution O
of O
these O
variables O
throughout O
the O
dataset O
, O
so O
we O
randomly O
select O
examples O
to O
get O
more O
uniform O
distributions O
of O
private O
variables O
. O

We O
split O
the O
corpus O
into O
a O
training O
set O
( O
80 O
% O
) O
, O
a O
validation O
set O
, O
and O
a O
test O
set O
( O
10 O
% O
each O
) O
. O
Finally O
, O

We O
report O
a O
single O
accuracy B-MetricName
measure O
for O
the O
main O
task O
. O

We O
compute O
the O
following O
metrics O
for O
measuring O
the O
privacy O
of O
a O
representation O
: O


 O
For O
demographic O
variables O
( O
sentiment B-TaskName
analysis O
and O
blog O
post O
topic B-TaskName
classification O
): O
1 O
- O
X B-MetricName
, O
where O
X B-MetricName
is O
the O
average I-MetricName
of O
the O
accuracy I-MetricName
of O
the O
attacker O
on O
the O
prediction O
of O
gender O
and O
age O
. O


 O
For O
named O
entities O
( O
news O
topic B-TaskName
classification O
): O
1 O
- O
F B-MetricName
, O
where O
F B-MetricName
is O
an O
F B-MetricName
- O
score O
computed O
over O
the O
set O
of O
binary O
variables O
in O
zthat O
indicate O
the O
presence O
of O
named O
entities O
in O
the O
input O
example O
. O

We O
trained O
our O
model O
using O
Dynet B-MethodName
( O
Neubig O
et O
al O
. O
, O
2017 O
) O
. O

The O
feedforward O
components O
of O
both O
the O
main O
model O
and O
the O
attacker O
have O
a O
single O
hidden O
layer O
of O
64 B-HyperparameterValue
units O
with O
a O
ReLU O
activation O
. O

Word O
embeddings O
have O
32 B-HyperparameterValue
separate O
units O
. O

Since O
it O
is O
expected O
that O
the O
amount O
of O
information O
that O
can O
be O
learned O
depends O
on O
the O
size O
of O
these O
representations O
, O
the O
LSTM O
encoder O
has O
a O
single O
layer O
of O
varying O
sizes O
. O

We O
used O
the O
Adam O
optimizer O
( O
Kingma O
and O
Ba O
, O
2014 O
) O
with O
the O
default O
learning B-HyperparameterName
rate I-HyperparameterName
. O
We O
used O
a O
dropout B-HyperparameterName
rate I-HyperparameterName
of O
0.2 B-HyperparameterValue
for O
the O
LSTM O
. O

After O
doing O
some O
preliminary O
experiments O
, O
we O
decided O
to O
use O
a O
declustering O
method O
with O
a O
value O
of O
0.1 B-HyperparameterValue
. O

For O
the O
other O
defense O
methods O
, O
we O
used O
a O
value O
of O
1 B-HyperparameterValue
and O
did O
not O
experiment O
with O
other O
values O
. O

We O
train O
the O
main O
model O
for O
8 B-HyperparameterValue
or O
16 B-HyperparameterValue
epochs B-HyperparameterName
, O
depending O
on O
the O
task O
, O
and O
select O
the O
model O
with O
the O
best O
accuracy B-MetricValue
on O
the O
development O
set O
, O
for O
each O
dataset O
and O
LSTM B-HyperparameterName
state I-HyperparameterName
dimension O
. O

The O
dataset O
is O
generated O
for O
the O
attacker O
, O
the O
adversarial O
model O
is O
trained O
for O
16 O
epochs O
, O
and O
the O
model O
that O
is O
the O
most O
successful O
attacker O
is O
selected O
. O

We O
only O
select O
models O
that O
are O
accurate O
, O
not O
models O
that O
implement O
defenses O
for O
privacy O
or O
a O
combination O
of O
the O
two O
. O

We O
could O
also O
select O
the O
most O
accurate O
model O
with O
privacy O
above O
a O
certain O
threshold O
as O
our O
selection O
strategy O
. O

This O
section O
discusses O
the O
results O
for O
the O
sentiment O
analysis O
task O
in O
4.3.1 O
and O
the O
topic B-TaskName
classification O
task O
in O
4.3.2 O
. O

How O
private O
are O
the O
neural O
representations O
? O

Before O
discussing O
the O
effect O
of O
proposed O
defense O
methods O
, O
we O
show O
empirically O
that O
adversarial O
models O
can O
recover O
private O
information O
with O
reasonable O
accuracy O
when O
the O
attack O
is O
targeted O
towards O
a O
model O
that O
implements O
none O
of O
the O
presented O
defense O
methods O
. O

We O
compare O
the O
accuracy B-MetricName
of O
adversarial O
models O
to O
two O
types O
of O
baselines O
: O
the O
most O
frequent O
class O
baseline O
and O
a O
lower O
bound O
. O

We O
trained O
a O
classifier O
that O
can O
optimize O
the O
hidden O
representations O
for O
the O
attacker O
's O
tasks O
, O
with O
an O
upper O
bound O
. O

This O
baseline O
is O
trained O
to O
predict O
demographic O
variables O
from O
x O
, O
with O
the O
main O
task O
being O
to O
de O
- O
x. O

In O
Table O
2 O
, O
we O
compare O
the O
two O
baselines O
to O
the O
best O
adversary O
in O
the O
RAW O
and O
DEMO O
settings O
among O
the O
models O
trained O
with O
no O
defenses O
. O

We O
observe O
that O
, O
on O
the O
German O
dataset O
, O
the O
trained O
baseline O
outperforms O
the O
most O
frequent O
class O
baseline O
by O
a O
wide O
margin O
( O
8 O
to O
25 O
absolute O
difference O
) O
, O
regardless O
of O
gender O
. O

Second O
, O
the O
attacker O
is O
able O
to O
outperform O
the O
most O
frequent O
class O
baseline O
overall O
, O
even O
when O
RAW O
setting O
is O
used O
. O

The O
adversary O
is O
older O
than O
the O
baseline O
in O
all O
cases O
except O
for O
the O
US O
. O

Gender O
seems O
harder O
to O
predict O
than O
other O
factors O
. O
The O
adversary O
only O
outperforms O
the O
most O
frequent O
class O
baseline O
in O
the O
+ O
DEMO O
setting O
. O

A O
similar O
pattern O
can O
be O
seen O
for O
the O
blog O
post O
dataset O
, O
which O
is O
shown O
in O
the O
last O
line O
of O
Table O
2 O
. O
The O
best O
adversaries O
are O
14 B-MetricValue
points O
over O
the O
base- O
line O
for O
gender O
and O
5 B-MetricValue
points O
for O
age O
. O
This O
is O
almost O
as O
good O
as O
a O
model O
that O
can O
ﬁne O
tune O
the O
hidden O
representations O
. O

Since O
these O
results O
demonstrate O
that O
hidden O
representations O
learn O
private O
information O
about O
the O
input O
and O
can O
be O
exploited O
to O
recover O
this O
information O
with O
reasonable O
accuracy B-MetricName
, O
they O
justify O
our O
approach O
. O

In O
Tables O
3 O
and O
4 O
, O
we O
present O
the O
results O
for O
the O
main O
task O
accuracy O
and O
the O
representation O
privacy O
for O
the O
+ O
DEMO O
setting O
and O
the O
RAW O
setting O
, O
respectively O
. O

The O
privacy O
measure O
, O
Priv O
. O
, O
is O
calculated O
by O
subtracting O
the O
average O
accuracy I-MetricName
of O
the O
attacker O
's O
predictions O
for O
gender O
and O
age O
from O
1 O
. O

When O
this O
privacy O
metric O
is O
higher O
, O
it O
becomes O
more O
difficult O
to O
use O
the O
hidden O
information O
within O
the O
network O
to O
discover O
details O
about O
x. O

The O
' O
Standard O
' O
columns O
show O
the O
accuracy O
and O
privacy O
of O
the O
base O
model O
described O
in O
Section O
2 O
. O

The O
following O
columns O
show O
how O
much O
accuracy B-MetricName
and O
privacy O
varies O
for O
three O
different O
defense O
methods O
: O
multitasking O
, O
adversarial O
generation O
, O
and O
declustering O
. O

We O
also O
report O
for O
each O
corpus O
the O
most O
frequent O
class O
baseline O
for O
the O
main O
task O
accuracy O
, O
as O
well O
as O
the O
privacy O
of O
the O
most O
frequent O
class O
baselines O
on O
private O
variables O
( O
i.e. O
the O
upper O
bound O
for O
privacy O
) O
. O

The O
three O
training O
methods O
designed O
as O
defenses O
have O
a O
positive O
effect O
on O
privacy O
. O

Despite O
choosing O
a O
model O
based O
on O
accuracy B-MetricName
, O
it O
led O
to O
an O
improvement O
in O
privacy O
on O
all O
datasets O
, O
with O
the O
exception O
of O
the O
France O
subcorpus O
. O

We O
usually O
only O
see O
a O
small O
decrease O
in O
accuracy B-MetricName
, O
or O
even O
an O
improvement O
, O
when O
using O
this O
method O
, O
which O
improves O
the O
balance O
between O
the O
usefulness O
and O
privacy O
of O
text O
representations O
. O

The O
results O
of O
Topic B-TaskName
classification O
are O
reported O
in O
Table O
5 O
. O

For O
the O
news O
corpora O
, O
the O
privacy B-MetricName
metric O
is O
based O
on O
the O
F B-MetricName
- O
score O
on O
the O
binary O
variables O
indicating O
the O
presence O
or O
absence O
of O
a O
named O
entity O
in O
the O
text O
. O

First O
, O
we O
notice O
that O
defense O
mechanisms O
that O
make O
use O
of O
z O
directly O
( O
for O
example O
, O
multitasking O
and O
declustering O
) O
have O
a O
positive O
effect O
on O
privacy O
but O
a O
negative O
effect O
on O
the O
primary O
task O
. O

We O
think O
this O
is O
because O
the O
main O
task O
labels O
are O
closely O
related O
to O
the O
private O
information O
. O

This O
means O
that O
improving O
the O
privacy O
of O
neural O
representations O
comes O
at O
a O
cost O
to O
accuracy B-MetricName
. O

The O
adversarial O
generation O
defense O
method O
led O
to O
a O
substantial O
improvement O
in O
accuracy B-MetricName
for O
the O
DW B-DatasetName
corpus O
. O

We O
believe O
this O
is O
caused O
by O
the O
secondary O
term O
in O
the O
objective O
function O
of O
the O
main O
model O
( O
Section O
3.1.2 O
) O
which O
helps O
prevent O
overfitting O
the O
main O
task O
or O
learning O
spurious O
features O
. O

On O
the O
blog O
post O
dataset O
, O
the O
attacker O
's O
task O
is O
easier O
, O
so O
the O
effects O
are O
smaller O
. O

The O
defense O
methods O
improve O
privacy O
and O
accuracy O
, O
in O
one O
case O
. O

The O
best O
results O
are O
achieved O
with O
the O
multidetasking O
and O
adversarial O
generation O
methods O
. O

Our O
experiments O
' O
main O
result O
is O
that O
the O
defenses O
we O
propose O
usually O
have O
a O
small O
, O
positive O
or O
negative O
, O
effect O
on O
accuracy O
, O
thus O
improving O
the O
tradeoff O
between O
neural O
representations O
' O
utility O
and O
privacy O
. O

A O
future O
goal O
for O
this O
type O
of O
work O
is O
to O
choosing O
a O
strategy O
for O
model O
selection O
. O

The O
balance O
between O
utility O
and O
privacy O
can O
be O
controlled O
in O
many O
ways O
. O

For O
example O
, O
you O
can O
control O
how O
important O
both O
terms O
are O
in O
the O
loss O
functions O
in O
Section O
3.1 O
to O
prioritize O
either O
privacy O
or O
utility O
. O

In O
this O
paper O
, O
we O
did O
not O
perform O
thorough O
hyperparameter O
tuning O
, O
but O
we O
believe O
that O
it O
is O
important O
for O
achieving O
better O
results O
. O
The O
effects O
of O
defense O
methods O
can O
be O
more O
drastic O
than O
desired O
in O
some O
cases O
, O
as O
exemplified O
in O
the O
news O
corpora O
( O
Table O
5 O
) O
. O

We O
found O
that O
the O
multidetasking O
approach O
leads O
to O
more O
stable O
improvements O
and O
should O
be O
preferred O
in O
most O
cases O
, O
since O
it O
is O
also O
less O
computationally O
expensive O
. O

On O
the O
other O
hand O
, O
the O
adversarial O
generation O
method O
does O
not O
require O
the O
speciﬁcation O
of O
private O
vari- O
ables O
, O
and O
thus O
is O
a O
more O
general O
approach O
. O

There O
are O
concerns O
that O
machine O
learning O
will O
be O
used O
for O
malicious O
purposes O
, O
as O
well O
as O
concerns O
that O
attacks O
will O
be O
specifically O
targeted O
at O
algorithms O
that O
often O
rely O
on O
large O
amounts O
of O
data O
, O
including O
personal O
data O
. O

Differential O
privacy O
is O
a O
framework O
that O
provides O
privacy O
guarantees O
for O
releasing O
information O
without O
compromising O
confidential O
data O
. O
It O
usually O
involves O
adding O
noise O
to O
the O
released O
information O
. O

It O
has O
been O
applied O
to O
the O
training O
of O
deep O
learning O
models O
( O
Abadi O
et O
al O
. O
, O
2016 O
; O
. O


 O
This O
technique O
has O
been O
shown O
to O
be O
effective O
in O
training O
deep O
learning O
models O
( O
Abadi O
et O
al O
. O
, O
2016 O
) O
. O

Papernot O
et O
al O
. O
( O
2016 O
, O
2018 O
) O
and O
Schein O
et O
al O
. O
( O
2018 O
) O
used O
Bayesian O
topic O
models O
. O

NLP O
's O
handling O
of O
private O
information O
is O
of O
utmost O
importance O
due O
to O
the O
sensitive O
nature O
of O
the O
text O
- O
based O
user O
data O
it O
commonly O
deals O
with O
. O

For O
example O
, O
Hovy O
and O
Spruit O
( O
2016 O
) O
found O
that O
textual O
data O
can O
provide O
a O
lot O
of O
information O
about O
authors O
. O

The O
ability O
to O
predict O
demographic O
variables O
can O
be O
increased O
by O
taking O
advantage O
of O
( O
Rosenthal O
and O
McKeown O
, O
2011 O
; O
Preot O
¸iuc- O
Pietro O
et O
al O
. O
, O
2015 O
) O
. O

This O
information O
is O
often O
not O
explicit O
in O
the O
text O
, O
but O
is O
latent O
and O
related O
to O
the O
usage O
of O
various O
linguistic O
traits O
. O

Our O
work O
is O
based O
on O
the O
hypothesis O
that O
latent O
information O
is O
still O
present O
in O
vectorial O
representations O
of O
texts O
, O
even O
if O
the O
representations O
have O
not O
been O
supervised O
by O
these O
latent O
variables O
. O

( O
2019 O
) O
suggest O
that O
a O
potential O
advantage O
of O
mobile O
technologies O
is O
that O


  O
Li O
et O
al O
. O
( O
2019 O
) O
suggests O
that O
a O
potential O
advantage O
of O
mobile O
technologies O
is O
the O
ability O
to O

A O
2017 O
study O
looked O
at O
the O
privacy O
of O
unsupervised O
images O
representations O
, O
and O
measured O
their O
privacy O
using O
the O
peak O
signal O
to O
noise O
ratio O
between O
an O
original O
image O
and O
its O
reconstruction O
by O
an O
attacker O
. O

There O
is O
a O
tradeoff O
between O
the O
privacy O
of O
the O
representations O
that O
are O
learned O
and O
the O
accuracy O
of O
an O
image O
classification O
model O
that O
uses O
these O
representations O
as O
inputs O
. O

Our O
setting O
is O
complementary O
to O
other O
work O
since O
it O
is O
applied O
to O
NLP O
tasks O
, O
but O
explores O
a O
similar O
problem O
in O
the O
case O
of O
representations O
learned O
with O
a O
task O
supervision O
. O

A O
similar O
problem O
is O
when O
private O
data O
from O
the O
training O
set O
is O
unintentionally O
memorized O
and O
Carlini O
et O
al O
. O
addressed O
this O
. O

The O
flowers O
were O
blooming O
beautifully O


 O
The O
flowers O
were O
in O
full O
bloom O
and O
looked O
beautiful O
. O

They O
solve O
this O
problem O
in O
the O
context O
of O
machine B-TaskName
translation I-TaskName
and O
language B-TaskName
modeling O
. O

If O
an O
attacker O
has O
access O
to O
a O
trained O
language O
model O
, O
they O
are O
likely O
to O
be O
able O
to O
generate O
sentences O
from O
the O
training O
set O
that O
the O
model O
is O
designed O
to O
assign O
high O
probabilities O
to O
. O

When O
the O
training O
data O
contains O
private O
information O
and O
personal O
data O
, O
such O
memorization O
can O
be O
problematic O
. O

The O
setting O
we O
explore O
is O
different O
from O
others O
in O
that O
we O
assume O
the O
attacker O
has O
access O
to O
a O
hidden O
layer O
and O
is O
trying O
to O
recover O
information O
about O
an O
input O
not O
in O
the O
training O
set O
. O

( O
2020 O
) O
examined O
the O
impact O
of O
the O
coronavirus O


 O
The O
impact O
of O
the O
coronavirus O
was O
examined O
by O
Li O
et O
al O
. O
in O
a O
recent O
study O
. O

In O
2018 O
, O
a O
method O
was O
proposed O
that O
uses O
GAN O
to O
improve O
the O
robustness O
and O
privacy O
of I-TaskName
neural O
representations O
. O
This O
method O
was O
applied O
to O
part B-TaskName
- I-TaskName
of I-TaskName
- I-TaskName
speech I-TaskName
tagging I-TaskName
and O
sentiment B-TaskName
analysis I-TaskName
. O

They O
found O
that O
using O
a O
training O
scheme O
with O
two O
agents O
similar O
to O
our O
multidetasking O
strategy O
( O
Section O
3.1.1 O
) O
made O
neural O
representations O
more O
robust O
and O
accurate O
. O

The O
single O
adversary O
model O
is O
used O
to O
train O
and O
evaluate O
the O
privacy O
of O
the O
representations O
, O
which O
may O
result O
in O
an O
overestimation O
of O
privacy O
. O

Once O
the O
parameters O
of O
our O
main O
model O
are O
fixed O
, O
we O
train O
a O
new O
classifier O
from O
scratch O
to O
evaluate O
privacy O
in O
contrast O
. O

In O
conclusion O
, O
we O
have O
presented O
an O
adversarial O
scenario O
and O
used O
it O
to O
measure O
the O
privacy O
of O
hidden O
representations O
in O
the O
context O
of O
two O
NLP O
tasks O
: O
sentiment O
analysis I-TaskName
and O
topic B-TaskName
classification O
of O
news O
articles O
and O
blog O
posts O
. O

We O
have O
shown O
that O
it O
is O
possible O
for O
an O
attacker O
to O
accurately O
recover O
private O
variables O
more O
often O
than O
by O
chance O
, O
using O
only O
hidden O
representations O
. O

We O
have O
proposed O
defense O
methods O
based O
on O
modifications O
of O
the O
training O
objective O
of O
the O
main O
model O
in O
order O
to O
improve O
the O
privacy O
of O
hidden O
representations O
. O

Empirically O
, O
the O
proposed O
defenses O
result O
in O
models O
with O
better O
privacy O
. O

We O
would O
like O
to O
thank O
the O
anonymous O
reviewers O
and O
members O
of O
the O
Cohort O
for O
their O
helpful O
feedback O
on O
previous O
versions O
of O
this O
article O
. O

We O
would O
like O
to O
express O
our O
gratitude O
to O
the O
European O
Union O
for O
their O
support O
under O
the O
Horizon O
2020 O
SUMMA O
project O
( O
grant O
agreement O
688139 O
) O
, O
as O
well O
as O
Huawei O
Technologies O
. O

Martin O
Abadi O
, O
Andy O
Chu O
, O
Ian O
Goodfellow O
, O
H. O
Brendan O
McMahan O
, O
Ilya O
Mironov O
, O
Kunal O
Talwar O
, O
and O
Li O
Zhang O
are O
all O
references O
. O

This O
sentence O
is O
stating O
that O
2016 O
is O
a O
year O
. O

Deep O
learning O
with O
privacy O
protection O
that O
is O
based O
on O
identifying O
and O
minimizing O
the O
differences O
between O
individuals O
. O

In O
the O
2016 O
ACM O
SIGSAC O
Conference O
on O
Computer O
and O
Communications O
Security O
, O
pages O
308 O
- O
318 O
, O
New O
York O
, O
NY O
, O
USA O
, O
ACM O
. O

Steven O
Bird O
, O
Ewan O
Klein O
, O
and O
Edward O
Loper O
are O
the O
authors O
of O
the O
2009 O
text O
. O

Natural O
Language O
Processing O
with O
Python O
, O
first O
edition O
. O

Ng O


 O
O'Reilly O
Media O
, O
Inc. O
is O
a O
media O
company O
that O
was O
founded O
by O
David O
M. O
Blei O
and O
Andrew O
Y. O
Ng O
. O

Ng O
and O
Jordan O
are O
both O
well O
- O
known O
researchers O
. O

This O
sentence O
is O
in O
improper O
form O
. O

Latent O
dirichlet O
allocation O
is O
a O
topic O
modeling O
technique O
. O

The O
Journal O
of O
Machine O
is O
a O
peer O
- O
reviewed O
publication O
that O
covers O
all O
aspects O
of O
machine O
learning O
. O

The O
article O
" O
Learning O
Research O
" O
was O
published O
in O
3:993–1022 O
. O

The O
following O
people O
are O
Nicholas O
Carlini O
, O
Chang O
Liu O
, O
Jernej O
Kos O
, O
Ulfar O
Erlingsson O
, O
and O
Dawn O
Song O
. O

The O
year O
2018 O
. O

The B-MethodName
secret I-MethodName
sharer I-MethodName
: O
Measuring O
unintended O
neural O
network O
memorization O
and O
extracting O
secrets O
. O

This O
sentence O
is O
a O
citation O
for O
a O
paper O
on O
the O
arXiv O
website O
. O
The O
title O
of O
the O
paper O
is O
" O
Achieving O
Open O
Vocabulary O
Neural O
Machine O
Translation O
. O
" O

Gianna O
M. O
Del O
Corso O
, O
Antonio O
Gulli O
, O
and O
Francesco O
Romani O
. O

The O
year O
2005 O
. O

Ranking O
news O
stories O
in O
order O
of O
importance O
. O

In O
Proceedings O
of O
the O
14th O
International O
Conference O
on O
World O
Wide O
Web O
, O
WWW O
' O
05 O
, O
pages O
97 O
- O
106 O
, O
New O
York O
, O
NY O
, O
USA O
, O
ACM O
. O

Cynthia O
Dwork O
is O
a O
computer O
scientist O
and O
statistician O
. O

The O
year O
2006 O
. O

Differential O
privacy O
is O
a O
mathematical O
definition O
of O
privacy O
used O
in O
statistics O
and O
data O
mining O
. O

In O
the O
33rd O
International O
Colloquium O
on O
Automata O
, O
Languages O
, O
and O
Programming O
, O
part O
II O
, O
which O
was O
held O
in O
Venice O
, O
Italy O
, O
researchers O
presented O
papers O
on O
a O
variety O
of O
topics O
. O

Springer O
Verlag O
is O
a O
publishing O
company O
. O

The O
authors O
of O
the O
paper O
are O
Ian O
Goodfellow O
, O
Jean O
Pouget O
- O
Abadie O
, O
Mehdi O
Mirza O
, O
Bing O
Xu O
, O
David O
Warde O
- O
Farley O
, O
Sherjil O
Ozair O
, O
Aaron O
Courville O
, O
and O
Yoshua O
Bengio O
. O

The O
year O
is O
2014 O
. O

Generative O
adversarial O
networks O
are O
a O
type O
of O
artificial O
intelligence O
that O
can O
generate O
new O
data O
that O
is O
similar O
to O
the O
training O
data O
. O

Z. O
Ghahramani O
, O
M. O
Welling O
, O
C. O
Cortes O
, O
N. O
D. O
Lawrence O
, O
and O
K. O
Q. O
Weinberger O
edited O
Advances O
in O
Neural O
Information O
Processing O
Systems O
27 O
, O
where O
pages O
2672 O
- O
2680 O
can O
be O
found O
. O

This O
is O
Curran O
Associates O
, O
Inc. O

Sepp O
Hochreiter O
and O
Jurgen O
Schmidhuber O
are O
two O
people O
. O

The O
year O
is O
1997 O
. O

This O
sentence O
is O
hard O
to O
parse O
because O
of O
its O
unusual O
word O
order O
. O
It O
might O
mean O
" O
memory O
that O
is O
both O
long O
and O
short O
- O
term O
, O
" O
or O
it O
might O
mean O
" O
long O
- O
term O
memory O
for O
short O
things O
. O
" O

Neural O
Computation O
, O
9 O
( O
8) O
: O
1735 O
- O
1780 O

Dirk O
Hovy O
authored O
a O
2015 O
paper O
. O

Classification O
performance O
is O
improved O
by O
demographic O
factors O
. O

The O
53rd O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
and O
the O
7th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
was O
held O
in O
Beijing O
, O
China O
. O
The O
Proceedings O
of O
the O
conference O
were O
published O
in O
Volume O
1 O
: O
Long O
Papers O
, O
with O
pages O
752 O
- O
762 O
containing O
the O
conference O
's O
papers O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
an O
organization O
that O
promotes O
the O
study O
of O
linguistics O
and O
computation O
. O

Dirk O
Hovy O
, O
Anders O
Johannsen O
, O
and O
Anders O
Søgaard O
are O
researchers O
. O

The O
year O
is O
2015 O
. O

User O
review O
sites O
can O
be O
used O
for O
large O
- O
scale O
sociolinguistic O
studies O
. O

In O
the O
24th O
International O
Conference O
on O
World O
Wide O
Web O
, O
pages O
452 O
- O
461 O
in O
Republic O
and O
Canton O
of O
Geneva O
, O
Switzerland O
were O
discussed O
. O

The O
International O
World O
Wide O
Web O
Conference O
Steering O
Committee O
is O
responsible O
for O
organizing O
the O
World O
Wide O
Web O
Conference O
, O
an O
annual O
event O
that O
brings O
together O
researchers O
, O
developers O
, O
users O
, O
and O
businesses O
from O
around O
the O
world O
to O
discuss O
the O
latest O
advances O
in O
web O
technology O
. O

Dirk O
Hovy O
and O
Anders O
Søgaard O
are O
two O
people O
. O

The O
year O
2015 O
. O

Author O
age O
is O
correlated O
with O
tagging O
performance O
. O

At O
the O
53rd O
Annual O
Meeting O
of O
the O
Association O
for O
, O
researchers O
presented O
their O
work O
on O
a O
variety O
of O
topics O
. O

The O
Association O
for O
Computational O
Linguistics O
published O
a O
volume O
of O
short O
papers O
titled O
" O
Computational O
Linguistics O
and O
the O
7th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
" O
that O
includes O
a O
paper O
on O
page O
483 O
- O
488 O
titled O
" O
Beijing O
, O
China O
" O
. O

Dirk O
Hovy O
and O
Shannon O
L. O
Spruit O
are O
two O
people O
. O

The O
year O
2016 O
. O

The O
social O
implications O
of O
using O
natural O
language O
processing O
. O

At O
the O
54th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
held O
in O
Berlin O
, O
Germany O
, O
papers O
were O
presented O
on O
a O
variety O
of O
topics O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
an O
organization O
that O
deals O
with O
the O
study O
of O
linguistics O
through O
the O
use O
of O
computers O
. O

Diederik O
P. O
Kingma O
and O
Jimmy O
Ba O
wrote O
a O
paper O
in O
2014 O
. O

A O
method O
for O
optimization O
that O
relies O
on O
randomness O
. O

The O
sentence O
is O
a O
citation O
for O
a O
paper O
on O
arXiv.org O
. O
The O
title O
of O
the O
paper O
is O
" O
Deep O
Learning O
with O
COTS O
HPC O
Systems O
. O
" O

Meng O
Li O
, O
Liangzhen O
Lai O
, O
Naveen O
Suda O
, O
Vikas O
Chandra O
, O
and O
David O
Z. O
Pan O
. O
2017 O
. O
Privynet B-MethodName
: O
A I-MethodName
flexible O
framework I-MethodName
for I-MethodName
privacy I-MethodName
- I-MethodName
preserving I-MethodName
deep I-MethodName
neural I-MethodName
network O
training I-MethodName
with I-MethodName
A I-MethodName
fine O
- I-MethodName
grained I-MethodName
privacy I-MethodName
control I-MethodName
. O

The O
sentence O
is O
a O
reference O
to O
a O
research O
paper O
that O
can O
be O
found O
on O
the O
CoRR O
website O
. O

Yitong O
Li O
, O
Timothy O
Baldwin O
, O
and O
Trevor O
Cohn O
are O
all O
researchers O
in O
the O
field O
of O
AI O
. O

2018 O
is O
a O
year O
. O

Towards O
text O
representations O
that O
are O
both O
robust O
and O
preserve O
privacy O
. O

The O
56th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
was O
held O
in O
Melbourne O
, O
Australia O
. O
The O
proceedings O
of O
the O
meeting O
, O
which O
include O
short O
papers O
, O
can O
be O
found O
on O
pages O
25 O
- O
30 O
. O

This O
is O
the O
name O
of O
the O
organization O
. O

Dynet B-MethodName
is O
a O
dynamic I-MethodName
neural I-MethodName
network I-MethodName
toolkit I-MethodName
created O
by O
Graham O
Neubig O
, O
Chris O
Dyer O
, O
Yoav O
Goldberg O
, O
Austin O
Matthews O
, O
Waleed O
Ammar O
, O
Antonios O
Anastasopou- O
los O
, O
Miguel O
Ballesteros O
, O
David O
Chiang O
, O
Daniel O
Clothiaux O
, O
Trevor O
Cohn O
, O
Kevin O
Duh O
, O
Manaal O
Faruqui O
, O
Cynthia O
Gan O
, O
Dan O
Garrette O
, O
Yangfeng O
Ji O
, O
Lingpeng O
Kong O
, O
Adhiguna O
Kuncoro O
, O
Gaurav O
Ku- O
mar O
, O
Chaitanya O
Malaviya O
, O
Paul O
Michel O
, O
Yusuke O
Oda O
, O
Matthew O
Richardson O
, O
Naomi O
Saphra O
, O
Swabha O
Swayamdipta O
, O
and O
Pengcheng O
Yin O
in O
2017 O
. O

This O
sentence O
is O
a O
preprint O
of O
the O
article O
" O
arXiv:1701.03980 O
. O
" O

The O
authors O
of O
the O
paper O
are O
Nicolas O
Papernot O
, O
Martín O
Abadi O
, O
Úlfar O
Erlingsson O
, O
Ian O
J. O
Goodfellow O
, O
and O
Kunal O
Talwar O
. O

This O
sentence O
is O
about O
the O
year O
2016 O
. O

Transferring O
knowledge O
from O
private O
training O
data O
for O
deep O
learning O
using O
a O
semi O
- O
supervised O
approach O
. O

This O
sentence O
is O
a O
citation O
for O
a O
paper O
published O
on O
the O
arXiv O
pre O
- O
print O
server O
. O
The O
full O
citation O
is O
: O
arXiv:1610.05755 O
[ O
cs O
. O
LG O
] O

The O
authors O
of O
the O
paper O
are O
Nicolas O
Papernot O
, O
Shuang O
Song O
, O
Ilya O
Mironov O
, O
Ananth O
Raghunathan O
, O
Kunal O
Talwar O
, O
and O
´ O
Ulfar O
Erlingsson O
. O

This O
year O
is O
2018 O
. O

PATE B-MethodName
allows O
for O
scalable O
private O
learning O
. O

This O
sentence O
is O
difficult O
to O
parse O
. O

The O
sentence O
is O
discussing O
prints O
and O
their O
abs/1802.08908 O
. O

Nikolaos O
Pappas O
and O
Andrei O
Popescu O
- O
Belis O
are O
two O
people O
. O

This O
sentence O
is O
about O
the O
year O
2017 O
. O

Multilingual O
hierarchical O
attention O
networks O
are O
used O
for O
document O
classification O
. O

In O
the O
Eighth O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
, O
pages O
1015 O
- O
1025 O
, O
Taipei O
, O
Taiwan O
, O
it O
was O
shown O
that O
.... O

The O
Asian O
Federation O
of O
Natural O
Language O
Processing O
is O
an O
organization O
that O
promotes O
research O
and O
development O
in O
the O
field O
of O
natural O
language O
processing O
. O

Daniel O
Preotiuc O
- O
Pietro O
, O
Vasileios O
Lampos O
, O
and O
Nikolaos O
Aletras O
. O

The O
year O
is O
2015 O
. O

An O
analysis O
of O
the O
user O
's O
occupational O
class O
through O
twitter O
content O
. O

The O
53rd O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
and O
the O
7th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
was O
held O
in O
Beijing O
, O
China O
. O
The O
papers O
from O
this O
conference O
are O
published O
in O
Volume O
1 O
: O
Long O
Papers O
. O

. O
. O


 O
This O
is O
the O
Association O
for O
Computational O
Linguistics O
. O

Sara O
Rosenthal O
and O
Kathleen O
McKeown O
wrote O
a O
paper O
in O
2011 O
. O

A O
study O
of O
style O
, O
content O
, O
and O
online O
behavior O
found O
that O
there O
are O
differences O
between O
the O
way O
that O
pre- O
and O
post O
- O
social O
media O
generations O
communicate O
online O
. O

The O
49th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
was O
held O
in O
proceedings O
. O

In O
the O
" O
tics O
" O
section O
of O
the O
Human O
Language O
Technologies O
pages O
, O
763 O
- O
772 O
, O
you O
will O
find O
Portland O
, O
Oregon O
, O
USA O
. O
This O
is O
the O
Association O
for O
Computational O
Linguistics O
. O

Aaron O
Schein O
, O
Zhiwei O
Steven O
Wu O
, O
Mingyuan O
Zhou O
, O
and O
Hanna O
Wallach O
are O
all O
researchers O
. O

The O
year O
is O
2018 O
. O

Private O
Bayesian O
inference O
for O
count O
models O
that O
are O
local O
. O

ArXiv O
e O
- O
prints O
are O
available O
at O
abs/1803.08471 O
. O

The O
authors O
of O
the O
study O
are O
Jonathan O
Schler O
, O
Moshe O
Koppel O
, O
Shlomo O
Argamon O
, O
and O
James O
Pennebaker O
. O

In O
2006 O
, O

How O
does O
age O
and O
gender O
affect O
blogging O
? O

The O
AAAI O
Spring O
Symposium O
's O
Computational O
Approaches O
to O
Analyzing O
Weblogs O
produced O
a O
technical O
report O
with O
191 O
- O
197 O
pages O
. O

The O
authors O
' O
names O
are O
Yequan O
Wang O
, O
Minlie O
Huang O
, O
Xiaoyan O
Zhu O
, O
and O
Li O
Zhao O
. O

The O
year O
2016 O
. O

This O
sentence O
is O
about O
an O
LSTM O
that O
is O
designed O
to O
pay O
attention O
to O
aspects O
of O
sentiment B-TaskName
in O
order O
to O
classify O
them O
. O

The O
2016 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
was O
held O
in O
Austin O
, O
Texas O
, O
on O
pages O
606 O
- O
615 O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
a O
professional O
organization O
for O
linguists O
who O
work O
with O
computers O
. O

The O
authors O
Xiang O
Zhang O
, O
Junbo O
Zhao O
, O
and O
Yann O
LeCun O
published O
the O
article O
in O
2015 O
. O

Character O
- O
level O
convolutional O
networks O
are O
used O
for O
text O
classification O
. O

In O
" O
Advances O
in O
Neural O
Information O
Processing O
Systems O
28 O
" O
, O
editors O
C. O
Cortes O
, O
N. O
D. O
Lawrence O
, O
D. O
D. O
Lee O
, O
M. O
Sugiyama O
, O
and O
R. O
Garnett O
discuss O
advances O
on O
pages O
649 O
- O
657 O
. O

Curran O
Associates O
, O
Inc. O
is O
a O
company O
. O

Peng O
Zhou O
, O
Zhenyu O
Qi O
, O
Suncong O
Zheng O
, O
Jiaming O
Xu O
, O
Hongyun O
Bao O
, O
and O
Bo O
Xu O
are O
all O
authors O
. O

The O
year O
2016 O
. O

The O
classification I-TaskName
of O
Text B-TaskName
was O
improved O
by O
integrating O
a O
bidirectional O
lstm O
with O
two O
- O
dimensional O
max O
pooling O
. O

At O
the O
26th O
International O
Conference O
on O
Computational O
Linguistics O
in O
Osaka O
, O
Japan O
, O
researchers O
presented O
papers O
on O
a O
variety O
of O
topics O
. O

The O
Organizing O
Committee O
for O
COLING O
2016 O
. O
