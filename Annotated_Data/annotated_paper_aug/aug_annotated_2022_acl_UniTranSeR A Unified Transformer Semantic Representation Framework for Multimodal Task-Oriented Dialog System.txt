UniTranSeR B-MethodName
is O
a O
semantic O
representation O
framework O
for O
Multimodal B-MethodName
Task I-MethodName
- I-MethodName
Oriented I-MethodName
Dialog I-MethodName
Systems I-MethodName
that O
uses O
a O
unified O
transformer O
. O
Zhiyuan O
Ma1 O
, O
Jianjun O
Li1 O
, O
Guohui O
Li1 O
, O
Yongjing O
Cheng2 O
1Huazhong O
University O
of O
Science O
and O
Technology O
( O
HUST O
) O
, O
China O
2National O
University O
of O
Defense O
Technology O
( O
NUDT O
) O
, O
China O
{ O
zhiyuanma,jianjunli,guohuili}@hust.edu.cn O
davidcheng1001@163.com O

multimodal B-MethodName
task I-MethodName
- I-MethodName
oriented I-MethodName
dialog O
systems O
that O
allow O
for O
more O
natural O
and O
intelligent O
interaction O
have O
received O
great O
attention O
recently O
and O
made O
remarkable O
progress O
. O

Despite O
this O
, O
most O
existing O
studies O
follow O
a O
pipeline O
where O
they O
first O
learn O
intra O
- O
modal O
features O
separately O
, O
then O
conduct O
simple O
feature O
concatenation O
or O
attention O
- O
based O
feature O
fusion O
to O
generate O
responses O
. O
This O
limits O
their O
ability O
to O
learn O
inter O
- O
modal O
interactions O
and O
conduct O
cross O
- O
modal O
feature O
alignment O
to O
generate O
more O
intention O
- O
aware O
responses O
. O

We O
propose O
UniTranSeR B-MethodName
, O
a O
unified O
transformer O
semantic O
representation O
framework O
with O
feature O
alignment O
and O
intention O
reasoning O
, O
to O
address O
these O
issues O
. O

Designing O
dialog O
systems O
that O
can O
use O
multiple O
modes O
of O
communication O
. O

The O
sentence O
is O
not O
complete O
. O

We O
first O
embed O
the O
multimodal O
features O
into O
a O
unified O
Transformer O
semantic O
space O
, O
which O
allows O
for O
inter O
- O
modal O
interactions O
. O
We O
then O
devise O
a O
feature O
alignment O
and O
intention O
reasoning O
( O
FAIR O
) O
layer O
to O
perform O
cross O
- O
modal O
entity O
alignment O
and O
fine O
- O
grained O
key O
- O
value O
reasoning O
. O
This O
allows O
us O
to O
more O
effectively O
identify O
the O
user O
's O
intention O
and O
generate O
more O
accurate O
responses O
. O

The O
effectiveness O
of O
UniTranSeR B-MethodName
has O
been O
verified O
by O
experimental O
results O
, O
which O
show O
that O
it O
outperforms O
state O
- O
of O
- O
the O
- O
art O
approaches O
by O
a O
significant O
margin O
on O
the O
representative O
MMD B-DatasetName
dataset O
. O

1 O
Introduction O
The O
multimodal B-MethodName
task I-MethodName
- I-MethodName
oriented I-MethodName
dialog I-MethodName
systems I-MethodName
are O
designed O
to O
help O
users O
achieve O
specific O
goals O
, O
such O
as O
clothing O
recommendation O
or O
restaurant O
reservation O
, O
which O
is O
in O
growing O
demand O
in O
the O
current O
business O
environment O
. O

As O
a O
leading O
study O
, O
Saha O
et O
al O
. O

A O
multimodal B-DatasetName
dialog I-DatasetName
dataset I-DatasetName
( O
MMD M-DatasetName
) O
for O
the O
online O
retail O
domain O
was O
released O
in O
2018 O
. O

, O
2019 O
) O


 O
Many O
multimodal O
dialog O
models O
that O
incorporate O
domain O
knowledge O
have O
been O
proposed O
recently O
, O
based O
on O
such O
a O
benchmark O
dataset O
( O
Chauhan O
et O
al O
. O
, O
2019 O
; O
Zhang O
et O
. O
, O
2019 O
) O
. O

All O
of O
the O
students O
are O
here O
. O

, O
2018 O
) O


 O
The O
taxonomy O
- O
based O
method O
( O
Liao O
et O
al O
. O
, O
2018 O
; O
Cui O
et O
al O
. O
, O
2018 O
) O
is O
exploited O
in O
2019 O
and O
2021 O
. O

There O
are O
two O
methods O
that O
can O
be O
used O
to O
incorporate O
knowledge O
base O
information O
for O
better O
performance O
: O
an O
attention O
- O
based O
method O
( O
Nie O
et O
al O
. O
, O
2019 O
) O
or O
an O
attention O
- O
based O
method O
( O
He O
et O
al O
. O
, O
2020 O
) O
. O

Despite O
significant O
advances O
, O
current O
task I-MethodName
- I-MethodName
oriented I-MethodName
dialog I-MethodName
systems I-MethodName
still O
have O
three O
main O
limitations O
. O

The O
previous O
models O
only O
learned O
the O
intra O
- O
modal O
features O
separately O
before O
fusing O
them O
. O

Since O
multimodal O
cues O
can O
generally O
enhance O
and O
complement O
each O
other O
, O
projecting O
them O
into O
a O
unified O
semantic O
space O
to O
learn O
inter O
- O
modal O
features O
can O
undoubtedly O
help O
improve O
abilities O
for O
natural O
language O
understanding O
, O
which O
will O
in O
turn O
benefit O
response B-TaskName
generation I-TaskName
. O

Secondly O
, O
prior O
models O
only O
conduct O
simple O
feature O
concatenation O
or O
attention O
- O
based O
feature O
fusion O
. O

Without O
learning O
how O
to O
align O
different O
modalities O
before O
fusion O
, O
it O
is O
difficult O
to O
generate O
an O
accurate O
multimodal B-TaskName
response O
. O

For O
example O
, O
if O
a O
user O
asks O
a O
question O
about O
jackets O
similar O
to O
the O
ones O
in O
Figure O
1 O
, O
the O
model O
should O
be O
able O
to O
identify O
the O
word O
" O
jackets O
" O
and O
match O
it O
with O
the O
corresponding O
visual O
features O
in O
order O
to O
provide O
a O
proper O
answer O
and O
enhance O
the O
user O
experience O
. O

Thirdly O
, O
prior O
models O
lack O
the O
capability O
of O
entity O
- O
level O
reasoning O
, O
which O
prevents O
them O
from O
performing O
reasoning O
over O
crucial O
entities O
to O
guide O
intention O
- O
aware O
response O
generation O
. O

For O
example O
, O
in O
Figure O
1 O
, O
the O
chatbot O
is O
expected O
to O
properly O
explore O
the O
pivot O
attribute O
" O
black O
" O
that O
connects O
the O
start O
query O
cue O
" O
jackets O
" O
with O
the O
target O
recommended O
product O
images O
when O
the O
user O
asks O
" O
show O
some O
similar O
jackets O
in O
black O
color O
. O
" O

The O
model O
needs O
to O
perform O
a O
2 O
- O
hop O
reasoning O
over O
triples O
to O
obtain O
the O
intended O
images O
. O

We O
propose O
a O
new O
framework O
called O
UniTranSeR B-MethodName
that O
overcomes O
the O
aforementioned O
limitations O
by O
aligning O
features O
and O
reasoning O
about O
intentions O
. O

The O
sentence O
is O
not O
complete O
. O

, O
2020 O
; O
Su O
et O
al O
. O
, O
2020 O
) O


 O
We O
build O
on O
the O
success O
of O
Vision O
- O
and O
- O
Language O
Pre O
- O
training O
( O
VLP O
) O
methods O
to O
address O
the O
first O
limitation O
. O

Chen O
et O
al O
. O
( O
2020 O
) O
and O
Li O
et O
al O
. O
( O
2021 O
) O
proposed O
a O
uniﬁed O
- O
modal O
Transformer O
encoder O
to O
project O
all O
the O
multimodal O
features O
into O
a O
uniﬁed O
semantic O
space O
to O
prompt O
inter O
- O
modality O
interactions O
, O
with O
the O
objective O
of O
learning O
better O
representations O
. O

We O
address O
the O
second O
limitation O
by O
designing O
a O
feature O
alignment O
module O
to O
perform O
cross O
- O
modal O
feature O
alignment O
, O
based O
on O
the O
unified O
encoder O
. O

To O
address O
the O
third O
limitation O
, O
we O
devised O
a O
fine O
- O
grained O
intention O
reasoning O
module O
that O
leverages O
a O
key O
- O
value O
attention O
based O
memory O
mechanism O
. O
This O
allows O
for O
multi O
- O
hop O
knowledge O
query O
in O
order O
to O
generate O
text O
or O
image O
responses O
. O

We O
conduct O
experiments O
on O
the O
MMD B-DatasetName
dataset O
, O
which O
is O
one O
of O
the O
most O
influential O
benchmark O
datasets O
for O
multimodal B-TaskName
dialog I-TaskName
generation I-TaskName
. O

We O
demonstrate O
that O
UniTranSeR B-MethodName
significantly O
outperforms O
current O
state O
- O
of O
- O
the O
- O
art O
baselines O
by O
following O
the O
mainstream O
evaluation O
script O
of O
dialog B-TaskName
generation I-TaskName
. O

Studies O
have O
shown O
that O
each O
component O
of O
our O
model O
is O
effective O
in O
improving O
the O
performance O
of O
dialog I-TaskName
generation I-TaskName
, O
and O
a O
further O
case O
study O
reveals O
that O
our O
model O
can O
effectively O
perform O
fine O
- O
grained O
token O
- O
level O
feature O
alignment O
for O
multimodal B-TaskName
dialog I-TaskName
generation I-TaskName
. O

Two O
pieces O
of O
related O
work O
are O
mentioned O
in O
the O
following O
paragraphs O
. O
The O
first O
is O
about O
work O
done O
on O
similar O
topics O
and O
the O
second O
is O
about O
work O
done O
on O
related O
topics O
. O

. O
. O
) O
and O
task O
- O
oriented O
dialogues O
( O
Li O
et O
al O
. O
, O
2016 O
; O
Wen O
et O
al O
. O
, O
2016 O
; O
. O
. O
. O
) O


 O
In O
recent O
years O
, O
there O
have O
been O
remarkable O
successes O
in O
textual O
Dialog I-MethodName
Systems I-MethodName
, O
which O
can O
be O
roughly O
divided O
into O
two O
categories O
: O
open O
- O
domain O
conversations O
with O
casual O
chi O
- O
chat O
( O
Song O
et O
al O
. O
, O
2020 O
; O
Gangal O
et O
al O
. O
, O
2021 O
; O
... O
) O
and O
task O
- O
oriented O
dialogues O
( O
Li O
et O
al O
. O
, O
2016 O
; O
Wen O
et O
al O
. O
, O
2016 O
; O
... O
) O
. O

Chan O
et O
al O
. O
, O
2021 O
; O
Yang O
et O
al O
. O
, O
2021 O
) O
and O
task O
- O
oriented O
dialog O
systems O
( O
Pei O
et O
al O
. O
, O
2021 O
; O
Santra O
et O
al O
. O
, O
2021 O
; O
Wang O
et O
al O
. O
, O
2021 O
; O
Mi O
et O
al O
. O
, O
2021 O
; O
Madotto O
et O
al O
. O
, O
2021 O
; O
Gou O
et O
al O
. O
, O
2021 O
; O
Raghu O
et O
al O
. O
, O
2021 O
) O
, O
which O
are O
all O
designed O
to O
help O
users O
achieve O
specific O
goals O
. O

Early O
efforts O
to O
develop O
a O
sequence O
- O
to O
- O
sequence O
architecture O
were O
not O
effective O
for O
KB O
retrieval O
and O
reasoning O
. O

Copy O
mechanisms O
have O
been O
adopted O
to O
alleviate O
this O
problem O
and O
many O
memory O
augmented O
Seq2Seq O
models O
have O
been O
proposed O
. O

The O
aforementioned O
studies O
( O
Wen O
et O
al O
. O
, O
2018 O
; O
Madotto O
et O
al O
. O
, O
2018 O
; O
Wu O
et O
al O
. O
, O
2019 O
; O
Reddy O
et O
al O
. O
, O
2019 O
; O
Qin O
et O
al O
. O
, O
2019 O
; O
Wang O
et O
al O
. O
, O
2020 O
; O
Qin O
et O
al O
. O
, O
2020 O
) O
have O
yielded O
promising O
results O
. O

With O
the O
rise O
of O
social O
media O
platforms O
, O
large O
amounts O
of O
multimedia O
data O
are O
created O
daily O
, O
requiring O
the O
need O
for O
Multimodal B-MethodName
Dialog I-MethodName
Systems I-MethodName
. O

However O
, O
because O
there O
are O
few O
large O
- O
scale O
multimodal O
dialog O
datasets O
, O
research O
in O
this O
area O
has O
been O
limited O
. O

This O
is O
the O
goal O
that O
Saha O
et O
al O
. O
are O
working O
towards O
. O

The O
MMD B-DatasetName
dataset O
provides O
a O
vertical O
retail O
domain O
to O
promote O
research O
and O
proposed O
a O
multimodal B-MethodName
hierarchical I-MethodName
encoder O
- O
decoder I-MethodName
model I-MethodName
( O
MHRED B-MethodName
) O
as O
a O
baseline O
. O

Liao O
et O
al O
. O
base O
their O
study O
on O
MHRED B-MethodName
. O

The O
sentence O
means O
that O
the O
2018 O
model I-MethodName
includes O
information O
about O
different O
styles O
, O
and O
that O
it O
is O
possible O
to O
learn O
more O
than O
one O
style O
at O
the O
same O
time O
. O

al O
. O
reported O


 O
Cui O
and O
his O
colleagues O
reported O

All O
. O

The O
sentence O
says O
that O
someone O
designed O
a O
system I-MethodName
that O
takes O
into O
account O
a O
user O
's O
attention O
to O
products O
when O
considering O
a O
hierarchical O
product O
taxonomy O
. O

( O
2018 O
) O
showed O
that O


 O
According O
to O
Chauhan O
et O
al O
. O
( O
2018 O
) O
, O

In O
2019 O
, O
a O
multimodal I-MethodName
dialog I-MethodName
system I-MethodName
( O
OAM B-MethodName
) O
was O
introduced O
that O
takes O
into O
account O
ordinals O
and O
attributes O
by O
using O
a O
novel O
attention O
mechanism O
that O
is O
aware O
of O
position O
and O
attributes O
. O

proposed O
an O
extension O


 O
Nie O
et O
al O
. O
later O
proposed O
an O
extension O
. O

In O
2019 O
, O
a O
multimodal B-MethodName
dialog I-MethodName
system I-MethodName
with I-MethodName
adaptive I-MethodName
decoders I-MethodName
( O
MAGIC B-MethodName
) O
was O
proposed O
, O
which O
can O
generate O
different O
kinds O
of O
responses O
by O
incorporating O
different O
forms O
of O
domain O
knowledge O
. O

Recently O
, O
104 O
has O
been O
combined O
with O
. O

, O
( O
2018 O
) O


 O
Transformer O
( O
Vaswani O
et O
al O
. O
, O
2017 O
; O
He O
et O
al O
. O
, O
2018 O
) O

The O
MATE B-MethodName
system I-MethodName
for O
textual B-TaskName
response I-TaskName
generation I-TaskName
captures O
context O
- O
aware O
dependencies O
of O
semantic O
elements O
. O

Most O
multimodal B-MethodName
dialog I-MethodName
systems I-MethodName
learn O
intra O
- O
modal O
features O
separately O
, O
to O
be O
later O
concatenated O
or O
fused O
. O

Our O
proposed O
UniTranSeR B-MethodName
is O
different O
from O
them O
in O
that O
it O
can O
project O
all O
the O
multimodal O
features O
into O
a O
unified O
semantic O
space O
to O
perform O
fine O
- O
grained O
feature O
alignment O
and O
intention O
reasoning O
, O
which O
can O
lead O
to O
more O
accurate O
responses O
. O

Vision O
- O
Language O
Pre O
- O
training O
( O
VLP O
) O
( O
Lu O
et O
al O
. O
, O
2019 O
; O
Li O
et O
al O
. O
, O
2021 O
) O
is O
another O
area O
of O
research O
that O
is O
relevant O
to O
our O
work O
, O
but O
different O
from O
ours O
in O
that O
it O
focuses O
more O
on O
boosting O
the O
performance O
of O
representation O
learning O
. O
Our O
multimodal O
dialog O
systems O
focus O
more O
on O
multi O
- O
turn O
multimodal O
interaction O
between O
users O
and O
agents O
. O

The O
proposed O
UniTranSeR B-MethodName
mainly O
comprises O
three O
parts O
: O
the O
Uniﬁed O
- O
modal O
Transformer O
Semantic O
( O
UTS O
) O
encoder O
, O
the O
Feature O
Alignment O
and O
Inten O
- O
tion O
Reasoning O
( O
FAIR O
) O
layer O
, O
and O
the O
Hi O
- O
erarchical O
Transformer O
Response O
( O
HTR O
) O
decoder O
, O
as O
shown O
in O
Figure O
2 O
. O

We O
define O
the O
multimodal O
dialog I-TaskName
generation I-TaskName
task O
as O
generating O
the O
most O
likely O
response O
sequence O
Y= O
y1,y2, O
... O
,yngand O
selecting O
top- O
kmost O
matched O
images O
, O
given O
multimodal O
context O
utterances O
U= O
u1,u2, O
... O
ujUjgand O
. O

A O
multimodal O
knowledge O
base O
takes O
in O
multiple O
forms O
of O
input O
. O

The O
probability O
of O
a O
textual O
response O
can O
be O
formally O
defined O
as O
P(Y|U;B O
) O
. O

The O
HTR O
decoder O
decodes O
the O
current O
token O
. O

The O
UTS O
encoder O
projects O
all O
the O
multimodal O
features O
into O
a O
unified O
vector O
space O
, O
while O
the O
FAIR O
layer O
is O
designed O
to O
align O
cross O
- O
modal O
hidden O
features O
with O
textual O
features O
and O
visual O
features O
from O
the O
previous O
UTS O
encoder O
as O
inputs O
. O

Our O
HTR O
decoder O
is O
designed O
to O
decode O
three O
types O
of O
responses O
: O
general O
responses O
that O
refer O
to O
the O
highly O
frequent O
responses O
( O
e.g. O
, O
courtesy O
greetings O
) O
in O
the O
conversation O
, O
such O
as O
“ O
How O
can O
I O
help O
you O
? O
” O
; O
intention O
- O
aware O
responses O
that O
refer O
to O
the O
task O
- O
oriented O
utterances O
, O
such O
as O
“ O
Found O
some O
similar O
black O
leather O
- O
jackets O
for O
you O
” O
; O
and O
multimodal O
responses O
that O
refer O
to O
the O
intention O
- O
aware O
responses O
with O
image O
output O
. O

The O
response O
type O
is O
determined O
by O
a O
query O
vector O
Q O
from O
the O
FAIR O
layer O
. O
An O
intention O
classifier O
is O
trained O
to O
decide O
which O
kind O
of O
response O
should O
be O
given O
out O
. O

We O
use O
a O
text O
embedder O
and O
an O
image O
embedder O
to O
extract O
textual O
features O
and O
visual O
features O
, O
respectively O
. O
We O
then O
use O
both O
the O
text O
and O
image O
embedders O
to O
extract O
informative O
features O
from O
external O
knowledge O
. O

Afterwards O
, O
we O
feed O
these O
three O
kinds O
of O
features O
into O
a O
uniﬁed O
Transformer O
encoder O
in O
order O
to O
learn O
a O
uniﬁed O
- O
modal O
semantic O
representation O
. O

The O
text O
embedder O
inserts O
text O
into O
a O
document O
. O

To O
learn O
textual O
intra O
- O
modal O
features O
, O
we O
use O
a O
BERT O
tokenizer O
to O
split O
the O
input O
sentence O
into O
words O
and O
exploit O
a O
single O
transformer O
layer O
to O
obtain O
initial O
word O
embeddings O
. O

The O
self O
- O
attention O
mechanism O
in O
Transformer O
is O
not O
concerned O
with O
the O
order O
of O
the O
input O
. O

It O
is O
necessary O
to O
encode O
the O
words O
' O
position O
as O
additional O
inputs O
. O

The O
final O
item O
on O
the O
list O
is O
a O
book O
. O


 O
The O
final O
item O
on O
the O
list O
is O
a O
book O
. O

The O
representation O
for O
each O
word O
is O
derived O
by O
summing O
up O
its O
word O
embedding O
and O
position O
embedding O
, O
followed O
by O
a O
layer O
normalization O
( O
LN O
) O
layer O
. O

This O
sentence O
is O
about O
the O
Image O
Embedder O
. O

We O
use O
a O
contour O
slicer O
to O
cut O
the O
input O
images O
into O
patches O
and O
exploit O
ResNet-50 O
( O
He O
et O
al O
. O
, O
2016 O
) O
to O
extract O
these O
patches O
' O
visual O
features O
in O
order O
to O
learn O
visual O
intra O
- O
modal O
features O
. O

We O
notice O
that O
people O
usually O
focus O
on O
four O
parts O
of O
a O
clothing O
image O
: O
head O
, O
upper O
body O
, O
lower O
body O
, O
and O
feet O
. O
We O
use O
an O
equal O
- O
height O
mode O
to O
slice O
an O
image O
into O
four O
patches O
which O
efficiently O
solves O
the O
problem O
of O
region O
feature O
extraction O
, O
without O
using O
complex O
target O
detection O
networks O
such O
as O
Faster O
R O
- O
CNN O
. O

After O
that O
, O
we O
input O
the O
patches O
into O
ResNet-50 O
to O
obtain O
the O
patches O
' O
initial O
embeddings O
. O

We O
also O
encode O
the O
position O
features O
for O
each O
patch O
via O
a O
4 O
- O
dimensional O
vector O
. O

The O
index O
, O
width O
, O
and O
height O
are O
in O
that O
order O
. O

Both O
visual O
and O
position O
features O
are O
then O
fed O
through O
a O
fully O
- O
connected O
( O
FC O
) O
layer O
and O
projected O
into O
the O
same O
embedding O
space O
. O

The O
final O
visual O
embedding O
for O
each O
patch O
is O
obtained O
by O
first O
summing O
up O
the O
two O
fully O
connected O
outputs O
, O
and O
then O
passing O
them O
through O
a O
layer O
normalization O
layer O
. O

The O
Knowledge O
Embedder O
inserts O
knowledge O
into O
a O
system O
. O

We O
equip O
the O
product O
knowledge O
base O
for O
each O
utterance O
through O
searching O
a O
fashion O
item O
table O
provided O
by O
MMD B-DatasetName
in O
order O
to O
integrate O
informative O
features O
from O
external O
knowledge1 O
into O
the O
task O
- O
oriented O
dialog O
. O

We O
then O
format O
the O
searched O
knowledge O
entries O
in O
the O
same O
triplet O
format O
, O
i.e. O
, O
( O
product O
, O
match O
, O
product O
) O
, O
( O
product O
, O
attribute O
, O
value O
) O
, O
( O
product O
, O
celebrity O
, O
passion_score O
) O
. O

Next O
, O
we O
use O
text O
and O
image O
embedders O
to O
obtain O
representations O
for O
the O
text O
and O
image O
elements O
of O
these O
triples O
. O

Uniﬁed O
Transformer O
Encoder O
is O
a O
transformer O
encoder O
that O
is O
uniﬁed O
. O

We O
use O
a O
unified O
Transformer O
encoder O
to O
obtain O
interactive O
representations O
of O
multimodal O
initial O
embeddings O
, O
denoted O
as O
ht O
, O
hv O
, O
and O
hk O
, O
by O
projecting O
them O
into O
a O
unified O
semantic O
space O
. O

There O
are O
specifically O
three O
types O
of O
tokens O
in O
each O
utterance O
: O
textual O
features O
, O
visual O
features O
, O
and O
informative O
features O
. O

. O
. O


 O
In O
order O
to O
integrate O
, O
we O
need O
to O
be O
able O
to O
see O
things O
from O
other O
people O
's O
perspectives O
. O

We O
initialize O
the O
current O
dialog O
history O
with O
the O
dialog O
history O
of O
the O
previous O
rounds O
. O

By O
using O
the O
representation O
of O
the O
previous O
round O
, O
the O
sentence O
can O
be O
paraphrased O
. O

The O
output O
hidden O
state O
representations O
can O
then O
be O
expressed O
as O
: O
Hp O
= O
f. O

Assuming O
that O
f O
( O
) O
denotes O
the O
Transformer O
encoder O
and O
Hp O
0 O
denotes O
the O
hidden O
state O
representation O
of O
the O
current O
round O
, O
the O
sentence O
means O
that O
the O
Transformer O
encoder O
will O
generate O
a O
hidden O
state O
representation O
for O
the O
next O
round O
. O

The O
sentence O
is O
saying O
that O
CLS O
is O
regarded O
as O
the O
con- O
. O

The O
Hp O
1 O
: O
l O
vector O
represents O
the O
text O
sequence O
, O
Hp O
l+1 O
: O
l+4 O
represents O
the O
patch O
sequence O
, O
and O
Hp O
l+5 O
: O
l+8 O
represents O
the O
knowledge O
entries O
. O

For O
simplicity O
, O
the O
superscript O
pis O
will O
be O
omitted O
if O
no O
confusion O
occurs O
in O
the O
following O
discussion O
. O

We O
can O
improve O
the O
quality O
of O
our O
representations O
by O
training O
with O
the O
Masked O
Language O
Modeling O
( O
MLM O
) O
and O
Masked O
Patch O
Modeling O
( O
MPM O
) O
losses O
. O

We O
denote O
the O
input O
words O
as O
w O
= O
fw1;:::;wlg O
and O
the O
image O
patches O
as O
v O
. O

The O
sentence O
consists O
of O
the O
variables O
v1 O
through O
v4 O
, O
the O
knowledge O
elements O
k1 O
through O
k4 O
, O
and O
the O
mask O
indices O
m2NL O
, O
where O
N O
is O
the O
set O
of O
natural O
numbers O
and O
L O
is O
the O
length O
of O
the O
masked O
tokens O
. O

We O
randomly O
mask O
out O
input O
words O
with O
a O
probability O
of O
15 O
% O
and O
replace O
the O
masked O
ones O
with O
a O
special O
token O
" O
[ O
MASK O
] O
" O
, O
as O
illustrated O
in O
Figure O
3 O
. O

The O
goal O
is O
to O
accurately O
predict O
the O
masked O
words O
by O
taking O
into O
account O
the O
surrounding O
words O
, O
image O
patches O
, O
and O
knowledge O
elements O
, O
and O
to O
minimize O
the O
loss O
associated O
with O
this O
. O

We O
also O
randomly O
mask O
out O
image O
patches O
and O
replace O
them O
with O
zeros O
tensors O
in O
MPM O
, O
as O
shown O
in O
Figure O
3 O
. O

Unlike O
textual O
words O
which O
can O
be O
seen O
as O
discrete O
labels O
, O
visual O
features O
are O
high O
- O
dimensional O
and O
continuous O
tensors O
and O
can O
not O
be O
supervised O
via O
a O
negative O
log O
- O
likelihood O
loss O
. O

After O
UNITER B-MethodName
( O
Chen O
et O
al O
. O
, O
2020 O
) O
, O
we O
constructed O
the O
MPM O
loss O
as O
: O
LMPM( O
) O
. O

Masking O
here O
refers O
to O
the O
process O
of O
hiding O
certain O
image O
patches O
, O
while O
remaining O
refers O
to O
those O
that O
are O
not O
hidden O
. O

. O
. O


 O
The O
note O
here O
says O
that O
g O
is O
defined O
as O
an O
inverse O
function O
. O

The O
L2 O
regression O
function O
is O
where O
g O
is O
vmjvnm;w;k O
and O
LX O
is O
i=1 O
. O

John O
is O
taller O
than O
Bill O


 O
John O
is O
taller O
than O
Bill O
. O

The O
cat O
slept O
on O
the O
mat O


 O
The O
cat O
slept O
on O
the O
ground O
. O

The O
faster O
an O
object O
moves O
, O
the O
more O
mass O
it O
has O
. O

The O
thief O
was O
apprehended O
by O
the O
police O


 O
The O
police O
apprehended O
the O
thief O
. O

I O
love O
spending O
time O
with O
my O
family O


 O
I O
enjoy O
spending O
time O
with O
my O
family O
. O

We O
devise O
a O
feature O
alignment O
and O
intention O
reasoning O
( O
FAIR O
) O
layer O
to O
align O
the O
cross O
- O
modal O
features O
for O
accurate O
intention O
classification O
and O
knowledge O
query O
. O

In O
image O
alignment O
, O
we O
use O
features O
. O

The O
ITM O
and O
WPA O
are O
used O
to O
conduct O
a O
two O
- O
level O
alignment O
. O

ITM O
is O
used O
to O
align O
text O
and O
image O
at O
the O
sentence O
level O
, O
while O
WPA O
is O
used O
to O
align O
each O
split O
word O
and O
each O
sliced O
patch O
at O
the O
token O
level O
. O

In O
intention O
reasoning O
, O
we O
take O
the O
hidden O
state O
representations O
of O
[ O
CLS O
] O
and O
aligned O
entities O
, O
and O
fuse O
them O
together O
to O
obtain O
a O
query O
vector O
Q. O
This O
query O
vector O
Q O
is O
then O
used O
for O
intention O
classiﬁcation O
and O
knowledge O
query O
. O

The O
image O
- O
text O
matching O
feature O
alignment O
is O
3.2.1 O
. O

In O
ITM O
, O
we O
use O
the O
output O
of O
the O
uniﬁed O
Transformer O
encoder O
to O
compute O
the O
match O
probability O
of O
the O
sampled O
pair O
. O

We O
feed O
the O
[ O
CLS O
] O
vector O
into O
an O
FC O
layer O
and O
a O
sigmoid O
function O
to O
predict O
a O
probability O
score O
P(w;v O
) O
, O
which O
is O
a O
value O
between O
0 O
and O
1 O
. O

At O
each O
step O
during O
training O
, O
we O
sample O
a O
positive O
or O
negative O
pair O
( O
w;v O
) O
from O
the O
dataset O
Dat O
. O

A O
negative O
pair O
is O
created O
by O
randomly O
replacing O
either O
the O
image O
or O
text O
in O
the O
same O
batch O
. O

We O
use O
a O
binary O
cross O
- O
entropy O
loss O
for O
optimization O
: O
LITM( O
) O
. O

The O
expected O
value O
of O
w O
given O
v O
, O
E(w;v O
) O
, O
is O
equal O
to O
the O
summation O
of O
ylogP(w;v O
) O
plus O
( O
1 O
- O
y)log(1 O
- O
P(w;v O
) O
) O
over O
all O
possible O
values O
of O
w. O

We O
only O
use O
ITM O
to O
train O
image O
- O
text O
pairs O
without O
considering O
the O
knowledge O
vector O
. O

When O
being O
searched O
out O
, O
ready O
matched O
the O
textual O
sequence O
. O

The O
alignment O
of O
words O
and O
patchwork O
. O

We O
introduce O
a O
WPA O
technology O
to O
more O
closely O
align O
each O
word O
with O
an O
image O
patch O
. O
This O
technology O
is O
used O
to O
train O
the O
consistency O
and O
exclusiveness O
between O
these O
cross O
- O
modal O
features O
to O
prompt O
alignment O
. O

We O
use O
a O
WPA O
loss O
to O
supervise O
the O
process O
of O
training O
the O
model O
. O

which O
is O
defined O
as O
the O
LWPA O
being O
equal O
to O
the O
sum O
of O
Tij O
for O
all O
i O
and O
j. O

This O
is O
a O
mathematical O
sentence O
that O
can O
not O
be O
paraphrased O
. O

The O
cos()similarity O
function O
denotes O
whether O
or O
not O
T2Rl4is O
a O
ground O
truth O
table O
and O
each O
Tij2 O
T O
is O
a O
binary O
label O
0 O
or O
1 O
. O

We O
create O
a O
probability O
table O
by O
sampling O
positive O
or O
negative O
pairs O
from O
each O
multi O
- O
modal O
utterance O
during O
training O
, O
as O
shown O
in O
Figure O
2 O
. O

The O
parameters O
are O
then O
updated O
using O
the O
LWPA O
loss O
function O
. O

During O
inference O
, O
we O
continue O
to O
fuse O
the O
aligned O
entities O
' O
hidden O
state O
representation O
and O
f([CLS O
] O
) O
to O
obtain O
a O
unified O
query O
vector O
Q. O
This O
vector O
contains O
multimodal O
query O
information O
with O
entity O
enhancement O
, O
and O
will O
be O
used O
for O
subsequent O
intention O
reasoning O
. O

The O
Intention O
Reasoning O
Intention O
Classify O
( O
IC O
) O
classifies O
intentions O
. O

This O
component O
analyzes O
the O
query O
vector O
Q O
to O
understand O
the O
user O
's O
intention O
and O
generate O
an O
appropriate O
response O
. O

In O
total O
, O
there O
are O
17 O
types O
of O
labels O
in O
the O
MMD B-DatasetName
dataset O
. O
Each O
user O
's O
utterance O
is O
labeled O
with O
a O
specific O
intention O
type O
. O

After O
MAGIC B-MethodName
, O
we O
tailor O
the O
response O
to O
the O
specific O
intention O
, O
as O
shown O
in O
Table O
1 O
. O

We O
use O
an O
MLP O
layer O
to O
predict O
Q O
's O
probability O
distribution O
and O
select O
the O
highest O
probability O
to O
generate O
a O
response O
. O

In O
addition O
to O
the O
regular O
entropy O
loss O
, O
a O
cross O
- O
entropy O
loss O
is O
applied O
to O
optimize O
the O
intention O
classifier O
. O

The O
probability O
of O
being O
predicted O
as O
intention O
Iij O
, O
where O
Iij O
is O
a O
ground O
truth O
label O
, O
is O
denoted O
by O
P(IijjQ O
) O
. O

The O
intention O
classifier O
is O
trained O
using O
the O
loss O
function O
LIC( O
) O
to O
update O
the O
parameter O
 O
, O
and O
finally O
outputs O
a O
reliable O
intention O
prediction O
result O
. O

. O
. O


 O
In O
the O
inference O
phase O
, O
the O
system O
looks O
for O
a O
match O
between O
the O
input O
and O
the O
patterns O
that O
it O
has O
learned O
. O

What O
is O
KQ O
? O

This O
component O
will O
determine O
if O
a O
knowledge O
query O
is O
required O
based O
on O
the O
predicted O
intention O
result O
I O
and O
Table O
1 O
. O

We O
use O
a O
key O
- O
value O
memory O
mechanism O
to O
query O
all O
embedded O
knowledge O
triples O
if O
required O
. O

The O
embedded O
knowledge O
triples O
are O
divided O
into O
key O
parts O
and O
value O
parts O
, O
which O
are O
denoted O
as O
vector O
K O
and O
vector O
V. O
K O
is O
obtained O
through O
a O
linear O
transformation O
. O

The O
entities O
and O
relations O
are O
embedded O
in O
the O
fusion O
. O

The O
knowledge O
query O
process O
involves O
the O
following O
steps O
: O

i O
equals O
the O
softmax O
of O
the O
transpose O
of O
Q O
times O
K O
sub O
i O
divided O
by O
the O
transpose O
of O
V O
times O
T O
sub O
j O
, O
all O
summed O
up O
from O
1 O
to O
i. O

This O
is O
equivalent O
to O
saying O
that O
if O
i O
is O
an O
element O
of O
the O
set O
V O
, O
then O
10 O
is O
an O
element O
of O
the O
set O
Vi O
. O

The O
attentive O
probability O
score O
for O
Ki O
indicates O
the O
number O
of O
knowledge O
triples O
that O
VT O
is O
a O
weighted O
sum O
of O
Vi O
, O
which O
will O
be O
used O
for O
textual O
decoding O
in O
an O
intention O
- O
aware O
response O
. O

Multi O
- O
hop O
Recommendation O
( O
MR O
) O

Assuming O
the O
predicted O
intention O
result O
is O
accurate O
, O
and O
based O
on O
a O
one O
- O
hop O
query O
, O
it O
is O
likely O
that O

This O
component O
is O
very O
important O
. O

The O
first O
step O
is O
to O
determine O
whether O
or O
not O
an O
image O
recommendation O
is O
needed O
, O
based O
on O
the O
information O
in O
Table O
1 O
. O

If O
necessary O
, O
we O
can O
use O
VT O
as O
a O
query O
vector O
to O
perform O
another O
query O
over O
the O
entire O
knowledge O
base O
, O
which O
means O
that O
product O
images O
will O
be O
recommended O
if O
the O
key O
parts O
of O
their O
corresponding O
triples O
have O
high O
similarity O
to O
VT O
. O

. O
. O


 O
More O
specifically O
, O
. O
. O
. O

After O
deriving O
the O
gradient O
, O
the O
softmax O
function O
is O
applied O
to O
the O
outputs O
of O
the O
previous O
layer O
, O
multiplied O
by O
a O
weight O
vector O
, O
and O
then O
added O
to O
the O
bias O
vector O
. O

We O
use O
VI O
= O
fqig O
, O
an O
image O
pointer O
vector O
, O
to O
select O
images O
with O
top O
. O

If O
qi O
is O
not O
equal O
to O
1 O
, O
then O
Vi O
is O
equal O
to O
512 O
. O
Otherwise O
, O
Vi O
is O
equal O
to O
0 O
. O

and11512 O
is O
a O
column O
vector O
with O
each O
element O
equal O
to O
1 O
, O
which O
denotes O
the O
special O
token O
[ O
URL O
] O
for O
the O
image O
's O
link O
. O

The O
embedding B-HyperparameterName
size I-HyperparameterName
in O
our O
unified O
Transformer O
encoder O
is O
512 B-HyperparameterValue
. O

It O
's O
easy O
to O
see O
that O
UniTranSeR B-MethodName
can O
extend O
the O
one O
- O
hop O
knowledge O
query O
to O
multiple O
hops O
by O
iteratively O
performing O
attention O
- O
based O
key O
- O
value O
reasoning O
, O
and O
ultimately O
achieve O
multi O
- O
hop O
image O
recommendation O
. O

As O
mentioned O
before O
, O
we O
used O
a O
hierarchical O
system O
to O
decode O
different O
types O
of O
response O
sequences O
, O
including O
general O
responses O
, O
responses O
that O
are O
aware O
of O
intention O
, O
and O
responses O
that O
involve O
multiple O
modes O
. O

They O
use O
the O
same O
Transformer O
layer O
, O
but O
the O
input O
to O
this O
layer O
is O
different O
for O
each O
. O

For O
general O
responses O
, O
we O
take O
the O
sentence O
- O
level O
representations O
as O
input O
. O

We O
take O
the O
concatenation O
of O
f([CLS O
] O
) O
and O
attentive O
vector O
VT O
followed O
by O
an O
FC O
layer O
as O
input O
for O
intention O
aware O
responses O
. O

We O
take O
the O
input O
for O
the O
intention O
- O
aware O
responses O
, O
as O
well O
as O
the O
image O
pointer O
vector O
, O
as O
input O
for O
multimodal O
responses O
. O

We O
use O
the O
widely O
- O
known O
benchmark O
dataset O
MMD B-DatasetName
, O
contributed O
by O
Saha O
et O
al O
. O
, O
to O
evaluate O
the O
performance O
of O
UniTranSeR. O

The O
company O
's O
sales O
increased O
by O
20 O
percent O
last O
year O


 O
The O
company O
's O
sales O
increased O
by O
20 O
percent O
from O
the O
previous O
year O
. O

The O
MMD B-DatasetName
dataset O
contains O
over O
150,000 O
conversations O
between O
users O
and O
chatbots O
in O
the O
retail O
domain O
. O
Each O
conversation O
describes O
a O
complete O
online O
shopping O
process O
. O

The O
user O
proposes O
requirements O
using O
multimodal O
utterances O
during O
the O
conversation O
, O
and O
the O
chatbot O
introduces O
different O
products O
until O
a O
deal O
is O
made O
. O

We O
follow O
Nie O
et O
al O
's O
experiments O
. O

to O
separate O
MMD B-DatasetName

The O
partitioned O
dataset O
's O
statistics O
are O
presented O
in O
Table O
2 O
, O
with O
more O
detailed O
statistics O
in O
Appendix O
A.4 O
. O

We O
use O
Bleu O
- O
n I-MetricName
, O
Nist B-MetricName
and O
Recall@k O
to O
evaluate O
our O
model O
over O
two O
basic O
tasks O
separately O
, O
i.e. O
text O
task O
and O
image O
task O
, O
following O
several O
previous O
works O
( O
Nie O
et O
al O
. O
, O
2019 O
; O
He O
et O
al O
. O
, O
2020 O
; O
Zhang O
et O
al O
. O
, O
2021 O
) O
. O

For O
the O
text O
task O
, O
we O
use O
the O
proposed O
HTR O
decoder O
to O
generate O
all O
general O
responses O
and O
responses O
that O
are O
aware O
of O
intention O
. O

Since O
20.07 O
% O
of O
the O
responses O
in O
MMD B-DatasetName
are O
less O
than O
4 O
characters O
long O
, O
such O
as O
" O
Hello O
! O
" O
, O

We O
follow O
Nie O
et O
al O
, O
and O
thanks O
a O
lot O
! O

To O
calculate O
Bleu O
- O
n I-MetricName
, O
use O
the O
following O
formula O
. O

When O
n B-HyperparameterName
is O
varied O
from O
1 B-HyperparameterValue
to O
4 B-HyperparameterValue
. O

The O
higher O
the O
Bleu O
and O
Nist O
scores O
, O
the O
more O
n O
- O
gram O
overlaps O
exist O
between O
the O
predicted O
and O
target O
responses O
, O
and O
hence O
the O
more O
favorable O
the O
results O
are O
. O

We O
use O
Recall@ B-MetricName
k B-HyperparameterName
to O
evaluate O
the O
efficacy O
of O
image O
response O
for O
the O
image O
task O
, O
where O
k B-HyperparameterName
is O
varied O
from O
1 B-MetricValue
to O
3 B-MetricValue
. O

The O
image O
response O
is O
only O
considered O
correct O
if O
the O
positive O
image O
is O
recommended O
in O
the O
top O
k O
product O
images O
. O

We O
compare O
our O
model O
with O
the O
following O
state O
- O
of O
- O
the O
- O
art O
baselines O
. O

MHRED O
is O
the O
first O
work O
to O
integrate O
visual O
features O
into O
a O
hierarchical O
encoder O
- O
decoder O
model O
for O
their O
constructed O
MMD B-DatasetName
dataset O
. O

KMD O
( O
Liao O
et O
al O
. O
, O
2018 O
) O
uses O
deep O
reinforcement O
learning O
to O
improve O
the O
performance O
of O
a O
memory O
augmented O
neural O
model O
that O
incorporates O
style O
tips O
. O

The O
UMD O
system O
proposed O
by O
Cui O
et O
al O
. O
( O
2019 O
) O
takes O
into O
account O
a O
hierarchical O
product O
taxonomy O
and O
the O
user O
's O
attention O
to O
products O
when O
creating O
a O
dialog O
system O
. O

OAM O
proposes O
a O
novel O
mechanism O
that O
is O
aware O
of O
ordinals O
and O
attributes O
for O
multimodal B-TaskName
dialog I-TaskName
generation I-TaskName
. O

The O
sentence O
states O
that O
the O
MAGIC O
system O
uses O
adaptive O
decoders O
with O
intention O
understanding O
to O
explicitly O
generate O
three O
types O
of O
responses O
. O

MATE O
( O
He O
et O
al O
. O
, O
2020 O
) O
uses O
a O
multi O
- O
modal O
element O
- O
level O
encoder O
to O
integrate O
dialog O
context O
and O
knowledge O
to O
generate O
responses O
, O
achieving O
state O
- O
of O
- O
the O
- O
art O
performance O
. O

There O
are O
three O
GitHub O
repositories O
linked O
. O

The O
implementation O
details O
can O
be O
found O
in O
the O
link O
below O
. O

Nie O
et O
al O
. O
( O
2018 O
) O
found O
that O
... O

We O
use O
two O
- O
turn O
utterances O
preceding O
the O
target O
response O
as O
context O
and O
set O
the O
vocabulary O
size O
to O
26,422 O
. O

In O
our O
trainings O
, O
the O
batch B-HyperparameterName
size I-HyperparameterName
is O
set O
to O
64 B-HyperparameterValue
, O
learning B-HyperparameterName
rate I-HyperparameterName
is O
set O
to O
1e-4 O
. O

The O
maximum O
number O
of O
training B-HyperparameterName
epoches I-HyperparameterName
is O
set O
to O
1e4 B-HyperparameterValue
. O

The O
Adam O
optimizer O
is O
used O
to O
optimize O
all O
models O
. O

All O
experiments O
are O
conducted O
with O
the O
PyTorch O
framework O
. O

You O
can O
find O
more O
information O
about O
hyper- O
parameter O
settings O
in O
Appendix O
A.1 O
. O

We O
evaluate O
the O
performance O
of O
our O
model O
from O
two O
aspects O
: O
text O
response O
and O
image O
response O
. O

Our O
model O
UniTranSeR B-MethodName
outperforms O
the O
state O
- O
of O
- O
the O
- O
art O
on O
both O
tasks O
, O
as O
shown O
in O
Table O
3 O
. O

Our O
model O
is O
better O
than O
other O
models O
at O
generating O
responses O
that O
match O
the O
golden O
responses O
closely O
, O
as O
measured O
by O
Bleu B-MetricName
. O

Our O
model O
is O
26.3 O
% O
better O
than O
MATE B-MethodName
at O
Bleu-4 B-MetricName
score O
, O
which O
shows O
that O
our O
model O
is O
better O
at O
learning O
cross O
- O
modal O
feature O
alignment O
and O
conducting O
intention O
reasoning O
to O
generate O
more O
accurate O
and O
informative O
responses O
. O

An O
extremely O
difficult O
performance O
improvement O
can O
be O
observed O
in O
the O
image O
task O
, O
which O
further O
verifies O
the O
superiority O
of O
our O
model O
. O

Human O
evaluation O
is O
the O
process O
of O
making O
judgments O
about O
the O
quality O
of O
something O
based O
on O
personal O
opinion O
. O

The O
human O
evaluation O
focuses O
on O
four O
main O
aspects O
: O
fluency O
, O
relevance O
, O
correctness O
, O
and O
informativeness O
. O
These O
are O
all O
important O
factors O
for O
task O
- O
oriented O
dialogue O
systems O
( O
Cui O
et O
al O
. O
, O
2019 O
; O
Nie O
et O
al O
. O
, O
2019 O
; O
He O
et O
al O
. O
, O
2020 O
) O
. O

We O
randomly O
selected O
200 O
dialogs O
from O
the O
MMD B-DatasetName
datasets O
and O
generated O
responses O
using O
different O
models O
, O
including O
UMD B-MethodName
, O
OAM B-MethodName
, O
MAGIC B-MethodName
, O
and O
MATE B-MethodName
. O

We O
then O
hired O
human O
experts O
to O
score O
the O
responses O
and O
golden O
responses O
in O
blind O
review O
on O
a O
scale O
from O
1 O
to O
5 O
, O
which O
simulated O
a O
real O
- O
life O
multimodal O
task O
- O
oriented O
conversation O
scenario O
. O

The O
final O
manual O
evaluation O
results O
were O
obtained O
by O
calculating O
the O
average O
score O
of O
the O
above O
metrics O
, O
as O
shown O
in O
Table O
4 O
. O

UniTranSeR B-MethodName
outperforms O
the O
other O
four O
models O
on O
all O
metrics O
, O
which O
is O
in O
line O
with O
the O
results O
of O
automatic O
evaluation O
. O

In O
this O
section O
, O
we O
will O
evaluate O
how O
effective O
each O
component O
is O
by O
conducting O
ablation O
experiments O
. O

We O
focus O
on O
five O
crucial O
components O
and O
set O
them O
ac- O
cordingly O
: O
1 O
) O
w/o O
UTS O
Encoder O
denotes O
that O
we O
use O
a O
BiGRU O
to O
replace O
the O
uni- O
fied O
- O
modal O
Transformer O
encoder O
for O
multimodal O
encoding O
; O
2 O
) O
w/o O
HTR O
De- O
coder O
denotes O
that O
we O
use O
a O
Uni O
- O
directional O
GRU O
to O
replace O
the O
hierarchical O
Transformer O
decoder O
for O
response B-TaskName
generation I-TaskName
; O
3 O
) O
w/o O
ITM O
denotes O
that O
we O
remove O
the O
LITM O
loss O
to O
make O
the O
parameters O
not O
updated O
; O
4 O
) O
w/o O
WPA O
denotes O
that O
we O
remove O
the O
LWPA O
loss O
and O
just O
regard O
the O
sentence- O
level O
rep- O
resentation O
f([CLS O
] O
) O
as O
query O
vector O
Q O
to O
query O
knowledge O
; O
5 O
) O
w/o O
IR O
Module O
denotes O
that O
we O
re- O
move O
the O
IC O
and O
KQ O
components O
and O
just O
adopt O
the O
context O
vector O
f([CLS O
] O
) O
to O
generate O
responses10 O
; O
From O
Table O
5 O
, O
we O
can O
observe O
that O
removing O
each O
component O
will O
result O
in O
a O
performance O
degrada- O
tion O
. O

Without O
the O
IR O
module O
, O
there O
is O
a O
54.96 B-MetricValue
% I-MetricValue
drop O
in O
the O
Bleu-4 B-MetricName
score O
and O
a O
54.18 B-MetricValue
% I-MetricValue
drop O
in O
Nist B-MetricName
. O

The O
score O
verifies O
the O
great O
efficacy O
of O
the O
intention O
classify O
and O
knowledge O
query O
components O
. O

Without O
the O
WPA O
, O
ITM O
, O
and O
UTS O
Encoder O
respectively O
, O
there O
is O
a O
28.54 B-MetricValue
% I-MetricValue
, O
20.48 B-MetricValue
% I-MetricValue
, O
and O
14.37 B-MetricValue
% I-MetricValue
drop O
in O
the O
Nist B-MetricName
score O
. O
This O
further O
demonstrates O
the O
effectiveness O
of O
cross O
- O
modal O
feature O
alignment O
and O
unified O
- O
modal O
semantic O
encoding O
. O

In O
order O
to O
more O
clearly O
show O
the O
benefits O
of O
our O
model O
and O
to O
understand O
what O
the O
feature O
alignment O
module O
has O
learned O
, O
we O
have O
provided O
several O
examples O
of O
text O
- O
to O
- O
image O
attention O
in O
Figure O
4 O
. O

Our O
model O
does O
a O
good O
job O
of O
matching O
up O
entities O
between O
different O
modalities O
. O

The O
reason O
we O
adopted O
a O
uniﬁed O
- O
modal O
Transformer O
semantic O
encoder O
is O
because O
it O
enables O
to O
map O
different O
modalities O
of O
semantic O
cues O
into O
a O
same O
vector O
space O
to O
prompt O
inter O
- O
modality O
inter- O
actions O
for O
better O
representations O
. O
Based O
on O
the O
obtained O
representations O
, O
the O
WPA O
technology O
can O
help O
supervise O
ﬁne O
- O
grained O
word O
- O
patch O
alignment O
, O
which O
is O
beneﬁcial O
to O
identifying O
user O
’s O
real O
inten- O
tion O
and O
generate O
more O
intention O
- O
aware O
responses O
. O

In O
conclusion O
, O
we O
propose O
the O
Uni O
- O
TranSeR O
framework O
, O
which O
is O
a O
Unified O
Transformer I-MethodName
Semantic I-MethodName
Representation I-MethodName
that O
uses O
feature O
alignment O
and O
intention O
reasoning O
. O

More O
specifically O
, O
we O
use O
a O
Transformer O
encoder O
to O
prompt O
interactions O
between O
multimodal O
features O
by O
projecting O
them O
into O
a O
unified O
semantic O
space O
. O

We O
design O
a O
feature O
alignment O
and O
intention O
reasoning O
layer O
to O
conduct O
cross O
- O
modal O
feature O
alignment O
and O
fine O
- O
grained O
intention O
reasoning O
. O

The O
objective O
of O
soning O
is O
to O
generate O
more O
accurate O
and O
intention O
- O
aware O
responses O
. O

Both O
automatic O
and O
human O
evaluation O
demonstrate O
the O
effectiveness O
and O
superior O
performance O
of O
our O
UniTranSeR B-MethodName
model O
on O
the O
representative O
MMD B-DatasetName
dataset O
. O

Antoine O
Bordes O
, O
Y O
- O
Lan O
Boureau O
, O
and O
Jason O
Weston O
are O
referenced O
. O

The O
year O
is O
2017 O
. O

The O
goal O
of O
learning O
end O
- O
to O
- O
end O
dialog O
is O
to O
be O
able O
to O
have O
a O
conversation O
. O

The O
5th O
International O
Conference O
on O
Learning O
Representations O
was O
held O
in O
Toulon O
, O
France O
from O
April O
24 O
- O
26 O
, O
2017 O
. O

OpenReview.net O
is O
a O
website O
that O
allows O
users O
to O
post O
reviews O
of O
products O
and O
services O
. O

The O
sentence O
is O
discussing O
the O
authors O
of O
a O
paper O
published O
in O
2021 O
. O

Improving O
the O
dialogue O
evaluation O
in O
latent O
space O
for O
open O
domains O
. O

The O
Association O
for O
Computational O
Linguistics O
( O
ACL O
) O
/ O
IJCNLP O
2021 O
conference O
will O
be O
held O
online O
from O
August O
1 O
- O
6 O
, O
2021 O
. O
The O
conference O
proceedings O
will O
be O
published O
in O
the O
ACL O
/ O
IJCNLP O
2021 O
volume O
of O
the O
Findings O
of O
ACL O
series O
. O

ACL O
is O
an O
organization O
that O
is O
dedicated O
to O
the O
study O
of O
linguistics O
through O
computation O
. O

Hardik O
Chauhan O
, O
Mauajama O
Firdaus O
, O
Asif O
Ekbal O
, O
and O
Pushpak O
Bhattacharyya O
are O
all O
well O
- O
known O
researchers O
in O
the O
field O
of O
artificial O
intelligence O
. O

The O
year O
2019 O
. O

A O
dialogue O
system O
that O
is O
aware O
of O
ordinality O
and O
attributes O
. O

The O
Proceedings O
of O
the O
57th O
Conference O
of O
the O
Association O
for O
Computational O
Linguistics O
( O
ACL O
) O
2019 O
in O
Florence O
, O
Italy O
from O
July O
28- O
August O
2 O
, O
2019 O
, O
Volume O
1 O
: O
Long O
Papers O
, O
pages O
5437 O
- O
5447 O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
a O
professional O
organization O
for O
linguists O
who O
work O
with O
computers O
. O

The O
authors O
of O
the O
2020 O
study O
are O
Yen O
- O
Chun O
Chen O
, O
Linjie O
Li O
, O
Licheng O
Yu O
, O
Ahmed O
El O
Kholy O
, O
Faisal O
Ahmed O
, O
Zhe O
Gan O
, O
Yu O
Cheng O
, O
and O
Jingjing O
Liu O
. O

UNITER B-MethodName
is O
a O
learning O
system O
that O
can O
represent O
images O
and O
text O
universally O
. O

In O
the O
16th O
European O
Conference O
on O
Computer O
Vision O
, O
Glasgow O
, O
UK O
, O
August O
23 O
- O
28 O
, O
2020 O
, O
Proceedings O
, O
Part O
XXX O
, O
volume O
12375 O
of O
Lecture O
Notes O
in O
Computer O
Science O
, O
pages O
104 O
- O
120 O
, O
computer O
vision O
is O
discussed O
. O

Springer O
is O
a O
publishing O
company O
. O

The O
sentence O
is O
about O
six O
people O
who O
wrote O
a O
paper O
in O
2019 O
. O

Multimodal O
dialog O
systems O
that O
are O
guided O
by O
user O
attention O
. O

The O
42nd O
International O
ACM O
SIGIR O
Conference O
on O
Research O
and O
Development O
in O
Information O
Retrieval O
was O
held O
in O
Paris O
, O
France O
from O
July O
21 O
- O
25 O
, O
2019 O
. O

Mihail O
, O
Eric O
, O
and O
Christopher O
D. O
Manning O
. O

This O
sentence O
is O
in O
the O
year O
2017 O
. O

A O
copy O
- O
augmented O
sequence O
- O
to O
- O
sequence O
architecture O
gives O
good O
performance O
on O
task O
- O
oriented O
dialogue O
. O

The O
15th O
Conference O
of O
the O
European O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
was O
held O
in O
Valencia O
, O
Spain O
from O
April O
3 O
- O
7 O
, O
2017 O
. O
Short O
papers O
from O
the O
conference O
are O
included O
in O
Volume O
2 O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
an O
organization O
that O
deals O
with O
the O
field O
of O
linguistics O
that O
deals O
with O
computers O
. O

The O
authors O
of O
the O
2021 O
paper O
are O
Varun O
Gangal O
, O
Harsh O
Jhamtani O
, O
Eduard O
H. O
Hovy O
, O
and O
Taylor O
Berg O
- O
Kirkpatrick O
. O

Improving O
automated O
evaluation O
of O
open O
domain O
dialog O
by O
adding O
diverse O
reference O
points O
. O

The O
Association O
for O
Computational O
Linguistics O
will O
be O
presenting O
their O
findings O
from O
ACL O
/ O
IJCNLP O
2021 O
online O
from O
August O
1 O
- O
6 O
, O
2021 O
. O
Their O
findings O
will O
be O
published O
in O
volume O
ACL O
/ O
IJCNLP O
2021 O
of O
Findings O
of O
ACL O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
an O
organization O
that O
promotes O
the O
study O
of O
linguistics O
through O
computation O
. O

The O
authors O
of O
the O
study O
are O
Yanjie O
Gou O
, O
Yinjie O
Lei O
, O
Lingqiao O
Liu O
, O
Yong O
Dai O
, O
and O
Chunxu O
Shen O
. O

When O
creating O
knowledge O
bases O
for O
dialogue O
systems O
, O
it O
is O
important O
to O
take O
the O
context O
into O
account O
. O
Transformer O
networks O
can O
be O
used O
for O
this O
purpose O
. O

The O
2021 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
will O
be O
held O
virtually O
in O
Punta O
Cana O
, O
Dominican O
Republic O
from O
November O
7 O
- O
11 O
. O
Pages O
4300 O
- O
4310 O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
an O
international O
scientific O
and O
professional O
society O
for O
people O
working O
on O
problems O
involving O
natural O
language O
and O
computation O
. O

Deep O
Residual O
Learning O
for O
Image O
Recognition O


 O
The O
authors O
of O
the O
2016 O
paper O
" O
Deep O
Residual O
Learning O
for O
Image O
Recognition O
" O
are O
Kaiming O
He O
, O
Xiangyu O
Zhang O
, O
Shaoqing O
Ren O
, O
and O
Jian O
Sun O
. O

Deep O
learning O
that O
is O
residual O
for O
image O
recognition O
. O

At O
the O
2016 O
IEEE O
Conference O
on O
Computer O
Vision O
and O
Pattern O
Recognition O
in O
Las O
Vegas O
, O
NV O
, O
USA O
from O
June O
27 O
- O
30 O
, O
2016 O
, O
pages O
770 O
- O
778 O
were O
presented O
. O

IEEE O
Computer O
Society O
is O
an O
organization O
that O
promotes O
the O
advancement O
of O
computer O
science O
and O
technology O
. O

Weidong O
He O
, O
Zhi O
Li O
, O
Dongcai O
Lu O
, O
Enhong O
Chen O
, O
Tong O
Xu O
, O
Baoxing O
Huai O
and O
Jing O
Yuan O
are O
all O
researchers O
at O
Peking O
University O
. O

This O
year O
is O
2020 O
. O

Multi O
- O
modal O
dialogue O
systems O
are O
able O
to O
capture O
context O
- O
aware O
dependencies O
of O
semantic O
elements O
. O

In O
2020 O
, O
the O
28th O
ACM O
International O
Conference O
on O
Multi- O
media O
will O
be O
held O
virtually O
in O
Seattle O
, O
WA O
, O
USA O
from O
October O
12 O
- O
16 O
. O
This O
conference O
will O
cover O
pages O
2755 O
- O
2764 O
. O

The O
authors O
of O
the O
paper O
are O
Liunian O
Harold O
Li O
, O
Mark O
Yatskar O
, O
Da O
Yin O
, O
Cho O
- O
Jui O
Hsieh O
, O
and O
Kai O
- O
Wei O
Chang O
. O

The O
year O
2019 O
. O

Visualbert B-MethodName
is O
a O
great O
tool O
for O
visualizing O
data O
. O

A O
baseline O
that O
is O
both O
simple O
and O
efficient O
for O
vision O
and O
language O
. O

This O
sentence O
is O
the O
title O
of O
a O
research O
paper O
found O
on O
the O
Cornell O
University O
website O
. O

Wei O
Li O
, O
Can O
Gao O
, O
Guocheng O
Niu O
, O
Xinyan O
Xiao O
, O
Hao O
Liu O
, O
Jiachen O
Liu O
, O
Hua O
Wu O
, O
and O
Haifeng O
Wang O
are O
all O
authors O
of O
the O
paper O
. O

This O
sentence O
is O
saying O
that O
the O
year O
is O
2021 O
. O

UNIMO B-MethodName
is O
a O
system O
that O
uses O
cross O
- O
modal O
contrastive O
learning O
to O
improve O
the O
understanding O
and O
generation O
of O
unified O
modal O
expressions O
. O

The O
59th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
and O
the O
11th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
will O
be O
held O
virtually O
from O
August O
1 O
- O
6 O
, O
2021 O
. O
Papers O
from O
the O
conference O
will O
be O
published O
in O
volume O
1 O
of O
the O
conference O
proceedings O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
an O
organization O
that O
deals O
with O
the O
study O
of O
linguistics O
through O
the O
use O
of O
computers O
. O

Lizi O
Liao O
, O
Yunshan O
Ma O
, O
Xiangnan O
He O
, O
Richang O
Hong O
, O
and O
Tat O
- O
Seng O
Chua O
are O
all O
authors O
. O

The O
year O
is O
2018 O
. O

Multi O
- O
modal O
dialogue O
systems O
that O
are O
aware O
of O
knowledge O
. O

The O
ACM O
Multimedia O
Conference O
will O
be O
held O
in O
Seoul O
, O
Republic O
of O
Korea O
from O
October O
22 O
- O
26 O
, O
2018 O
. O

Jiasen O
Lu O
, O
Dhruv O
Batra O
, O
Devi O
Parikh O
, O
and O
Stefan O
Lee O
. O
2019 O
. O

Vilbert B-MethodName
is O
working O
on O
a O
project O
involving O
agnostic O
visi- O
olinguistic O
representations O
, O
which O
can O
be O
used O
for O
a O
variety O
of O
vision O
and O
language O
tasks O
. O

At O
the O
2019 O
NeurIPS O
conference O
, O
held O
in O
Vancouver O
, O
Canada O
, O
from O
December O
8 O
- O
14 O
, O
advances O
in O
neural O
information O
processing O
were O
presented O
in O
23 O
papers O
. O

Andrea O
Madotto O
, O
Zhaojiang O
Lin O
, O
Zhenpeng O
Zhou O
, O
Se O
- O
ungwhan O
Moon O
, O
Paul O
A. O
Crook O
, O
Bing O
Liu O
, O
Zhou O
Yu O
, O
111 O
. O

Eunjoon O
Cho O
, O
Pascale O
Fung O
, O
and O
Zhiguang O
Wang O
( O
2021 O
) O

Continuous O
learning O
in O
task O
- O
oriented O
dialogue O
systems O
. O

In O
the O
2021 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
, O
pages O
7452 O
- O
7467 O
, O
EMNLP O
2021 O
, O
Virtual O
Event O
/ O
Punta O
Cana O
, O
Dominican O
Republic O
, O
7 O
- O
11 O
November O
, O
2021 O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
a O
professional O
organization O
that O
promotes O
the O
study O
of O
linguistics O
through O
the O
use O
of O
computers O
. O

Andrea O
Madotto O
, O
Chien O
- O
Sheng O
Wu O
, O
and O
Pascale O
Fung O
are O
all O
researchers O
. O

The O
year O
2018 O
. O

Incorporating O
knowledge O
bases O
into O
end O
- O
to O
- O
end O
task O
- O
oriented O
dialog O
systems O
can O
be O
effective O
with O
Mem2seq B-MethodName
. O

In O
the O
56th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
ACL O
2018 O
, O
the O
volume O
1 O
: O
Long O
Papers O
was O
presented O
in O
Melbourne O
, O
Australia O
from O
July O
15 O
- O
20 O
, O
2018 O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
an O
organization O
that O
promotes O
the O
use O
of O
computational O
linguistics O
. O

The O
sentence O
means O
that O
the O
six O
people O
listed O
wrote O
a O
paper O
in O
2021 O
. O

Few O
- O
shot O
learning O
in O
task O
- O
oriented O
dialog O
systems O
is O
improved O
by O
self O
- O
training O
. O

EMNLP O
2021 O
will O
be O
held O
virtually O
in O
Punta O
Cana O
, O
Dominican O
Republic O
from O
November O
7 O
- O
11 O
, O
2021 O
. O
Pages O
1887 O
- O
1898 O
will O
be O
featured O
in O
the O
conference O
proceedings O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
an O
organization O
that O
promotes O
the O
use O
of O
computers O
for O
linguistic O
research O
. O

The O
authors O
of O
the O
paper O
are O
Liqiang O
Nie O
, O
Wenjie O
Wang O
, O
Richang O
Hong O
, O
Meng O
Wang O
, O
and O
Qi O
Tian O
. O

This O
sentence O
is O
stating O
that O
the O
year O
is O
2019 O
. O

A O
multimodal O
dialog O
system O
is O
one O
that O
can O
generate O
responses O
via O
adaptive O
decoders O
. O

The O
27th O
ACM O
International O
Conference O
was O
held O
to O
discuss O
various O
topics O
. O

The O
sentence O
is O
about O
the O
location O
and O
date O
of O
an O
event O
called O
MM O
2019 O
. O
The O
event O
will O
take O
place O
in O
Nice O
, O
France O
from O
October O
21 O
- O
25 O
, O
2019 O
. O

The O
Association O
for O
Computing O
Machinery O
. O

Jiahuan O
Pei O
, O
Pengjie O
Ren O
, O
and O
Maarten O
de O
Rijke O
authored O
a O
paper O
in O
2021 O
. O

A O
memory O
network O
that O
cooperates O
with O
personalized O
dialogue O
systems O
to O
complete O
user O
profiles O
. O

The O
Web O
Conference O
2021 O
will O
take O
place O
virtually O
from O
April O
19 O
- O
23 O
, O
2021 O
in O
Ljubljana O
, O
Slovenia O
. O
Pages O
1552 O
- O
1561 O
. O

The O
Association O
for O
Computing O
Machinery O
( O
ACM O
) O
and O
the O
International O
World O
Wide O
Web O
Conference O
Committee O
( O
IW3C2 O
) O
are O
two O
organizations O
that O
work O
together O
on O
standards O
for O
the O
World O
Wide O
Web O
. O

Libo O
Qin O
, O
Yijia O
Liu O
, O
Wanxiang O
Che O
, O
Haoyang O
Wen O
, O
Yangming O
Li O
, O
and O
Ting O
Liu O
are O
all O
researchers O
at O
Beijing O
Normal O
University O
. O

This O
is O
the O
year O
2019 O
. O

An O
entity O
is O
a O
consistent O
, O
end O
- O
to O
- O
end O
, O
task O
- O
oriented O
dialogue O
system O
with O
a O
KB O
retriever O
. O

In O
2019 O
, O
at O
the O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
and O
the O
9th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
in O
Hong O
Kong O
, O
China O
, O
pages O
133 O
- O
142 O
were O
discussing O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
an O
organization O
that O
deals O
with O
the O
study O
of O
linguistics O
through O
the O
use O
of O
computers O
. O

The O
names O
listed O
are O
Libo O
Qin O
, O
Xiao O
Xu O
, O
Wanxiang O
Che O
, O
Yue O
Zhang O
, O
and O
Ting O
Liu O
, O
and O
the O
year O
is O
2020 O
. O

A O
dynamic O
fusion O
network O
that O
can O
be O
used O
for O
multi O
- O
domain O
end O
- O
to O
- O
end O
task O
- O
oriented O
dialogues O
. O

In O
the O
58th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
pages O
6344 O
- O
6354 O
were O
presented O
online O
from O
July O
5 O
- O
10 O
, O
2020 O
. O

Dinesh O
Raghu O
, O
Atishya O
Jain O
, O
Mausam O
, O
and O
Sachindra O
Joshi O
( O
2021 O
) O

Constraint O
based O
knowledge O
base O
distillation O
is O
a O
process O
of O
reducing O
a O
knowledge O
base O
to O
its O
most O
important O
parts O
in O
order O
to O
create O
more O
efficient O
end O
- O
to O
- O
end O
task O
oriented O
dialogs O
. O

The O
Association O
for O
Computational O
Linguistics O
found O
that O
_ O
_ O
_ O
_ O
_ O
. O

The O
2021 O
ACL O
/ O
IJCNLP O
will O
be O
an O
online O
event O
from O
August O
1 O
- O
6 O
. O
Volume O
ACL O
/ O
IJCNLP O
2021 O
of O
Findings O
of O
ACL O
will O
be O
published O
on O
pages O
5051–5061 O
. O

This O
is O
the O
Association O
for O
Computational O
Linguistics O
. O

Revanth O
Reddy O
, O
Danish O
Contractor O
, O
Dinesh O
Raghu O
, O
and O
Sachindra O
Joshi O
are O
all O
names O
. O

This O
year O
is O
2019 O
. O

Multi O
- O
level O
memory O
is O
a O
type O
of O
memory O
that O
is O
used O
for O
task O
- O
oriented O
dialogs O
. O

At O
the O
2019 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Human O
Language O
Technologies O
, O
NAACL O
- O
HLT O
2019 O
, O
held O
in O
Minneapolis O
, O
MN O
, O
USA O
, O
from O
June O
2 O
- O
7 O
, O
2019 O
, O
researchers O
presented O
papers O
on O
a O
variety O
of O
topics O
related O
to O
language O
and O
computing O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
an O
organization O
that O
promotes O
the O
use O
of O
computer O
simulations O
to O
study O
language O
. O

Shaoqing O
Ren O
, O
Kaiming O
He O
, O
Ross O
B. O
Girshick O
, O
and O
Jian O
Sun O
are O
the O
authors O
of O
2015 O
. O

Faster B-MethodName
R I-MethodName
- O
CNN I-MethodName
is O
a O
region O
proposal O
network O
that O
is O
designed O
for O
real O
- O
time O
object B-TaskName
detection I-TaskName
. O

The O
paper O
" O
Advanes O
in O
Neural O
Information O
Processing O
Systems O
28 O
" O
was O
presented O
at O
the O
Annual O
Conference O
on O
Neural O
Information O
Processing O
Systems O
in O
2015 O
. O

Amrita O
Saha O
, O
Mitesh O
M. O
Khapra O
, O
and O
Karthik O
Sankaranarayanan O
are O
researchers O
at O
IIT O
Bombay O
. O

This O
sentence O
is O
in O
the O
year O
2018 O
. O

. O
. O


 O
In O
order O
to O
build O
large O
- O
scale O
, O
multi O
- O
modal O
, O
domain O
- O
aware O
conversation O
systems O
. O
. O
. O

The O
30th O
innovative O
Applications O
of O
Artificial O
Intelligence O
( O
IAAI-18 O
) O
was O
held O
in O
New O
Orleans O
, O
Louisiana O
, O
USA O
from O
February O
2 O
- O
7 O
, O
2018 O
. O

This O
is O
a O
sentence O
about O
the O
AAAI O
Press O
. O

Bishal O
Santra O
, O
Potnuru O
Anusha O
, O
and O
Pawan O
Goyal O
( O
2021 O
) O

A O
transformer O
that O
is O
task O
- O
oriented O
and O
hierarchical O
for O
dialog O
systems O
. O

At O
the O
2021 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Human O
Language O
Technologies O
, O
NAACL O
- O
HLT O
2021 O
, O
held O
online O
from O
June O
6 O
- O
11 O
, O
2021 O
, O
pages O
5649 O
- O
5658 O
were O
presented O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
an O
organization O
that O
promotes O
the O
use O
of O
computers O
for O
linguistic O
research O
. O

The O
following O
people O
Haoyu O
Song O
, O
Yan O
Wang O
, O
Wei O
- O
Nan O
Zhang O
, O
Zhengyu O
Zhao O
, O
Ting O
Liu O
, O
and O
Xiaojiang O
Liu O
are O
from O
2020 O
. O

One O
way O
to O
create O
believable O
open O
- O
domain O
dialogue O
agents O
is O
to O
give O
them O
consistent O
profiles O
. O

The O
2020 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
was O
held O
online O
from O
November O
16 O
- O
20 O
. O
Pages O
6651 O
- O
6662 O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
a O
professional O
organization O
for O
linguists O
who O
work O
with O
computers O
. O

Ashish O
Vaswani O
, O
Noam O
Shazeer O
, O
Niki O
Parmar O
, O
Jakob O
Uszkoreit O
, O
Llion O
Jones O
, O
Aidan O
N. O
Gomez O
, O
Lukasz O
Kaiser O
, O
and O
Illia O
Polosukhin O
authored O
a O
paper O
in O
2017 O
. O

If O
you O
want O
something O
, O
you O
need O
to O
pay O
attention O
to O
it O
. O

In O
Advances O
in O
Neural O
Information O
Processing O
Systems O
30 O
, O
the O
Annual O
Conference O
on O
Neural O
Information O
Processing O
Systems O
2017 O
will O
be O
held O
from O
December O
4 O
- O
9 O
in O
Long O
Beach O
, O
CA O
, O
USA O
. O
Pages O
5998 O
- O
6008 O
will O
be O
devoted O
to O
this O
conference O
. O

Jian O
Wang O
, O
Junhao O
Liu O
, O
Wei O
Bi O
, O
Xiaojiang O
Liu O
, O
Ke O
- O
jing O
He O
, O
Ruifeng O
Xu O
, O
and O
Min O
Yang O
all O
authored O
the O
following O
sentence O
. O

This O
year O
is O
2020 O
. O

A O
dual O
dynamic O
memory O
network O
can O
be O
used O
for O
end O
- O
to O
- O
end O
multi O
- O
turn O
task O
- O
oriented O
dialog O
systems O
. O

In O
the O
28th O
International O
Conference O
on O
Computational O
Linguistics O
, O
COLING O
2020 O
, O
Barcelona O
, O
Spain O
( O
On O
- O
line O
) O
, O
December O
8 O
- O
13 O
, O
2020 O
, O
pages O
4100 O
- O
4110 O
, O
Inter O
- O
national O
Committee O
on O
Computational O
Linguistics O
. O
112 O
. O

Jianhong O
Wang O
, O
Yuan O
Zhang O
, O
Tae O
- O
Kyun O
Kim O
, O
and O
Yun O
- O
jie O
Gu O
. O
2021 O
. O

The O
option O
framework O
is O
a O
way O
of O
modelling O
the O
hierarchical O
structure O
between O
the O
dialogue O
policy O
and O
the O
natural O
language O
generator O
for O
task O
- O
oriented O
dialogue O
systems O
. O

The O
9th O
International O
Conference O
on O
Learning O
Representations O
will O
be O
held O
virtually O
in O
Austria O
from O
May O
3 O
- O
7 O
, O
2021 O
. O

OpenReview.net O
is O
an O
online O
platform O
that O
helps O
facilitate O
academic O
research O
. O

Haoyang O
Wen O
, O
Yijia O
Liu O
, O
Wanxiang O
Che O
, O
Libo O
Qin O
, O
and O
Ting O
Liu O
are O
all O
authors O
. O

2018 O
is O
a O
year O
. O

Sequence O
- O
to O
- O
sequence O
learning O
is O
a O
type O
of O
machine O
learning O
that O
is O
commonly O
used O
for O
task O
- O
oriented O
dialogue O
. O
In O
this O
type O
of O
dialogue O
, O
each O
utterance O
is O
represented O
as O
a O
sequence O
of O
words O
, O
and O
the O
machine O
learning O
algorithm O
is O
trained O
to O
map O
these O
sequences O
to O
a O
corresponding O
dialogue O
state O
. O

In O
the O
27th O
International O
Conference O
on O
Computational O
Linguistics O
, O
COLING O
2018 O
, O
held O
in O
Santa O
Fe O
, O
New O
Mexico O
, O
USA O
from O
August O
20 O
- O
26 O
, O
2018 O
, O
pages O
3781 O
- O
3792 O
were O
dedicated O
to O
the O
conference O
. O

The O
Association O
for O
Computational O
Linguistics O
is O
an O
organization O
that O
promotes O
the O
field O
of O
computational O
linguistics O
. O

Chien O
- O
Sheng O
Wu O
, O
Richard O
Socher O
, O
and O
Caiming O
Xiong O
are O
all O
researchers O
in O
the O
field O
of O
artificial O
intelligence O
. O

This O
year O
is O
2019 O
. O

Global O
networks O
that O
pointer O
to O
local O
memory O
for O
task O
- O
oriented O
dialogue O
. O

The O
7th O
International O
Conference O
on O
Learning O
Representations O
( O
ICLR O
2019 O
) O
will O
take O
place O
in O
New O
Orleans O
, O
LA O
, O
USA O
from O
May O
6 O
- O
9 O
, O
2019 O
. O

OpenReview.net O
is O
an O
open O
- O
access O
online O
database O
that O
provides O
reviews O
of O
academic O
papers O
. O

The O
people O
in O
the O
photo O
are O
Ze O
Yang O
, O
Wei O
Wu O
, O
and O
Huang O
Hu O
. O

Could O
Xu O
, O
Wei O
Wang O
, O
and O
Zhoujun O
Li O
please O
come O
here O
. O

This O
sentence O
is O
not O
a O
question O
. O

Open O
domain O
dialogue B-TaskName
generation O
with O
latent O
images O
refers O
to O
the O
ability O
to O
generate O
dialogue B-TaskName
with O
images O
that O
are O
not O
explicitly O
shown O
. O

The O
Thirty O
- O
Fifth O
AAAI O
Conference O
on O
Artificial O
Intelligence O
and O
the O
Thirty O
- O
Third O
Conference O
on O
Innovative O
Applications O
of O
Artificial O
Intelligence O
will O
be O
held O
in O
2021 O
. O
The O
Eleventh O
Symposium O
on O
Educational O
Advances O
in O
Artificial O
Intelligence O
will O
also O
be O
held O
in O
2021 O
. O

The O
EAAI O
2021 O
Virtual O
Event O
will O
take O
place O
from O
February O
2 O
- O
9 O
, O
2021 O
and O
will O
feature O
intelligence O
on O
page O
14239 O
- O
14247 O
. O

This O
is O
a O
press O
release O
from O
AAAI O
. O

The O
authors O
of O
the O
study O
are O
Haoyu O
Zhang O
, O
Meng O
Liu O
, O
Zan O
Gao O
, O
Xiaoqiang O
Lei O
, O
Yinglong O
Wang O
, O
and O
Liqiang O
Nie O
. O

A O
multimodal O
dialog O
system O
that O
is O
context O
- O
aware O
and O
uses O
relational O
graphs O
to O
understand O
questions O
. O

The O
ACM O
Multimedia O
conference O
will O
be O
held O
virtually O
in O
China O
from O
October O
20 O
- O
24 O
, O
2021 O
. O

The O
authors O
of O
the O
study O
are O
Zheng O
Zhang O
, O
Lizi O
Liao O
, O
Minlie O
Huang O
, O
Xiaoyan O
Zhu O
, O
and O
Tat O
- O
Seng O
Chua O
. O

A O
neural O
belief O
tracker O
that O
can O
adapt O
its O
attention O
to O
different O
modalities O
for O
dialogue O
systems O
. O

The O
World O
Wide O
Web O
Conference O
( O
WWW O
2019 O
) O
will O
take O
place O
in O
San O
Francisco O
, O
CA O
, O
USA O
from O
May O
13 O
- O
17 O
, O
2019 O
. O
Pages O
2401 O
- O
2412 O
. O

The O
course O
ACM.113 O
covers O
topics O
in O
computer O
science O
. O

The O
hyperparameters O
used O
for O
the O
MMD O
dataset O
are O
shown O
in O
Appendix O
A.1 O
. O

The O
tokens O
listed O
below O
are O
in O
addition O
to O
the O
standard O
set O
of O
lexical O
tokens O
. O


 O
The O
following O
tokens O
are O
in O
addition O
to O
the O
standard O
set O
of O
lexical O
tokens O
. O

The O
special O
tokens O
we O
used O
in O
our O
experiments O
are O
shown O
in O
Table O
7 O
. O

The O
total O
loss O
function O
LTotal O
comprises O
three O
parts O
: O
the O
loss O
LE O
for O
the O
UTS O
encoder O
, O
the O
loss O
LF O
for O
the O
FAIR O
layer O
, O
and O
the O
loss O
LD O
for O
the O
HTR O
decoder O
. O

0250 O
L O


 O
The O
total O
amount O
of O
liquid O
is O
.0250 O
liters O
. O

This O
sentence O
is O
not O
in O
proper O
English O
. O

The O
sentence O
is O
incomplete O
. O

DLD O
( O
13 O
) O
is O
equal O
to O
. O

She O
's O
not O
here O
right O
now O
. O

F B-HyperparameterName
and O
G O
are O
working O
together O
. O

D B-HyperparameterName
, 0
and 0
are O
initialized O
equally O
as O
0.33 B-HyperparameterValue
, 0
0.33 B-HyperparameterValue
, 0
and 0
0.33 B-HyperparameterValue
respectively O
. O

We O
tune O
the O
weights O
on O
the O
verification O
set O
to O
obtain O
a O
better O
weight O
setting O
of O
0.30 B-HyperparameterValue
, 0
0.35 B-HyperparameterValue
, 0
and 0
0.35 B-HyperparameterValue
. O

The O
UTS O
encoder O
loss O
LE O
consists O
of O
two O
parts O
: O
LMLM O
and O
LMPM O
. O
Therefore O
, O
LE O
= O
LMLM O
. O

The O
FAIR O
layer O
loss O
contains O
three O
parts O
: O
LITM O
, O
LWPA O
, O
and O
LIC O
. O

The O
LF O
is O
equal O
to O
the O
sum O
of O
LITM O
, O
LWPA O
, O
and O
LIC O
, O
and O
the O
HTR O
decoder O
loss O
is O
divided O
into O
two O
types O
: O
the O
textual O
decoding O
loss O
LTXT O
for O
the O
text O
task O
and O
the O
image O
recommend O
loss O
LIMG O
for O
the O
image O
task O
. O
This O
is O
consistent O
with O
previous O
work O
. O

LD O
equals O
LTXT O
plus O
LIMG O
. O

The O
MMD B-DatasetName
dataset O
's O
detailed O
statistics O
are O
presented O
in O
Table O
8 O
. O

In O
order O
to O
improve O
our O
understanding O
of O
the O
model O
's O
limitations O
, O
we O
analyze O
the O
errors O
made O
by O
UniTranSeR. B-MethodName

We O
select O
100 O
responses O
generated O
by O
Uni- B-MethodName
TranSeR I-MethodName
at O
random O
that O
achieve O
low O
human O
evaluation O
scores O
in O
the O
test O
set O
of O
MMD B-DatasetName
. O

We O
report O
several O
reasons O
for O
the O
low O
scores O
, O
which O
can O
be O
classified O
into O
four O
categories O
. O

The O
KB O
information O
in O
the O
generated O
responses O
is O
incorrect O
38 O
% O
of O
the O
time O
, O
especially O
when O
the O
corresponding O
equipped O
knowledge O
base O
is O
large O
and O
complex O
. O

About O
24 O
% O
of O
the O
responses O
have O
incorrect O
sentence O
structure O
, O
with O
serious O
grammatical O
and O
semantic O
errors O
. O

The O
model O
does O
not O
respond O
correctly O
21 O
% O
of O
the O
time O
when O
there O
are O
multiple O
intentions O
contained O
in O
users O
' O
utterances O
. O

Since O
different O
products O
have O
similar O
attributes O
, O
the O
model O
incorrectly O
selects O
product O
images O
. O
