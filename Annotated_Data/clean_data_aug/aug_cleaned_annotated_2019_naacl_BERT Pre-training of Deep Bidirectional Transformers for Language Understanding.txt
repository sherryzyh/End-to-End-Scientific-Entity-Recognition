BERT B-MethodName
: O
Pre B-MethodName
- I-MethodName
training I-MethodName
of I-MethodName
Deep I-MethodName
Bidirectional I-MethodName
Transformers I-MethodName
for O
Language B-TaskName
Understanding I-TaskName


 O
Jacob O
Devlin O
, O
Ming O
- O
Wei O
Chang O
, O
Kenton O
Lee O
, O
and O
Kristina O
Toutanova O
of O
Google O
AI O
Language O
are O
the O
recipients O
of O
the O
Language B-TaskName
Understanding I-TaskName
award O
. O

The O
sentence O
is O
introducing O
a O
new O
language O
representation O
model O
called O
BERT B-MethodName
. O

Unlike O
most O
recent O
language O
representation O
models O
, O
BERT B-MethodName
is O
designed O
to O
pre O
- O
train O
deep O
bidirectional O
representations O
from O
unlabeled O
text O
by O
jointly O
conditioning O
on O
both O
left O
and O
right O
context O
in O
all O
layers O
. O

The O
pre O
- O
trained O
BERT B-MethodName
model O
can O
be O
fine O
- O
tuned O
with O
just O
one O
additional O
output O
layer O
to O
create O
state O
- O
of O
- O
the O
- O
art O
models O
for O
a O
wide O
range O
of O
tasks O
, O
such O
as O
question B-TaskName
answering I-TaskName
and O
language B-TaskName
inference I-TaskName
, O
without O
substantial O
task O
- O
specific O
architecture O
modifications O
. O

The O
BERT B-MethodName
model O
is O
simple O
to O
understand O
and O
has O
been O
shown O
to O
be O
effective O
through O
research O
. O

It O
outperforms O
current O
state O
- O
of O
- O
the O
- O
art O
results O
on O
eleven O
natural O
language O
processing O
tasks O
, O
including O
pushing O
the O
GLUE B-MetricName
score I-MetricName
to O
80.5% B-MetricValue
( O
7.7% B-MetricValue
point O
absolute O
improvement O
) O
, O
MultiNLI B-MetricName
accuracy I-MetricName
to O
86.7% B-MetricValue
( O
4.6% B-MetricValue
absolute O
improvement O
) O
, O
SQuAD B-DatasetName
v1.1 I-DatasetName
question B-TaskName
answering I-TaskName
Test O
F1 B-MetricName
to O
93.2 B-MetricValue
( O
1.5 B-MetricValue
point O
absolute O
im- O
provement O
) O
and O
SQuAD B-DatasetName
v2.0 I-DatasetName
Test O
F1 B-MetricName
to O
83.1 B-MetricValue
( O
5.1 B-MetricValue
point O
absolute O
improvement O
) O
. O

1 O
Introduction O
Language B-MethodName
model I-MethodName
pre I-MethodName
- I-MethodName
training I-MethodName
has O
been O
shown O
to O
improve O
many O
natural O
language O
processing O
tasks O
( O
Dai O
and O
Le O
, O
2015 O
; O
Peters O
et O
al O
. O
, O
2018a O
; O
Radford O
et O
al O
. O
, O
2018 O
; O
Howard O
and O
Ruder O
, O
2018 O
) O
. O

These O
tasks O
include O
sentence O
- O
level O
tasks O
such O
as O
natural B-TaskName
language I-TaskName
inference I-TaskName
and O
paraphrasing B-TaskName
, O
which O
aim O
to O
predict O
relationships O
between O
sentences O
by O
analyzing O
them O
holistically O
, O
as O
well O
as O
token O
- O
level O
tasks O
such O
as O
named B-TaskName
entity I-TaskName
recognition I-TaskName
and O
question B-TaskName
answering I-TaskName
, O
where O
models O
are O
required O
to O
produce O
fine O
- O
grained O
output O
at O
the O
token O
level O
. O

The O
feature O
- O
based O
approach O
, O
such O
as O
ELMo B-MethodName
( O
Peters O
et O
al O
. O
, O
2018a O
) O
, O
uses O
task O
- O
specific O
architectures O
that O
include O
the O
pre O
- O
trained O
representations O
as O
additional O
features O
. O

The O
fine O
- O
tuning O
approach O
, O
such O
as O
the O
Generative B-MethodName
Pre I-MethodName
- I-MethodName
trained I-MethodName
Transformer I-MethodName
( O
OpenAI B-MethodName
GPT I-MethodName
) O
( O
Radford O
et O
al O
. O
, O
2018 O
) O
, O
introduces O
minimal O
task O
- O
specific O
parameters O
, O
and O
is O
trained O
on O
the O
downstream O
tasks O
by O
simply O
fine O
- O
tuning O
all O
pre O
- O
trained O
parameters O
. O

The O
two O
approaches O
have O
the O
same O
goal O
during O
the O
initial O
training O
phase O
, O
where O
they O
use O
unidirectional B-MethodName
language I-MethodName
models I-MethodName
to O
learn O
general O
language O
representations O
. O

al O
. O
, O
2017 O
) O


 O
For O
example O
, O
in O
OpenAI B-MethodName
GPT I-MethodName
, O
the O
authors O
use O
a O
left O
- O
to O
- O
right O
architecture O
, O
where O
every O
token O
can O
only O
attend O
to O
previous O
tokens O
in O
the O
self O
- O
attention O
layers O
of O
the O
Transformer O
( O
Vaswani O
et O
al O
. O
, O
2017 O
) O
. O

Such O
restrictions O
are O
not O
ideal O
for O
sentence O
- O
level O
tasks O
, O
and O
could O
be O
very O
harmful O
when O
using O
Fine O
- O
tuning O
based O
approaches O
for O
token O
- O
level O
tasks O
such O
as O
question B-TaskName
answering I-TaskName
, O
where O
it O
is O
crucial O
to O
incorporate O
context O
from O
both O
directions O
. O

We O
improve O
the O
fine O
- O
tuning O
based O
approaches O
by O
proposing O
Bidirectional B-MethodName
Encoder I-MethodName
Representations I-MethodName
from I-MethodName
Transformers I-MethodName
in O
this O
paper O
. O

The O
masked B-MethodName
lan- I-MethodName
guage I-MethodName
model I-MethodName
objective O
helps O
to O
reduce O
the O
one O
- O
way O
directionality O
constraint O
by O
using O
an O
approach O
inspired O
by O
the O
Cloze O
task O
. O

The O
sentence O
is O
saying O
that O
the O
masked B-MethodName
language I-MethodName
model I-MethodName
randomly O
masks O
some O
of O
the O
input O
tokens O
, O
and O
the O
objective O
is O
to O
predict O
the O
original O
vocabulary O
i O
d O
of O
the O
masked O
word O
based O
only O
on O
the O
context O
. O

The O
MLM B-MethodName
objective O
is O
unique O
in O
that O
it O
allows O
the O
representation O
to O
fuse O
the O
left O
and O
right O
context O
, O
which O
enables O
the O
pre O
- O
training O
of O
a O
deep O
bidirectional O
Transformer O
. O

In O
addition O
to O
the O
masked B-MethodName
language I-MethodName
model I-MethodName
, O
we O
also O
use O
a O
" O
next B-TaskName
sentence I-TaskName
prediction I-TaskName
" O
task O
that O
jointly O
pre O
- O
trains O
representations O
for O
text O
pairs O
. O

BERT B-MethodName
uses O
masked B-MethodName
language I-MethodName
models I-MethodName
to O
enable O
pre O
- O
trained O
deep O
bidirectional O
representations O
, O
which O
uses O
unidirectional O
language O
models O
for O
pre O
- O
training O
. O

0 O
is O
the O
first O
model O
based O
on O
fine O
- O
tuning O
that O
achieves O
state O
- O
of O
- O
the O
- O
art O
performance O
on O
many O
sentence O
- O
level O
and O
token O
- O
level O
tasks O
, O
outperforming O
task O
- O
specific O
architectures O
. O

BERT B-MethodName
improves O
the O
state O
of O
the O
art O
for O
eleven O
NLP O
tasks O
. O

ELMo B-MethodName
is O
a O
successor O
to O
Peters O
et O
al O
. O
, O
2017 O
, O
2018a O
, O
which O
generalized O
traditional O
word O
embedding O
research O
along O
a O
different O
dimension O
. O

When O
integrating O
contextual O
word O
embeddings O
with O
existing O
task O
- O
specific O
architectures O
, O
Peters O
et O
al O
. O
( O
2018a O
) O
found O
that O
this O
improved O
the O
performance O
of O
several O
major O
NLP O
benchmarks O
, O
including O
Rajpurkar O
et O
al O
. O
( O
2016 O
) O
, O
Socher O
et O
al O
. O
( O
2013 O
) O
, O
and O
Tjong O
Kim O
Sang O
and O
De O
Meulder O
( O
2003 O
) O
. O

Their O
model O
is O
similar O
to O
ELMo B-MethodName
in O
that O
it O
is O
feature O
- O
based O
, O
not O
deeply O
bidirectional O
. O

The O
OpenAI B-MethodName
GPT I-MethodName
model O
( O
Radford O
et O
al O
. O
, O
2018 O
) O
achieved O
state O
- O
of O
- O
the O
- O
art O
results O
on O
many O
sentence- O
level O
tasks O
from O
the O
GLUE O
benchmark O
( O
Wang O
et O
al O
. O
, O
2018a O
) O
, O
at O
least O
partly O
due O
to O
its O
advantage O
. O

In O
this O
section O
, O
we O
will O
introduce O
BERT B-MethodName
and O
go O
over O
its O
implementation O
in O
detail O
. O

The O
BERT B-MethodName
model O
is O
first O
initialized O
with O
the O
pre O
- O
trained O
parameters O
, O
and O
then O
all O
of O
the O
parameters O
are O
fine O
- O
tuned O
using O
labeled O
data O
from O
the O
downstream O
tasks O
. O

BERT B-MethodName
's O
unified O
architecture O
is O
a O
key O
distinguishing O
feature O
across O
different O
tasks O
. O

Model O
Architecture O
BERT B-MethodName
's O
model O
architecture O
is O
based O
on O
the O
original O
implementation O
described O
in O
Vaswani O
. O

( O
2017 O
) O
for O
further O
details O
. O


 O
Our O
implementation O
of O
Transformers B-MethodName
is O
almost O
identical O
to O
the O
original O
, O
so O
we O
will O
not O
provide O
a O
detailed O
description O
of O
the O
model O
architecture O
here O
. O
For O
more O
information O
, O
please O
see O
Vaswani O
et O
al O
. O
( O
2017 O
) O
. O

In O
this O
work O
, O
we O
denote O
the O
set O
of O
all O
finite O
strings O
( O
i.e. O
, O
the O
set O
of O
all O
strings O
with O
at O
least O
one O
character O
) O
as O
Transformer B-HyperparameterName
blocks I-HyperparameterName
, O
the O
set O
of O
all O
strings O
with O
at O
least O
two O
characters O
as O
L B-HyperparameterName
, O
and O
the O
set O
of O
all O
strings O
with O
at O
least O
three O
characters O
as O
hidden B-HyperparameterName
size I-HyperparameterName
. O

The O
two O
model O
sizes O
we O
mainly O
report O
results O
for O
are O
BERT B-MethodName
BASE I-MethodName
( O
with O
L B-HyperparameterName
= O
12 B-HyperparameterValue
, O
H B-HyperparameterName
= O
768 B-HyperparameterValue
, O
A B-HyperparameterName
= O
12 B-HyperparameterValue
, O
and O
a O
total O
of O
110 O
million O
parameters O
) O
and O
BERT B-MethodName
LARGE I-MethodName
( O
with O
L B-HyperparameterName
= O
24 B-HyperparameterValue
, O
H B-HyperparameterName
= O
1024 B-HyperparameterValue
, O
A B-HyperparameterName
= O
16 B-HyperparameterValue
, O
and O
a O
total O
of O
340 O
million O
parameters O
) O
. O

BERT B-MethodName
BASE I-MethodName
was O
chosen O
to O
have O
the O
same O
model O
size O
as O
OpenAI B-MethodName
GPT I-MethodName
so O
that O
they O
could O
be O
compared O
. O

The O
BERT B-MethodName
Transformer I-MethodName
uses O
bidirectional O
self O
- O
attention O
, O
while O
the O
GPT B-MethodName
Trans- I-MethodName
former I-MethodName
uses O
constrained O
self O
- O
attention O
where O
every O
token O
can O
only O
attend O
to O
context O
to O
its O
left O
. O

To O
make O
BERT B-MethodName
handle O
a O
variety O
of O
down O
- O
stream O
tasks O
, O
our O
input O
representation O
is O
able O
to O
unambiguously O
represent O
both O
a O
single O
sentence O
and O
a O
pair O
of O
sentences O
( O
e.g. O
, O
Question O
, O
Answer O
) O
in O
one O
token O
sequence O
. O

The O
" O
sequence O
" O
refers O
to O
the O
input O
token O
sequence O
to O
BERT B-MethodName
, O
which O
may O
be O
a O
single O
sentence O
or O
two O
sentences O
packed O
together O
. O

We O
use O
embeddings O
from O
Wu O
et O
al O
. O
( O
2016 O
) O
with O
a O
vocabulary O
of O
30,000 O
tokens O
. O

( O
2018 O
) O
, O
we O
pre O
- O
train O
our O
models O
on O
the O
BERT B-MethodName
corpus O
instead O
of O
the O
ImageNet O
dataset O
. O


 O
We O
train O
our O
models O
on O
the O
BERT B-MethodName
corpus O
instead O
of O
the O
ImageNet O
dataset O
, O
unlike O
Peters O
et O
al O
. O
( O
2018a O
) O
and O
Radford O
et O
al O
. O
( O
2018 O
) O
. O

We O
do O
n't O
use O
traditional O
left O
- O
to O
- O
right O
or O
right O
- O
to O
- O
left O
language O
models O
to O
pre O
- O
train O
BERT B-MethodName
. O

Instead O
of O
pre O
- O
training O
BERT B-MethodName
using O
two O
unsupervised O
tasks O
, O
we O
describe O
them O
in O
this O
section O
. O

In O
all O
of O
our O
experiments O
, O
we O
randomly O
mask O
out O
15% B-HyperparameterValue
of O
all O
WordPiece B-DatasetName
tokens O
in O
each O
sequence O
. O

The O
training O
data O
generator O
predicts O
randomly O
chosen O
15% B-HyperparameterValue
token O
positions O
. O

If O
the O
i O
- O
th O
token O
is O
chosen O
, O
we O
replace O
it O
with O
the O
[ O
MASK O
] O
token O
80% B-HyperparameterValue
of O
the O
time O
, O
a O
random O
token O
10% B-HyperparameterValue
of O
the O
time O
, O
or O
the O
unchanged O
i O
- O
th O
token O
10% B-HyperparameterValue
of O
the O
time O
. O

There O
are O
many O
important O
downstream O
tasks O
, O
such O
as O
answering O
and O
Natural B-TaskName
Language I-TaskName
Infer- I-TaskName
ence I-TaskName
, O
that O
are O
based O
on O
understanding O
the O
relationship O
between O
two O
sentences O
. O
This O
relationship O
is O
not O
directly O
captured O
by O
language O
modeling O
. O

When O
choosing O
sentences O
A O
and O
B O
for O
each O
pre O
- O
training O
example O
, O
50% B-HyperparameterValue
of O
the O
time O
B O
is O
the O
actual O
next O
sentence O
that O
follows O
A O
( O
labeled O
as O
IsNext O
) O
, O
and O
50% B-HyperparameterValue
of O
the O
time O
it O
is O
a O
random O
sentence O
from O
the O
corpus O
( O
labeled O
as O
NotNext O
) O
. O

As O
seen O
in O
Figure O
1 O
, O
pre O
- O
training O
for O
next O
sentence O
prediction O
( O
NSP O
) O
is O
very O
beneficial O
for O
both O
QA B-TaskName
and O
NLI B-TaskName
. O

However O
, O
in O
previous O
work O
, O
only O
sentence O
embeddings O
were O
transferred O
to O
downstream O
tasks O
. O
In O
this O
work O
, O
we O
transfer O
all O
parameters O
to O
initialize O
the O
end O
- O
task O
model O
parameters O
. O

We O
use O
the O
BooksCorpus B-DatasetName
( O
800 O
M O
words O
) O
as O
our O
pre O
- O
training O
corpus O
. O

Zhu O
et O
al O
. O
( O
2015 O
) O
and O
English B-DatasetName
Wikipedia I-DatasetName
( O
2,500 O
M O
words O
) O
. O

We O
only O
extract O
text O
passages O
from O
Wikipedia B-DatasetName
and O
ignore O
lists O
, O
tables O
, O
and O
headers O
. O

It O
is O
more O
effective O
to O
use O
a O
corpus O
of O
whole O
documents O
rather O
than O
a O
shuffled O
corpus O
of O
sentences O
, O
like O
the O
Billion B-DatasetName
Word I-DatasetName
Benchmark I-DatasetName
, O
to O
extract O
long O
sequences O
. O

3.2 O
Fine O
- O
tuning O
is O
straightforward O
since O
the O
self- O
attention O
mechanism O
in O
the O
Transformer B-MethodName
al- O
lows O
BERT B-MethodName
to O
model O
many O
downstream O
tasks O
— O
whether O
they O
involve O
single O
text O
or O
text O
pairs O
— O
by O
swapping O
out O
the O
appropriate O
inputs O
and O
outputs O
. O


 O
Fine O
- O
tuning O
is O
easy O
to O
do O
because O
the O
self- O
attention O
mechanism O
in O
the O
Transformer B-MethodName
al- O
lows O
BERT B-MethodName
to O
model O
many O
downstream O
tasks O
— O
whether O
they O
involve O
single O
text O
or O
text O
pairs O
— O
by O
swapping O
out O
the O
appropriate O
inputs O
and O
outputs O
. O

BERT B-MethodName
uses O
the O
self O
- O
attention O
mechanism O
to O
unify O
the O
encoding O
of O
a O
concatenated O
text O
pair O
, O
which O
effectively O
includes O
bidirectional O
cross O
attention O
between O
the O
two O
sentences O
. O

At O
the O
input O
, O
sentence O
A O
and O
sentence O
B O
from O
pre O
- O
training O
are O
analogous O
to O
sentence O
pairs O
in O
paraphras- B-TaskName
ing I-TaskName
, O
hypothesis O
- O
premise O
pairs O
in O
entailment B-TaskName
, O
question O
- O
passage O
pairs O
in O
question B-TaskName
answering I-TaskName
, O
and O
a O
degenerate O
text- O
? O
. O

Pairs O
can O
be O
found O
in O
text B-TaskName
classiﬁcation I-TaskName
or O
sequence B-TaskName
tagging I-TaskName
. O

At O
the O
output O
, O
the O
token O
representations O
are O
fed O
into O
an O
output O
layer O
for O
token O
- O
level O
tasks O
, O
such O
as O
sequence B-TaskName
tagging I-TaskName
or O
question B-TaskName
answering I-TaskName
. O
The O
[ O
CLS O
] O
representation O
is O
fed O
into O
an O
output O
layer O
for O
classification O
, O
such O
as O
en- B-TaskName
tailment I-TaskName
or O
sentiment B-TaskName
analysis I-TaskName
. O

We O
present O
the O
results O
of O
BERT B-MethodName
fine O
- O
tuning O
on O
11 O
NLP O
tasks O
in O
this O
section O
. O

The O
General B-DatasetName
Language I-DatasetName
Understanding I-DatasetName
Evaluation I-DatasetName
( O
GLUE B-DatasetName
) O
benchmark O
by O
Wang O
et O
al O
. O
( O
2018a O
) O
is O
a O
collection O
of O
diverse O
natural O
language O
understanding O
tasks O
. O

Appendix O
B.1 O
contains O
detailed O
descriptions O
of O
the O
GLUE B-DatasetName
datasets O
. O

To O
fine O
- O
tune O
on O
the O
GLUE B-DatasetName
dataset O
, O
we O
represent O
the O
input O
sequence O
( O
for O
a O
single O
sentence O
or O
a O
sentence O
pair O
) O
as O
described O
in O
Section O
3 O
, O
and O
use O
the O
final O
hidden O
vector O
C2RH O
corresponding O
to O
the O
first O
input O
token O
( O
[ O
CLS O
] O
) O
as O
the O
aggregate O
representation O
. O

The O
only O
new O
parameters O
introduced O
during O
fine O
- O
tuning O
are O
classification O
layer B-HyperparameterName
weights I-HyperparameterName
W B-HyperparameterName
RKH O
, O
where O
K B-HyperparameterName
is O
the O
number B-HyperparameterName
of I-HyperparameterName
labels I-HyperparameterName
. O

We O
use O
a O
neural O
network O
architecture O
of O
[ O
type O
] O
and O
fine O
- O
tune O
for O
[ O
purpose O
] O
over O
the O
data O
for O
all O
[ O
situations O
/ O
tasks O
] O
. O

We O
selected O
the O
best O
learning B-HyperparameterName
rate I-HyperparameterName
for O
each O
task O
from O
among O
5e-5 B-HyperparameterValue
, O
4e-5 B-HyperparameterValue
, O
3e-5 B-HyperparameterValue
, O
and O
2e-5 B-HyperparameterValue
on O
the O
Dev O
set O
. O

We O
found O
that O
fine O
- O
tuning O
was O
sometimes O
unstable O
on O
small O
datasets O
for O
BERT B-MethodName
LARGE I-MethodName
, O
so O
we O
ran O
several O
random O
restarts O
and O
selected O
the O
best O
model O
on O
the O
Dev O
set O
. O

Both O
BERT B-MethodName
BASE I-MethodName
and O
BERT B-MethodName
LARGE I-MethodName
obtain O
substantially O
higher O
average O
accuracy B-MetricName
scores O
than O
all O
other O
systems O
on O
all O
tasks O
, O
representing O
4.5% B-MetricValue
and O
7.0% B-MetricValue
respective O
average O
im- O
provements O
over O
the O
prior O
state O
of O
the O
art O
. O

The O
only O
difference O
between O
BERT B-MethodName
BASE I-MethodName
and O
OpenAI B-MethodName
GPT I-MethodName
is O
the O
attention O
masking O
. O

For O
the O
most O
widely O
reported O
task O
, O
MNLI B-TaskName
, O
BERT B-MethodName
obtains O
an O
absolute O
improvement O
. O

As O
of O
the O
date O
of O
writing O
, O
on O
the O
official O
GLUE B-DatasetName
leaderboard O
, O
BERT B-MethodName
LARGE I-MethodName
has O
a O
score O
of O
80.5 B-MetricValue
, O
compared O
to O
OpenAI B-MethodName
GPT I-MethodName
, O
which O
has O
a O
score O
of O
72.8 B-MetricValue
. O

We O
find O
that O
BERT B-MethodName
LARGE I-MethodName
outperforms O
BERT B-MethodName
BASE I-MethodName
significantly O
across O
all O
tasks O
, O
especially O
those O
that O
have O
very O
little O
training O
data O
. O

The O
Stanford B-DatasetName
Question I-DatasetName
Answering I-DatasetName
Dataset I-DatasetName
( O
SQuAD B-DatasetName
v1.1 I-DatasetName
) O
is O
a O
collection O
of O
100k O
crowd O
- O
sourced O
question O
/ O
answer O
pairs O
. O
This O
was O
first O
published O
in O
2016 O
by O
Rajpurkar O
et O
al O
. O

In O
Figure O
1 O
, O
we O
represent O
the O
input O
question O
and O
passage O
as O
a O
single O
packed O
sequence O
, O
with O
the O
question O
using O
the O
A O
embedding O
and O
the O
passage O
using O
the O
B O
embedding O
, O
for O
the O
question B-TaskName
answer- I-TaskName
ing I-TaskName
task O
. O

We O
use O
learning B-HyperparameterName
rate I-HyperparameterName
to O
fine O
- O
tune O
for O
3 B-HyperparameterValue
epochs B-HyperparameterName
with O
a O
5e-5 B-HyperparameterValue
and O
a O
batch B-HyperparameterName
size I-HyperparameterName
. O

The O
top O
performers O
on O
the O
SQuAD B-DatasetName
leaderboard O
have O
not O
provided O
up O
- O
to O
- O
date O
descriptions O
of O
their O
systems O
, O
and O
are O
allowed O
to O
use O
any O
public O
data O
when O
training O
their O
systems O
. O

We O
use O
modest O
data O
augmentation O
in O
our O
system O
by O
first O
fine O
- O
tuning O
on O
TriviaQA B-DatasetName
before O
fine O
- O
tuning O
on O
SQuAD B-DatasetName
. O

Our O
best O
performing O
system O
is O
a O
single O
system O
that O
outperforms O
the O
top O
leaderboard O
system O
in O
ensembling O
and O
+1.3 B-MetricValue
F1 B-MetricName
. O

Our O
BERT B-MethodName
model O
outperforms O
the O
top O
ensemble O
system O
in O
terms O
of O
F1 B-MetricName
score O
. O

Without O
any O
extra O
data O
to O
fine O
- O
tune O
our O
model O
, O
we O
only O
lose O
a O
small O
amount O
of O
performance O
, O
still O
outperforming O
all O
existing O
systems O
by O
a O
wide O
margin O
. O

The O
task O
allows O
for O
the O
possibility O
that O
no O
short O
answer O
exists O
in O
the O
provided O
paragraph O
, O
making O
the O
problem O
more O
realistic O
. O

We O
use O
a O
simple O
approach O
to O
extend O
the O
SQuAD B-DatasetName
v1.1 I-DatasetName
BERT B-MethodName
model O
so O
that O
it O
can O
be O
used O
for O
this O
task O
. O

The O
sentence O
is O
saying O
that O
the O
dev O
set O
is O
being O
used O
to O
select O
a O
model O
that O
will O
maximize O
the O
F1 B-MetricName
score O
. O

We O
did O
not O
use O
the O
TriviaQA B-DatasetName
data O
for O
this O
model O
. O

We O
optimized O
for O
2 B-HyperparameterValue
epochs B-HyperparameterName
with O
a O
learning B-HyperparameterName
rate I-HyperparameterName
of O
5e-5 B-HyperparameterValue
and O
a O
batch B-HyperparameterName
size I-HyperparameterName
of O
48 B-HyperparameterValue
. O

The O
table O
below O
shows O
the O
results O
of O
the O
top O
published O
work O
, O
excluding O
systems O
that O
use O
BERT B-MethodName
as O
one O
of O
their O
components O
. O

We O
observe O
an O
improvement O
over O
the O
previous O
best O
system O
. O

The O
Situations B-DatasetName
With I-DatasetName
Adversarial I-DatasetName
Generations I-DatasetName
( O
SWAG B-DatasetName
) O
dataset O
contains O
113k O
sentence O
- O
pair O
completion O
examples O
that O
evaluate O
grounded O
common O
- O
sense O
inference O
( O
Zellers O
et O
al O
. O
, O
2018 O
) O
. O

We O
construct O
four O
input O
sequences O
when O
fine O
- O
tuning O
on O
the O
SWAG B-DatasetName
dataset O
. O
Each O
sequence O
contains O
the O
concatenation O
of O
the O
given O
sentence O
( O
sentence O
A O
) O
and O
a O
possible O
continuation O
( O
sentence O
B O
) O
. O

We O
adjust O
the O
model O
for O
3 B-HyperparameterValue
epochs B-HyperparameterName
with O
a O
learning B-HyperparameterName
rate I-HyperparameterName
of O
2e-5 B-HyperparameterValue
and O
a O
batch B-HyperparameterName
size B-HyperparameterValue
of O
16 B-HyperparameterValue
. O

BERT B-MethodName
LARGE I-MethodName
outperforms O
the O
authors O
' O
baseline O
ESIM+ELMo B-MethodName
system O
by O
+27.1% B-MetricValue
and O
is O
OpenAI B-MethodName
GPT I-MethodName
by O
8.3% B-MetricValue
. O

We O
perform O
ablation O
experiments O
on O
different O
aspects O
of O
BERT B-MethodName
to O
better O
understand O
how O
important O
each O
one O
is O
. O

We O
show O
that O
the O
deep O
bidirectionality O
of O
BERT B-MethodName
is O
important O
by O
evaluating O
two O
pre O
- O
training O
objectives O
using O
the O
same O
pre O
- O
training O
data O
, O
fine O
- O
tuning O
scheme O
, O
and O
hyperparameters O
as O
BERT B-MethodName
BASE I-MethodName
. O

This O
is O
comparable O
to O
OpenAI B-MethodName
GPT I-MethodName
, O
but O
using O
our O
larger O
training O
dataset O
, O
our O
input O
representation O
, O
and O
our O
fine O
- O
tuning O
scheme O
. O

Table O
5 O
demonstrates O
that O
removing O
NSP O
has O
a O
negative O
impact O
on O
performance O
for O
QNLI B-DatasetName
, O
MNLI B-DatasetName
, O
and O
SQuAD B-DatasetName
1.1 I-DatasetName
. O

The O
LTR O
model O
does O
not O
perform O
as O
well O
as O
the O
MLM O
model O
on O
any O
task O
, O
with O
significant O
decreases O
on O
MRPC B-DatasetName
and O
SQuAD B-DatasetName
. O

Since O
the O
token O
- O
level O
hidden O
states O
have O
no O
right O
- O
side O
context O
, O
it O
is O
clear O
that O
a O
LTR O
model O
will O
not O
perform O
well O
at O
token O
predictions O
for O
SQuAD B-DatasetName
. O

This O
significantly O
improves O
results O
on O
SQuAD B-DatasetName
, O
but O
the O
results O
are O
still O
far O
worse O
than O
those O
of O
the O
pre O
- O
trained O
bidirectional O
models O
. O

The O
BiLSTM O
is O
n't O
as O
good O
as O
other O
methods O
on O
the O
GLUE B-DatasetName
tasks O
. O

We O
recognize O
that O
it O
would O
also O
be O
possible O
to O
train O
separate O
LTR O
and O
RTL O
models O
and O
represent O
each O
token O
as O
the O
concatenation O
of O
the O
two O
models O
, O
as O
ELMo B-MethodName
does O
. O

Although O
this O
is O
twice O
as O
expensive O
as O
a O
single O
bidirectional O
model O
, O
and O
it O
is O
less O
powerful O
than O
a O
deep O
bidirectional O
model O
, O
it O
is O
still O
useful O
for O
tasks O
like O
QA B-TaskName
. O

We O
trained O
a O
number O
of O
models O
with O
different O
number B-HyperparameterName
of I-HyperparameterName
layers I-HyperparameterName
, O
hidden B-HyperparameterName
units I-HyperparameterName
, O
and O
attention B-HyperparameterName
heads I-HyperparameterName
, O
while O
using O
the O
same O
hyperparameters O
and O
training O
procedure O
as O
before O
. O

The O
results O
for O
the O
selected O
GLUE B-DatasetName
tasks O
are O
shown O
in O
Table O
6 O
. O

This O
table O
reports O
the O
average B-MetricName
Dev I-MetricName
Set I-MetricName
accuracy I-MetricName
from O
5 O
random O
restarts O
of O
fine O
- O
tuning O
. O

The O
larger O
models O
lead O
to O
a O
significant O
improvement O
in O
accuracy O
across O
all O
four O
datasets O
, O
even O
for O
MRPC B-DatasetName
which O
only O
has O
3,600 O
labeled O
training O
examples O
, O
and O
is O
substantially O
different O
from O
the O
pre O
- O
training O
tasks O
. O

( O
2017 O
) O
is O
( O
L B-HyperparameterName
= O
6 B-HyperparameterValue
, O
H B-HyperparameterName
= O
1024 B-HyperparameterValue
, O
A B-HyperparameterName
= O
16 B-HyperparameterValue
) O
with O
100M B-HyperparameterValue
parameters O
for O
the O
encoder O
, O
and O
the O
largest O
Transformer O
we O
have O
found O
in O
the O
literature O
is O
( O
L B-HyperparameterName
= O
64 B-HyperparameterValue
, O
H B-HyperparameterName
= O
512 B-HyperparameterValue
, O
A B-HyperparameterName
= O
2 B-HyperparameterValue
) O
with O
235M B-HyperparameterValue
parameters O
( O
Al O
- O
Rfou O
et O
al O
. O
, O
2018 O
) O
. O

The O
sentence O
is O
saying O
that O
BERT B-MethodName
BASE I-MethodName
contains O
110M B-HyperparameterValue
parameters O
and O
BERT B-MethodName
LARGE I-MethodName
contains O
340M B-HyperparameterValue
parameters O
. O

The O
results O
presented O
so O
far O
have O
all O
used O
the O
fine O
- O
tuning O
approach O
, O
where O
a O
simple O
classification O
layer O
is O
added O
to O
the O
pre O
- O
trained O
model O
and O
all O
parameters O
are O
jointly O
fine O
- O
tuned O
on O
a O
downstream O
task O
. O

We O
compare O
the O
two O
approaches O
by O
applying O
BERT B-MethodName
to O
the O
CoNLL-2003 B-TaskName
Named I-TaskName
Entity I-TaskName
Recognition I-TaskName
( O
NER B-TaskName
) O
task O
in O
this O
section O
( O
Tjong O
Kim O
Sang O
and O
De O
Meulder O
, O
2003 O
) O
. O

We O
use O
a O
case O
- O
preserving O
model O
in O
the O
input O
to O
BERT B-MethodName
, O
and O
we O
include O
the O
maximal O
document O
context O
provided O
by O
the O
data O
. O

We O
formulate O
this O
as O
a O
tagging B-TaskName
task O
, O
following O
standard O
practice O
, O
but O
do O
not O
use O
a O
CRF O
layer O
in O
the O
output O
. O

We O
use O
the O
first O
sub O
- O
token O
's O
representation O
as O
the O
input O
for O
the O
token O
- O
level O
classifier O
over O
the O
NER B-TaskName
label O
set O
. O

We O
extract O
the O
activations O
from O
one O
or O
more O
layers O
without O
fine O
- O
tuning O
any O
parameters O
of O
BERT B-MethodName
in O
order O
to O
eliminate O
the O
need O
for O
the O
fine O
- O
tuning O
approach O
. O

These O
randomly O
initialized O
BiLSTMs O
take O
the O
context O
embeddings O
as O
input O
before O
the O
classification O
layer O
. O

BERT B-MethodName
LARGE I-MethodName
is O
just O
as O
good O
as O
the O
best O
methods O
out O
there O
. O

The O
best O
performing O
method O
combines O
the O
token O
representations O
from O
the O
top O
four O
hidden O
layers O
of O
the O
pre O
- O
trained O
Transformer O
, O
which O
is O
only O
slightly O
worse O
than O
fine O
- O
tuning O
the O
entire O
model O
. O

This O
sentence O
demonstrates O
that O
BERT B-MethodName
is O
just O
as O
effective O
for O
fine O
tuning O
approaches O
as O
it O
is O
for O
feature O
based O
approaches O
. O

More O
information O
about O
BERT B-MethodName
can O
be O
found O
in O
Appendix O
A. O

We O
provide O
more O
detailed O
studies O
for O
BERT B-MethodName
including O
: O


 O
-The O
effect O
of O
the O
number O
of O
training O
steps O


 O
-Ablation O
for O
different O
masking O
procedures O

Assuming O
the O
unlabeled O
sentence O
is O
" O
My O
dog O
is O
hairy O
, O
" O
and O
during O
the O
random O
masking O
procedure O
we O
chose O
the O
fourth O
token O
( O
which O
corresponds O
to O
" O
hairy O
" O
) O
, O
our O
masking O
procedure O
can O
be O
further O
illustrated O
by O
the O
following O
: O
ABCDEFG O
0 O
% O
of O
the O
time O
: O

my O
dog O
is O
asleep O
most O
of O
the O
time O

my O
dog O
is O
apple O
. O
1 O


 O
What O
does O
the O
following O
sentence O
mean O
? O
I O
have O
a O
lot O
in O
common O
with O
my O
dog O
• O
We O
have O
a O
lot O
of O
things O
in O
common O
. O
2 O

Additionally O
, O
this O
does O
not O
seem O
to O
harm O
the O
model O
's O
language O
understanding O
capability O
because O
random O
replacement O
only O
occurs O
for O
1.5% B-HyperparameterValue
of O
all O
tokens O
( O
i.e. O
, O
10 O
% O
of O
15 O
% O
) O
. O

50% B-HyperparameterValue
is O
the O
actual O
next O
sentence O
that O
follows O
A O
, O
and O
50% B-HyperparameterValue
is O
a O
random O
sentence O
. O

They O
are O
sampled O
such O
that O
the O
combined O
length O
of O
the O
sample O
is O
<512 B-HyperparameterValue
tokens O
. O

After O
the O
LM O
masking O
is O
applied O
, O
the O
WordPiece B-MethodName
tokenization O
is O
given O
a O
uni- B-HyperparameterName
form I-HyperparameterName
masking I-HyperparameterName
rate I-HyperparameterName
, O
with O
no O
special O
consideration O
given O
to O
partial O
word O
pieces O
. O

We O
train O
with O
batches O
of O
256 B-HyperparameterValue
sequences O
* O
512 B-HyperparameterValue
tokens O
, O
which O
is O
approximately O
128,000 O
tokens O
. O
This O
is O
done O
for O
1,000,000 B-HyperparameterValue
steps B-HyperparameterName
, O
which O
is O
approximately O
40 B-HyperparameterValue
epochs B-HyperparameterName
over O
the O
3.3 O
billion O
word O
corpus O
. O

We O
use O
Adam O
with O
learning B-HyperparameterName
rate I-HyperparameterName
of O
1e-4 B-HyperparameterValue
. O

1= O
0.9 B-HyperparameterValue
, O
. O


 O
This O
sentence O
is O
difficult O
to O
understand O
. O

2= O
0.999 B-HyperparameterValue
, O
L2 B-HyperparameterName
weight I-HyperparameterName
decay I-HyperparameterName
of O
0:01 B-HyperparameterValue
, O
learning O
rate O
warmup O
over O
the O
ﬁrst O
10,000 B-HyperparameterValue
steps B-HyperparameterName
, O
and O
linear O
decay O
of O
the O
learning O
rate O
. O

We O
use O
a O
combination O
of O
dropout B-HyperparameterName
prob- I-HyperparameterName
ability I-HyperparameterName
and O
0.1 B-HyperparameterValue
on O
all O
layers O
. O

We O
use O
a O
gelu O
activation O
( O
Hendrycks O
and O
Gimpel O
, O
2016 O
) O
rather O
than O
the O
standard O
relu O
, O
following O
OpenAI B-MethodName
GPT I-MethodName
. O

BERT B-MethodName
BASE I-MethodName
was O
trained O
on O
4 O
Cloud O
TPUs O
in O
a O
pod O
configuration O
( O
16 O
TPU O
chips O
total O
) O
, O
and O
BERT B-MethodName
LARGE I-MethodName
was O
trained O
on O
16 O
Cloud O
TPUs O
( O
64 O
TPU O
chips O
total O
) O
. O

To O
accelerate O
the O
pretraining O
process O
in O
our O
experiments O
, O
we O
pre O
- O
train O
the O
model O
using O
the O
sequence B-HyperparameterName
length I-HyperparameterName
of O
128 B-HyperparameterValue
for O
90% B-HyperparameterValue
of O
the O
steps B-HyperparameterName
. O

First O
, O
we O
train O
the O
sequence O
to O
learn O
the O
positional O
embeddings O
, O
and O
then O
train O
the O
rest O
of O
the O
sequence O
. O

The O
fine O
- O
tuning O
procedure O
mostly O
uses O
the O
same O
model O
hyperparameters O
as O
the O
pre O
- O
training O
, O
with O
the O
exception O
of O
the O
batch B-HyperparameterName
size I-HyperparameterName
, O
learning B-HyperparameterName
rate I-HyperparameterName
, O
and O
number B-HyperparameterName
of I-HyperparameterName
train- I-HyperparameterName
ing I-HyperparameterName
epochs I-HyperparameterName
. O

The O
dropout B-HyperparameterName
probability I-HyperparameterName
was O
always O
kept O
at O
0.1 B-HyperparameterValue
. O

The O
optimal O
hyperparameter O
values O
are O
task O
- O
specific O
, O
but O
we O
found O
the O
following O
range O
of O
possible O
values O
to O
work O
well O
across O
all O
tasks O
: O
Batch B-HyperparameterName
size I-HyperparameterName
: O
16 B-HyperparameterValue
, O
32 B-HyperparameterValue
. O

We O
observed O
that O
large O
data O
sets O
( O
e.g. O
, O
100k+ O
labeled O
training O
examples O
) O
were O
far O
less O
sensitive O
to O
hyperparameter O
choice O
than O
small O
data O
sets O
. O

We O
compare O
the O
ELMo B-MethodName
, O
OpenAI B-MethodName
GPT I-MethodName
, O
and O
BERT B-MethodName
representation O
learning O
models O
. O

There O
are O
three O
approaches O
mentioned O
: O
architecture O
differences O
, O
fine O
- O
tuning O
approaches O
, O
and O
feature O
- O
based O
approaches O
. O

The O
most O
comparable O
existing O
pre O
- O
training O
method O
to O
BERT B-MethodName
is O
OpenAI B-MethodName
GPT I-MethodName
, O
which O
is O
a O
left O
- O
to O
- O
right O
Transformer O
LM O
that O
is O
trained O
on O
a O
large O
text O
corpus O
. O

Many O
of O
the O
design O
decisions O
in O
BERT B-HyperparameterName
were O
intentionally O
made O
to O
make O
it O
similar O
to O
GPT B-MethodName
so O
that O
the O
two O
methods O
could O
be O
compared O
. O

The O
main O
point O
of O
this O
work O
is O
that O
the O
two O
- O
way O
training O
and O
the O
two O
pretraining O
tasks O
described O
in O
Section O
3.1 O
are O
responsible O
for O
most O
of O
the O
observed O
improvements O
, O
although O
we O
do O
acknowledge O
that O
there O
are O
other O
differences O
in O
how O
BERT B-MethodName
and O
GPT B-MethodName
were O
trained O
. O

GPT B-MethodName
is O
trained O
on O
800 O
million O
words O
from O
the O
BooksCorpus B-DatasetName
dataset O
, O
while O
BERT B-MethodName
is O
trained O
on O
800 O
million O
words O
from O
the O
BooksCor- B-DatasetName
pus I-DatasetName
dataset O
and O
2.5 O
billion O
words O
from O
the O
Wikipedia B-DatasetName
dataset O
. O

BERT B-MethodName
uses O
a O
sentence O
separator O
( O
[ O
SEP O
] O
) O
and O
classifier O
token O
( O
[ O
CLS O
] O
) O
which O
are O
only O
introduced O
at O
fine O
- O
tuning O
time O
; O
BERT B-MethodName
learns O
[ O
SEP O
] O
, O
[ O
CLS O
] O
and O
sentence O
A O
/ O
B O
embed- O
. O

GPT B-MethodName
was O
trained O
to O
identify O
1M B-HyperparameterValue
steps B-HyperparameterName
with O
a O
vocabulary O
of O
batch B-HyperparameterName
size I-HyperparameterName
words O
; O
BERT B-MethodName
was O
trained O
to O
identify O
1M B-HyperparameterValue
steps B-HyperparameterName
with O
a O
vocabulary O
of O
batch B-HyperparameterName
size I-HyperparameterName
words O
. O

GPT B-MethodName
used O
the O
same O
method O
of O
learning B-HyperparameterName
rate I-HyperparameterName
for O
all O
fine O
- O
tuning O
experiments O
; O
BERT B-HyperparameterName
chooses O
a O
task O
- O
specific O
fine O
- O
tuning O
learning B-HyperparameterName
rate I-HyperparameterName
which O
performs O
the O
best O
on O
the O
development O
set O
. O

The O
different O
ways O
that O
fine O
- O
tuning O
BERT B-MethodName
can O
be O
applied O
to O
different O
tasks O
is O
illustrated O
in O
Figure O
4 O
. O

The O
task O
is O
to O
form O
specific O
models O
by O
incorporating O
BERT B-MethodName
with O
one O
additional O
output O
layer O
, O
so O
that O
a O
minimal O
number O
of O
parameters O
need O
to O
be O
learned O
from O
scratch O
. O

The O
datasets O
described O
in O
Wang O
et O
al O
. O
are O
included O
in O
the O
GLUE B-DatasetName
benchmark O
. O

The O
MNLI O
Multi B-TaskName
- I-TaskName
Genre I-TaskName
Natural I-TaskName
Language I-TaskName
Inference I-TaskName
task O
is O
a O
large O
- O
scale O
, O
crowdsourced O
entailment O
classification O
task O
( O
Williams O
et O
al O
. O
, O
2018 O
) O
. O

The O
goal O
of O
the O
QQP O
Quora B-TaskName
Question I-TaskName
Pairs I-TaskName
binary O
classification O
task O
is O
to O
determine O
if O
two O
questions O
asked O
on O
Quora O
are O
semantically O
equivalent O
( O
Chen O
et O
al O
. O
, O
2018 O
) O
. O

The O
Question B-DatasetName
Natural I-DatasetName
Language I-DatasetName
Inference I-DatasetName
dataset O
is O
a O
version O
of O
the O
Stanford B-DatasetName
Question I-DatasetName
Answering I-DatasetName
Dataset O
( O
Rajpurkar O
et O
al O
. O
, O
2016 O
) O
which O
has O
been O
converted O
to O
a O
binary O
classification O
task O
( O
Wang O
et O
al O
. O
, O
2018a O
) O
. O

The O
Stanford B-TaskName
Sentiment I-TaskName
Treebank I-TaskName
is O
a O
binary O
single O
- O
sentence O
classification O
task O
consisting O
of O
sentences O
extracted O
from O
movie O
reviews O
with O
human O
annotations O
of O
their O
sentiment O
. O

The O
Corpus B-TaskName
of I-TaskName
Linguistic I-TaskName
Acceptability I-TaskName
is O
a O
binary O
single O
- O
sentence O
classification O
task O
where O
the O
goal O
is O
to O
predict O
whether O
an O
English O
sentence O
is O
linguistically O
" O
acceptable O
" O
or O
not O
( O
Warstadt O
et O
al O
. O
, O
2018 O
) O
. O

The O
Semantic B-DatasetName
Textual I-DatasetName
Similarity I-DatasetName
Bench- I-DatasetName
mark I-DatasetName
is O
a O
collection O
of O
sentence O
pairs O
that O
are O
taken O
from O
news O
headlines O
and O
other O
sources O
( O
Cer O
et O
al O
. O
, O
2017 O
) O
. O

The O
sentence O
pairs O
in O
MRPC O
Microsoft B-DatasetName
Research I-DatasetName
Paraphrase I-DatasetName
Corpus I-DatasetName
were O
automatically O
extracted O
from O
online O
news O
sources O
, O
and O
each O
pair O
has O
been O
annotated O
by O
a O
human O
to O
indicate O
whether O
the O
sentences O
in O
the O
pair O
are O
semantically O
equivalent O
( O
Dolan O
and O
Brockett O
, O
2005 O
) O
. O

Recognizing B-TaskName
Textual I-TaskName
Entailment I-TaskName
is O
a O
binary O
entailment O
task O
that O
is O
similar O
to O
MNLI B-TaskName
, O
but O
it O
has O
much O
less O
training O
data O
. O

2009).14 O
WNLI O
Winograd B-DatasetName
NLI I-DatasetName
is O
a O
small O
natural O
language O
inference O
dataset O
that O
was O
published O
by O
Levesque O
et O
al O
. O
in O
2011 O
. O

The O
GLUE B-DatasetName
webpage O
mentions O
that O
there O
might O
be O
some O
problems O
with O
the O
dataset O
's O
construction O
, O
and O
every O
AI O
system O
that O
's O
been O
submitted O
to O
GLUE B-DatasetName
has O
done O
worse O
than O
the O
65.1 O
baseline O
accuracy O
for O
predicting O
the O
majority O
class O
. O

We O
are O
excluding O
this O
set O
to O
be O
fair O
to O
OpenAI B-MethodName
GPT I-MethodName
. O

Our O
GLUE B-DatasetName
submission O
always O
predicted O
the O
majority O
class O
. O

Figure O
5 O
presents O
the O
results O
of O
MNLI B-TaskName
and O
Dev B-MetricName
accuracy I-MetricName
after O
fine O
- O
tuning O
from O
a O
checkpoint O
that O
has O
been O
pre O
- O
trained O
for O
steps O
. O

This O
allows O
us O
to O
answer O
the O
following O
question O
: O
Does O
BERT B-MethodName
really O
need O
such O
a O
large O
amount O
of O
pre O
- O
training O
( O
128,000 B-HyperparameterValue
words B-HyperparameterName
/ I-HyperparameterName
batch I-HyperparameterName
* O
1,000,000 B-HyperparameterValue
steps B-HyperparameterName
) O
to O
achieve O
high O
fine O
- O
tuning O
accuracy O
? O

BERT B-MethodName
BASE I-MethodName
does O
almost O
1.0% B-MetricValue
% O
more O
accuracy B-MetricName
on O
MNLI B-TaskName
when O
trained O
on O
1M B-HyperparameterValue
steps B-HyperparameterName
than O
when O
trained O
on O
500k B-HyperparameterValue
steps B-HyperparameterName
. O

Since O
only O
a O
portion O
of O
the O
words O
are O
predicted O
in O
each O
batch O
during O
MLM O
pre O
- O
training O
, O
does O
this O
cause O
the O
training O
to O
converge O
more O
slowly O
than O
LTR O
pre O
- O
training O
? O

In O
section O
3 O
, O
we O
mention O
that O
BERT B-MethodName
uses O
a O
mixed O
strategy O
for O
masking O
the O
target O
tokens O
when O
pre O
- O
training O
with O
the O
masked O
language O
model O
( O
MLM O
) O
objective O
. O

We O
are O
reporting O
the O
Dev O
results O
for O
both O
MNLI B-TaskName
and O
NER B-TaskName
. O

We O
report O
both O
fine O
- O
tuning O
and O
feature O
- O
based O
approaches O
for O
NER B-TaskName
, O
as O
we O
expect O
the O
mismatch O
will O
be O
amplified O
for O
the O
feature O
- O
based O
approach O
as O
the O
model O
will O
not O
have O
the O
chance O
to O
adjust O
the O
representations O
. O

The O
numbers O
in O
the O
left O
part O
of O
the O
table O
represent O
the O
probabilities O
of O
the O
specific O
strategies O
used O
during O
MLM O
pretraining O
( O
BERT B-MethodName
uses O
80% B-HyperparameterValue
, O
10% B-HyperparameterValue
, O
10% B-HyperparameterValue
) O
. O

We O
concatenate O
the O
last O
4 O
layers O
of O
BERT B-MethodName
as O
the O
features O
for O
the O
feature O
- O
based O
approach O
, O
which O
was O
shown O
to O
be O
the O
best O
approach O
in O
Section O
5.3 O
. O

However O
, O
the O
feature O
- O
based O
approach O
to O
NER B-TaskName
was O
problematic O
when O
using O
only O
the O
M O
ASK O
strategy O
as O
expected O
. O
