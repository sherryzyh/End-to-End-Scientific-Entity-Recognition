Mediators O
in O
Determining O
what O
Processing O
BERT B-MethodName
Performs O
First O
Aviv O
Slobodkin O

Leshem O
Choshen O
Omri O
Abend O
School O
of O
Computer O
Science O
and O
Engineering O
The O
Hebrew O
University O
of O
Jerusalem O
{ O
aviv.slobodkin,leshem.choshen,omri.abend}@mail.huji.ac.il O
Abstract O
Probing O
neural O
models O
for O
the O
ability O
to O
per- O
form O
downstream O
tasks O
using O
their O
activation O
patterns O
is O
often O
used O
to O
localize O
what O
parts O
of O
the O
network O
specialize O
in O
performing O
what O
tasks O
. O

However O
, O
little O
work O
addressed O
poten- O
tial O
mediating O
factors O
in O
such O
comparisons O
. O

As O
a O
test O
- O
case O
mediating O
factor O
, O
we O
consider O
the O
prediction O
’s O
context O
length O
, O
namely O
the O
length O
of O
the O
span O
whose O
processing O
is O
minimally O
re- O
quired O
to O
perform O
the O
prediction O
. O

We O
show O
that O
not O
controlling O
for O
context O
length O
may O
lead O
to O
contradictory O
conclusions O
as O
to O
the O
local- O
ization O
patterns O
of O
the O
network O
, O
depending O
on O
the O
distribution O
of O
the O
probing O
dataset O
. O

Indeed O
, O
when O
probing O
BERT B-MethodName
with O
seven O
tasks O
, O
we O
ﬁnd O
that O
it O
is O
possible O
to O
get O
196 O
different O
rankings O
between O
them O
when O
manipulating O
the O
distribu- O
tion O
of O
context O
lengths O
in O
the O
probing O
dataset O
. O

We O
conclude O
by O
presenting O
best O
practices O
for O
conducting O
such O
comparisons O
in O
the O
future.1 O
1 O
Introduction O
The O
strong O
performance O
of O
end O
- O
to O
- O
end O
models O
and O
the O
difﬁculty O
in O
understanding O
their O
inner O
work- O
ings O
has O
led O
to O
extensive O
research O
aimed O
at O
inter- O
preting O
their O
behavior O
( O
Li O
et O
al O
. O
, O
2016 O
; O

Yosinski O
et O
al O
. O
, O
2015 O
; O
Karpathy O
et O
al O
. O
, O
2015 O
) O
. O

This O
notion O
has O
led O
researchers O
to O
investigate O
the O
behavioral O
traits O
of O
networks O
in O
general O
( O
Li O
et O
al O
. O
, O
2015 O
; O
Haco- O
hen O
et O
al O
. O
, O
2020 O
) O
and O
representative O
architectures O
in O
particular O
( O
Schlichtkrull O
et O
al O
. O
, O
2020 O
) O
. O

Within O
NLP B-TaskName
, O
Transformer O
- O
based O
pretrained O
embeddings O
are O
the O
basis O
for O
many O
tasks O
, O
which O
underscores O
the O
impor- O
tance O
in O
interpreting O
their O
behavior O
( O
Belinkov O
et O
al O
. O
, O
2020 O
) O
, O
and O
especially O
the O
behavior O
of O
BERT B-MethodName
( O
De- O
vlin O
et O

al O
. O
, O
2019 O
; O
Rogers O
et O
al O
. O
, O
2020 O
) O
, O
perhaps O
the O
most O
widely O
used O
of O
Transformer O
- O
based O
models O
. O

In O
this O
work O
, O
we O
analyze O
the O
common O
approach O
ofprobing O
( O
§ O
2 O
) O
, O
used O
to O
localize O
where O
“ O
knowledge O
” O
1The O
code O
is O
available O
at O
https://github.com/ O
lovodkin93 O
/ O
BERT B-MethodName
- O
context O
- O
distance O
.of O

particular O
tasks O
is O
encoded O
; O
localization O
is O
often O
carried O
out O
in O
terms O
of O
the O
layers O
most O
responsible O
for O
the O
task O
at O
hand O
( O
c.f O
. O
Tenney O
et O
al O
. O
, O
2019b O
) O
. O

Vari- O
ous O
works O
( O
Tenney O
et O
al O
. O
, O
2019a O
; O
Peters O
et O
al O
. O
, O
2018 O
; O
Blevins O
et O
al O
. O
, O
2018 O
) O
showed O
that O
some O
tasks O
are O
processed O
in O
lower O
levels O
than O
others O
. O

We O
examine O
the O
extent O
to O
which O
potential O
me- O
diating O
factors O
may O
account O
for O
observed O
trends O
and O
show O
that O
varying O
some O
mediating O
factors O
( O
see O
§ O
2 O
) O
may O
diminish O
, O
or O
even O
reverse O
, O
the O
conclusions O
made O
by O
Tenney O
et O
al O
. O

( O
T19 O
; O
2019a O
) O
. O

Speciﬁcally O
, O
despite O
reafﬁrming O
T19 O
’s O
experimental O
ﬁndings O
, O
we O
contest O
T19 O
’s O
interpretation O
of O
the O
results O
, O
namely O
that O
the O
processing O
carried O
out O
by O
BERT B-MethodName
parallels O
the O
classical O
NLP B-TaskName
pipeline O
. O

Indeed O
, O
T19 O
concludes O
that O
lexical O
tasks O
( O
POS B-TaskName
tagging I-TaskName
) O
are O
performed O
by O
the O
lower O
layers O
, O
followed O
by O
syntactic B-TaskName
tasks I-TaskName
, O
whereas O
more O
semantic O
tasks O
are O
performed O
later O
on O
. O

This O
analysis O
rests O
on O
the O
assumption O
that O
the O
nature O
of O
the O
task O
( O
lexical O
, O
syntactic O
, O
or O
semantic O
) O
is O
the O
driving O
force O
that O
determines O
what O
layer O
per- O
forms O
what O
analysis O
. O

We O
show O
that O
other O
factors O
should O
be O
weighed O
in O
as O
well O
. O

Speciﬁcally O
, O
we O
show O
that O
manipulating O
the O
distribution O
of O
examples O
in O
the O
probing O
dataset O
can O
lead O
to O
a O
variety O
of O
different O
conclusions O
as O
to O
what O
tasks O
are O
performed O
ﬁrst O
. O

We O
argue O
that O
potential O
mediators O
must O
be O
con- O
sidered O
when O
comparing O
tasks O
, O
and O
focus O
on O
one O
such O
mediator O
– O
the O
context O
length O
, O
which O
we O
de- O
ﬁne O
as O
the O
number O
of O
tokens O
whose O
processing O
is O
minimally O
required O
to O
perform O
the O
prediction O
. O

We O
operationalize O
this O
notion O
by O
deﬁning O
it O
as O
the O
max- O
imal O
distance O
between O
any O
two O
tokens O
for O
which O
a O
label O
is O
predicted O
. O

This O
amounts O
to O
the O
span O
length O
in O
tasks O
that O
involve O
a O
single O
span O
( O
e.g. O
, O
NER B-TaskName
) O
, O
and O
to O
the O
dependency O
length O
in O
tasks O
that O
address O
the O
relation O
between O
two O
spans O
. O

See O
§ O
2 O
. O

Our O
motiva- O
tion O
for O
considering O
context O
length O
as O
a O
mediator O
is O
grounded O
in O
previous O
work O
that O
presented O
the O
difﬁculty O
posed O
by O
long O
- O
distance O
dependencies O
in O
various O
NLP B-TaskName
tasks O
( O
Xu O
et O
al O
. O
, O
2009 O
; O
Sennrich O
, O
2017 O
) O
, O

87and O
particularly O
in O
previous O
work O
that O
indicated O
the O
Transformers O
’ O
difﬁculty O
to O
generalize O
across O
dif- O

ferent O
dependency O
lengths O
( O
Choshen O
and O
Abend O
, O
2019 O
) O
. O

We O
show O
that O
in O
some O
of O
the O
cases O
where O
one O
task O
seems O
to O
be O
better O
predicted O
by O
a O
higher O
layer O
than O
another O
task O
, O
controlling O
for O
context O
length O
may O
reverse O
that O
order O
. O

Indeed O
we O
show O
that O
196 O
different O
rankings O
between O
the O
seven O
tasks O
explored O
in O
T19 O
may O
be O
obtained O
with O
a O
suitable O
distribution O
over O
the O
probing O
datasets O
, O
namely O
196 O
different O
ways O
to O
rank O
the O
tasks O
according O
to O
their O
expected O
layer O
. O

Moreover O
, O
our O
results O
show O
that O
when O
context O
length O
is O
not O
taken O
into O
account O
, O
one O
task O
( O
e.g. O
, O
dependency B-TaskName
parsing I-TaskName
) O
may O
seem O
to O
be O
processed O
at O
a O
higher O
layer O
than O
another O
( O
e.g. O
, O
NER B-TaskName
) O
, O
when O
its O
expected O
layer O
( O
see O
§ O
2 O
) O
is O
, O
in O
fact O
, O
lower O
for O
all O
ranges O
of O
context O
lengths O
( O
§ O
3.1.1 O
) O
. O

2 O
Background O
We O
begin O
by O
laying O
out O
the O
terminology O
and O
methodology O
we O
will O
use O
in O
the O
paper O
. O

Edge O
Probing O
. O

Edge O
probing O
is O
the O
method O
of O
training O
a O
classiﬁer O
for O
a O
given O
task O
on O
different O
parts O
of O
the O
network O
( O
without O
ﬁne O
- O
tuning O
) O
. O

Suc- O
cess O
in O
classiﬁcation O
is O
interpreted O
as O
evidence O
that O
the O
required O
features O
for O
classiﬁcation O
are O
some- O
how O
encoded O
in O
the O
examined O
part O
and O
are O
sufﬁ- O
ciently O
easy O
to O
extract O
. O

In O
our O
experiments O
, O
we O
follow O
T19 O
and O
probe O
BERT B-MethodName
with O
Named O
Entity O
Recognition O
( O
NER B-TaskName
) O
, O
a O
constituent O
- O
based O
task O
( O
clas- O
sifying O
Non O
- O
terminals O
- O
Non O
- O
term O
. O
) O
, O
Semantic O
Role O
Labeling O
( O
SRL B-TaskName
) O
, O
Co B-TaskName
- I-TaskName
reference I-TaskName
( O
Co B-TaskName
- I-TaskName
ref I-TaskName
. O
) O
, O
Semantic O
Proto O
- O
Roles O
( O
SPR B-TaskName
; O
Reisinger O
et O
al O
. O
, O
2015 O
) O
, O
Relation O
Classiﬁcation O
( O
RC B-TaskName
) O
and O
the O
Stanford O
Dependency B-TaskName
Parsing I-TaskName
( O
Dep B-TaskName
. O
; O
de O
Marneffe O
et O
al O
. O
, O
2006 O
) O
. O

Causal O
considerations O
in O
interpreting O
probing O
results O
were O
also O
emphasized O
by O
several O
recent O
works O
( O
e.g. O
, O
Kaushik O
et O
al O
. O
, O
2020 O
; O

Vig O
et O
al O
. O
, O
2020 O
; O
Elazar O
et O
al O
. O
, O
2021 O
) O
. O

Localization O
by O
Expected O
Layer O
. O

The O
expected O
layer O
metric O
( O
which O
we O
will O
henceforth O
refer O
to O
it O
as
Elayer B-MetricName
) O
of O
T19 O
assesses O
which O
layer O
in O
BERT B-MethodName
is O
most O
needed O
for O
prediction O
: O
a O
probing B-MetricName
classiﬁer I-MetricName
P I-MetricName
is O
trained O
on O
the O
lowest O
llayers O
. O

Then O
, O
a O
dif- O
ferential O
score O
(l)is O
computed O
, O
which O
indicates O
the O
performance O
gain O
when O
taking O
into O
account O
one O
additional O
layer O
: O
(l)=Score O
( O
P(l)) Score O
( O
P(l 1))(1)Once O
all O
thef(l)g12 O
l=1are O
computed O
, O
we O
may O
compute
Elayer B-MetricName
: O
Elayer B-MetricName
] O
= O
P12 O
l=1l(l O
) O
P12 O
l=1(l)(2 O
) O
Therefore O
, O
unlike O
standard O
edge O
probing O
, O
which O
is O
performed O
on O
each O
layer O
individually O
, O
computing O
Elayer B-MetricName
takes O
into O
account O
all O
layers O
up O
to O
a O
given O
l. O
Mediation O
Analysis O
. O

Each O
of O
the O
explored O
tasks O
classiﬁes O
one O
or O
two O
input O
sub O
- O
spans O
. O

In O
both O
cases O
, O
we O
deﬁne O
the O
context O
length O
to O
be O
the O
distance O

be- O
tween O
the O
earliest O
and O
latest O
span O
index O
. O

Namely O
, O
for O
tasks O
with O
two O
spans O
( O
e.g. O
, O
SPR B-TaskName
) O
, O
span O
1=[i1,j1 O
] O
andspan O
2=[i2,j2 O
] O
, O
where O
span O
1appears O
before O
span O
2 O
, O
the O
context O
length O
is O
j2 O
- O
i1 O
, O
whereas O
for O
tasks O
with O
just O
one O
span O
( O
e.g. O
, O
NER B-TaskName
) O
, O
span O
1=[i1,j1 O
] O
, O
it O
is O
j1 O
- O
i1 O
. O

In O
order O
to O
examine O
the O
effect O
of O
context O
length O
on
Elayer B-MetricName
, O
we O
model O
it O
as O
a O
mediating O
factor O
, O
namely O
as O
an O
intermediate O
variable O
that O
( O
partly O
) O
ex- O
plains O
the O
relationship O
between O
two O
other O
variables O
( O
in O
this O
work O
, O
a O
task O
and O
its O
Elayer B-MetricName
) O
. O

See O
Figure O
1 O
. O

We O
bin O
each O
task O
’s O
test O
set O
into O
non O
- O
overlapping O
bins O
, O
according O
to O
their O
context O
length O
ranges O
. O

We O
use O
the O
notation O
‘ O
i O
- O
j O
’ O
to O
denote O
the O
bin O
of O
context O
lengths O
in O
the O
range O

[ O
i O
, O
j O
] O
. O

For O
example O
, O
the O
sec- O
ond O
bin O
would O
be O
’ O
3 O
- O
5 O
’ O
, O
denoting O
context O
lengths O
3 O
, O
4 O
, O
and O
5 O
. O

In O
addition O
, O
given O
a O
speciﬁc O
task O
, O
two O
possible O
approaches O
exist O
to O
examine O
the O
media- O
tion O
effect O
of O
context O
length O
on O
the O
task O
’s O
Elayer B-MetricName
. O

The O
ﬁrst O
one O
bins O
all O
the O
task O
’s O
data O
into O
sub O
- O
sets O
, O
in O
advance O
. O

Then O
, O
this O
approach O
ﬁne O
- O
tunes O
over O
each O
subset O
separately O
. O

Alternatively O
, O
the O
second O
approach O
ﬁne O
- O
tunes O
over O
the O
whole O
dataset O
, O
binning O
only O
during O
the O
test O
phase O
. O

We O
follow O
the O
latter O
ap- O
proach O
, O
as O
it O
is O
more O
computationally O
efﬁcient O
. O

T O
C O
Elayer B-MetricName
Figure O
1 O
: O
The O
relationship O
we O
stipulate O
between O
the O
task O
, O
the O
context O
length O
, O
and O
Elayer B-MetricName
. O

We O
use O
two O
ran- O
dom O
variables O
: O
Tis O
the O
task O
, O
which O
can O
be O
any O
of O
the O
seven O
tasks O
we O
observe O
and O
Cis O
the O
context O
length O
. O

Interestingly O
, O
in O
§ O
3.1.1 O
, O
we O
encounter O
a O
spe- O
cial O
edge O
case O
, O
where O
the O
aggregated O
average O
( O
i.e. O
, O
Elayer B-MetricName
) O
of O
one O
task O
is O
higher O
than O
another O
, O
whereas O

88 O
in O
each O
sub O
- O
set O
( O
by O
a O
given O
context O
length O
) O
it O
is O
lower O
. O

This O
may O
occur O
when O
the O
weight O
of O
the O
sub O
- O
sets O
differs O
between O
the O
two O
aggregations O
. O

3 O
Experiments O
We O
hypothesize O
that O
the O
context O
length O
is O
a O
medi- O
ating O
factor O
in O
the O
Elayer B-MetricName
of O
a O
task O
. O

In O
order O
to O
test O
this O
hypothesis O
, O
we O
run O
the O
following O
experiments O
, O
aiming O
at O
isolating O
the O
context O
length O
. O

We O
use O
the O
SPR1 B-DatasetName
dataset O
( O
Reisinger O
et O
al O
. O
, O
2015 O
) O
to O
probe O
SPR B-TaskName
, O
the O
English O
Web O
Treebank O
for O
the O
Dep B-TaskName
. O
task O
( O
Silveira O
et O
al O
. O
, O
2014 O
) O
, O
the O
SemEval O
2010 O
Task O
8 O
for O
the O
RC B-TaskName
task O
( O
Hendrickx O
et O
al O
. O
, O
2009 O
) O
, O
and O
the O
OntoNotes B-DatasetName
5.0 I-DatasetName
dataset O
( O
Weischedel O
et O
al O
. O
, O
2013 O
) O
for O
the O
other O
tasks O
. O

Conﬁgurations O
follow O
the O
defaults O
in O
the O
Jiant O
toolkit O
implementation O
( O
Wang O
et O
al O
. O
, O
2019 O
) O
. O

In O
addition O
, O
we O
work O
with O
the O
BERT- O
base O
model O
. O

3.1 O
The O
Effect O
on O
Elayer B-MetricName
First O
, O
we O
wish O
to O
conﬁrm O
that O
context O
length O
indeed O
affects O
Elayer B-MetricName
and O
that O
the O
task O
is O
not O
a O
sole O
contrib- O
utor O
to O
this O
. O

Given O
a O
task O
and O
a O
threshold O
thr O
, O
we O
compile O
a O
dataset O
for O
the O
task O
containing O
the O
sub- O
set O
of O
examples O
with O
context O
lengths O
shorter O
than O
thr O
, O
and O
use O
it O
to O
compute O
Elayer B-MetricName
. O

We O
do O
it O
for O
all O
tasks O
and O
for O
every O
integer O
threshold O
between O
0 O
and O
a O
maximal O
threshold O
, O
which O
is O
selected O
separately O
for O
each O
task O
to O
ensure O
that O
at O
least O
2000 O
instances O
remain O
in O
the O
last O
bin O
. O

We O
ﬁnd O
that O
context O
length O
plays O
an O
important O
role O
in O
the O
difference O
between O
the O
expected O
layers O
( O
Figure O
2 O
) O
. O

Most O
notably O
, O
the O
Co B-TaskName
- I-TaskName
ref I-TaskName
. O
, O
SRL B-TaskName
, O
Dep B-TaskName
. O
, O
and O
RC B-TaskName
tasks O
’ O
Elayer B-MetricName
increases O
when O
increasing O
the O
threshold O
. O

Next O
, O
we O
divide O
the O
data O
into O
smaller O
bins O
of O
non O
- O
overlapping O
context O
length O
ranges O
, O
in O
order O
to O
control O
for O
the O
inﬂuence O
of O
the O
context O
lengths O
on O
the O
expected O
layers O
of O
the O
tasks O
. O

We O
compute O
Elayer B-MetricName
for O
sub O
- O
sets O
of O
similar O
lengths O
. O

In O
choos- O
ing O
the O
size O
of O
each O
such O
range O
, O
we O
try O
to O
balance O
between O
informativeness O
( O
narrower O
ranges O
) O
and O
re- O
liability O
( O
having O
enough O
examples O
in O
each O
range O
, O
so O
as O
to O
reduce O
noise O
) O
. O

We O
ﬁnd O
that O
the O
narrowest O
range O
width O
that O
retains O
at O
least O
1 O
% O
of O
the O
examples O
in O
each O
bin O
is O
3 O
. O

We O
thus O
divide O
the O
dataset O
for O
each O
task O
into O
context O
length O
ranges O
of O
width O
3 O
, O
until O
the O
maximal O
threshold O
is O
reached O
. O

Higher O
context O
lengths O
are O
lumped O
into O
an O
additional O
bin O
. O

Figure O
2 O
: O
Elayer B-MetricName
as O
a O
function O
of O
a O
threshold O
on O
the O
context O
length O
. O

For O
each O
such O
threshold O
thr(x O
- O
axis O
) O
, O
Elayer B-MetricName
( O
y O
- O
axis O
) O
is O
computed O
based O
only O
on O
the O
examples O
with O
context O
length O
no O
longer O
than O
thr O
. O

3.1.1 O
Manipulating O
the O
Context O
Length O
Distribution O
: O
An O
Extreme O
Case O
. O

We O
begin O
by O
examining O
two O
speciﬁc O
tasks O
: O

Dep B-TaskName
. O
and O
NER B-TaskName
, O
and O
their O
Elayer B-MetricName
for O
each O
context O
length O
’s O
range O
. O

We O
then O
consider O
, O
for O
simplicity O
, O
a O
case O
where O
all O
the O
context O
lengths O
of O
Dep B-TaskName
. O
are O
of O
length O
9 O
+ O
, O
while O
those O
of O
NER B-TaskName
are O
in O
the O
range O
of O
3 O
- O
5 O
( O
Figure O
3 O
) O
. O

We O
see O
that O
when O
controlling O
for O
context O
length O
, O
Dep B-TaskName
. O
is O
computed O
in O
a O
lower O
layer O
than O
NER B-TaskName
, O
regardless O
of O
the O
range O
. O

However O
, O
depending O
on O
the O
distribution O
of O
context O
lengths O
in O
the O
probing B-DatasetName
dataset I-DatasetName
, O
the O
outcome O
may O
be O
completely O
different O
, O
with O
Dep B-TaskName
. O

being O
processed O
in O
higher O
layers O
( O
for O
a O
similar O
example O
of O
a O
different O
task O
- O
pair O
, O
see O
§ O
A.1 O
) O
. O

These O
results O
indicate O
that O
the O
results O
of O
T19 O
do O
not O
necessarily O
indicate O
that O
BERT B-MethodName
is O
performing O
a O
pipeline O
of O
computations O
( O
as O
is O
commonly O
asserted O
, O
see O
e.g. O
, O
T19 O
and O
Blevins O
et O
al O
. O

( O
2018 O
) O
) O
, O
and O
that O
mediating O
factors O
need O
to O
be O
taken O
into O
account O
when O
interpreting O
Elayer B-MetricName
. O

Figure O
3 O
: O
Elayer B-MetricName
of O
NER B-TaskName
and O
Dep B-TaskName
. O

for O
different O
context O
length O
ranges O
( O
4 O
left O
blue O
and O
yellow O
pairs O
) O
, O
and O
their O
Elayer B-MetricName
when O
all O
instances O
of O
NER B-TaskName
are O
of O
context O
length O
l2[3;5]and O
all O
those O
of O
Dep B-TaskName
. O

are O
of O
context O
length O
l9(rightmost O
green O
and O
red O
pair O
) O
. O

While O
for O
every O
context O
length O
range O
, O
NER B-TaskName
’s O
Elayer B-MetricName
is O
bigger O
than O
that O
of O
Dep B-TaskName
. O
, O
for O
some O
context O
length O
distribution O
that O
order O
may O
be O
reversed O
. O

893.2 O
Imposing O
Similar O
Length O
Distributions O
In O
the O
previous O
section O
, O
we O
observed O
that O
one O
task O
can O
be O
both O
higher O
and O
lower O
than O
another O
. O

That O
depends O
on O
the O
distribution O
of O
context O
lengths O
in O
the O
probing B-DatasetName
dataset I-DatasetName
. O

We O
next O
ask O
whether O
such O
a O
" O
paradox O
" O
arises O
in O
experiments O
when O
imposing O
the O
same O
context O
length O
distributions O
on O
the O
two O
tasks O
. O

Following O
Pearl O
( O
2001 O
) O
, O
we O
employ O
mediation O
analysis O
and O
speciﬁcally O
concentrate O
on O
the O
Natural O
Direct O
Effect O
( O
NDE O
) O
, O
which O
is O
the O
difference O
be- O
tween O
two O
of O
the O
observed O
dependent O
variables O
( O
in O
our O
case O
Elayer B-MetricName
) O
, O
when O
ﬁxing O
the O
mediator O
. O

In O
our O
case O
, O
the O
NDE O
is O
the O
difference O
between O
the O
Elayer B-MetricName
of O
two O
tasks O
, O
while O
forcing O
the O
same O
context O
length O
distribution O
on O
both O
. O

For O
convenience O
, O
we O
force O
the O
distribution O
of O
one O
of O
the O
examined O
tasks O
( O
for O
more O
details O
, O
see O
§ O
A.2 O
) O
, O
but O
any O
distribution O
is O
applicable O
. O

In O
general O
, O
the O
equation O
for O
computing O
the O
NDE O
of O
taskst1andt2 O
, O
with O
the O
context O
length O
distribution O
oft1imposed O
on O
both O
, O
is O
: O
NDE O
t1t2 O
= O
X O
c[E[ljC O
= O
c O
; O

T O
= O
t2 O
] O
 E[ljC O
= O
c O
; O
T O
= O
t1]]P(C O
= O
cjT O
= O
t1)(3 O
) O
where O
T O
is O
a O
random O
variable O
of O
the O
tasks O
, O
and O
C O
is O
a O
random O
variable O
of O
the O
context O
length O
. O

We O
apply O
NDE O
twice O
for O
every O
pair O
of O
tasks O
( O
once O
for O
each O
task O
’s O
context O
length O
distribution O
) O
. O

We O
then O
compare O
the O
results O
to O
the O
difference O
be- O

tween O
the O
tasks O
’ O
expected O
layers O
where O
each O
task O
keeps O
its O
original O
context O
length O
distribution O
( O
un- O
mediated O
) O
. O

Results O
( O
Figure O
4 O
) O
show O
that O
the O
differ- O
ence O
could O
be O
more O
than O
50 O
times O
larger O
( O
change O
of O
1.24 O
in O
absolute O
value O
) O
or O
decrease O
by O
86 O
% O
( O
0.73 O
in O
absolute O
value O
) O
. O

In O
some O
cases O
the O
order O
of O
the O
two O
tasks O
is O
reversed O
, O
namely O
, O
the O
task O
that O
is O
lower O
with O
one O
distribution O
becomes O
higher O
with O
another O
. O

This O
shows O
that O
even O
among O
our O
examined O
set O
of O
seven O
tasks O
, O
the O
effect O
of O
potential O
mediators O
can O
not O
be O
ignored O
. O

For O
more O
results O
, O
see O
§ O
A.3 O
. O

3.2.1 O
Controlling O
for O
Context O
Length O
After O
observing O
that O
the O
distribution O
of O
context O
length O
in O
the O
probing B-DatasetName
dataset I-DatasetName
may O
affect O
the O
relative O
order O
of O
the O
expected O
layers O
, O
we O
propose O
a O
more O
de- O
tailed O
and O
accurate O
method O
to O
compare O
the O
expected O
layers O
, O
which O
does O
not O
rely O
on O
a O
speciﬁc O
length O
dis- O
tribution O
. O

We O
do O
so O
by O
plotting O
the O
controlled O
effect O
, O
namely O
Elayer B-MetricName
for O
each O
range O
separately O
. O

Our O
results O
( O
Figure O
5 O
) O
allow O
computing O
the O
range O
of O
possible O
expected O
layers O
for O
a O
task O
, O
that O
may O
re- O
sult O
from O
taking O
any O
context O
length O
distribution O
Figure O
4 O
: O
Difference O
between O
unmediated O
Elayer B-MetricName
and O
NDE O
for O
NER B-TaskName
and O
Co B-TaskName
- I-TaskName
ref I-TaskName
. O

( O
left O
) O
; O
NER B-TaskName
and O
RC B-TaskName
( O
mid- O
dle O
) O
; O
and O
SPR B-TaskName
and O
RC B-TaskName

( O
right O
) O
. O

The O
employed O
context O
length O
distributions O
( O
as O
part O
of O
the O
NDE O
calculations O
) O
are O
of O
Co B-TaskName
- I-TaskName
ref I-TaskName
. O
, O
NER B-TaskName
and O
SPR B-TaskName
, O
respectively O
. O

( O
Figure O
6 O
) O
. O

The O
ﬁgure O
shows O
the O
wide O
range O
of O
possible O
relative O
behaviors O
of O
Elayer B-MetricName
for O
task O
- O
pairs O
: O
from O
notable O
to O
negligible O
difference O
in O
expected O
layers O
( O
e.g. O
, O
SRL B-TaskName
and O
Co B-TaskName
- I-TaskName
ref I-TaskName
. O
) O
, O
to O
pairs O
whose O
or- O
dering O
of O
expected O
layers O
may O
be O
reversed O
( O
i.e. O
, O
overlapping O
ranges O
, O
such O
as O
with O
SPR B-TaskName
and O
RC B-TaskName
) O
. O

In O
fact O
, O
by O
taking O
into O
account O
every O
possible O
combi- O
nation O
of O
context O
length O
distribution O
for O
each O
of O
the O
tasks O
, O
we O
get O
as O
many O
as O
196 O
possible O
rankings O
of O
the O
seven O
tasks O
according O
to O
their O
Elayer B-MetricName
. O

One O
such O
possible O
order O
is O
, O
for O
example O
, O
Non O
- O
term O
. O

< O

Dep B-TaskName
. O
< O

SRL B-TaskName
< O
RC B-TaskName
< O

NER B-TaskName
< O
Co B-TaskName
- I-TaskName
ref I-TaskName
. O

< O

SPR B-TaskName
. O

We O
elaborate O
on O
this O
in O
§ O
A.4 O
. O

To O
recap O
, O
we O
ﬁnd O
that O
the O
difference O
in O
Elayer B-MetricName
between O
some O
tasks O
may O
considerably O
change O
and O
their O
order O
may O
reverse O
, O
depending O
on O
the O
context O
length O
. O

This O
ﬁnding O
lends O
further O
support O
to O
our O
claim O
that O
mediators O
should O
be O
taken O
into O
account O
. O

Figure O
5 O
: O
Expected O
layers O
of O
all O
seven O
tasks O
as O
a O
func- O
tion O
of O
context O
length O
range O
. O

4 O
Conclusion O
We O
showed O
that O
when O
performing O
edge O
probing O
to O
identify O
what O
layers O
are O
responsible O
for O
addressing O
what O
tasks O
, O
it O
is O
imperative O
to O
take O
into O
account O
potential O
mediators O
, O
as O
they O
may O
be O
responsible O

90 O
Figure O
6 O
: O
The O
range O
of O
possible O
expected O
layers O
when O
varying O
context O
length O
, O
for O
each O
of O
the O
seven O
tasks O
. O

for O
much O
of O
the O
observed O
effect O
. O

Speciﬁcally O
, O
we O
showed O
that O
context O
length O
has O
a O
signiﬁcant O
impact O
on O
a O
task O
’s O
Elayer B-MetricName
. O

Our O
analysis O
shows O
the O
wide O
range O
of O
relative O
orderings O
of O
the O
expected O
layers O
for O
different O
tasks O
when O
assuming O
different O
con- O
text O
length O
distributions O
; O
from O
extreme O
edge O
cases O
, O
like O
the O
one O
we O
observed O
in O
§ O
3.1.1 O
, O
to O
more O
com- O
mon O
, O
but O
potentially O
misleading O
ones O
, O
where O
the O
difference O
between O
expected O
layers O
may O
dramati- O
cally O
increase O
or O
decrease O
depending O
on O
the O
context O
length O
distribution O
. O

Most O
importantly O
, O
it O
shows O
that O
by O
manipulating O
the O
context O
length O
distribution O
, O
we O
may O
get O
a O
wide O
range O
of O
outcomes O
. O

Our O
work O
suggests O
that O
mediating O
factors O
should O
be O
taken O
into O
account O
when O
basing O
analysis O
on O
the O
Elayer B-MetricName
. O

On O
a O
broader O
note O
, O
alternative O
hypotheses O
should O
be O
considered O
, O
before O
limiting O
oneself O
to O
a O
single O
interpretation O
. O

Future O
work O
will O
consider O
the O
effect O
of O
other O
me- O
diating O
factors O
. O

The O
two O
methods O
we O
used O
, O
NDE O
and O
controlled O
effect O
, O
can O
be O
used O
to O
examine O
the O
impact O
of O
other O
mediating O
factors O
and O
should O
be O
adopted O
as O
part O
of O
the O
ﬁeld O
’s O
basic O
analysis O
toolkit O
( O
cf O
. O

Feder O
et O

al O
. O
, O
2020 O
; O
Vig O
et O
al O
. O
, O
2020 O
) O
. O

NDE O
should O
be O
used O
when O
several O
effects O
are O
examined O
simultaneously O
, O
as O
it O
facilitates O
the O
assessment O
of O
their O
effect O
on O
the O
tasks O
’ O
complexity O
. O

It O
is O
also O
ad- O
visable O
to O
use O
NDE O
when O
a O
more O
practical O
examina- O
tion O
is O
required O
, O
i.e. O
, O
when O
distributions O
of O
the O
medi- O
ators O
are O
given O
empirically O
, O
as O
it O
is O
easier O
to O
derive O
the O
mediating O
factors O
’ O
impact O
using O
this O
method O
. O

In O
contrast O
, O
the O
controlled O
effect O
method O
should O
be O
used O
when O
examining O
the O
effects O
of O
two O
vari- O
ables O
( O
e.g. O
, O
tasks O
and O
mediating O
factors O
) O
or O
when O
comparing O
several O
tasks O
with O
one O
mediating O
effect O
. O

Acknowledgements O
This O
work O
was O
supported O
by O
the O
Israel O
Science O
Foundation O
( O
grant O
no O
. O
929/17 O
) O
. O

We O
would O
also O
like O
to O
thank O
Amir O
Feder O
for O
his O
very O
insightful O
feedback O
on O
our O
paper O
. O

References O
Yonatan O
Belinkov O
, O
Nadir O
Durrani O
, O
Fahim O
Dalvi O
, O
Has- O
san O
Sajjad O
, O
and O
James O
Glass O
. O
2020 O
. O

On O
the O
linguistic O
representational O
power O
of O
neural O
machine O
translation O
models O
. O

Computational O
Linguistics O
, O
46(1):1–52 O
. O

Terra O
Blevins O
, O
Omer O
Levy O
, O
and O
Luke O
Zettlemoyer O
. O

2018 O
. O

Deep O
RNNs O
encode O
soft O
hierarchical O
syntax O
. O

In O
Pro- O
ceedings O
of O
the O
56th O
Annual O
Meeting O
of O
the O
Associa- O
tion O
for O
Computational O
Linguistics O
( O
Volume O
2 O
: O
Short O
Papers O
) O
, O
pages O
14–19 O
, O
Melbourne O
, O
Australia O
. O

Asso- O
ciation O
for O
Computational O
Linguistics O
. O

Leshem O
Choshen O
and O
Omri O
Abend O
. O

2019 O
. O

Automat- O
ically O
extracting O
challenge O
sets O
for O
non O
- O
local O
phe- O
nomena O
in O
neural O
machine O
translation O
. O

In O
Proceed- O
ings O
of O
the O
23rd O
Conference O
on O
Computational O
Nat- O
ural O
Language O
Learning O
( O
CoNLL O
) O
, O
pages O
291–303 O
, O
Hong O
Kong O
, O
China O
. O

Association O
for O
Computational O
Linguistics O
. O

Marie O
- O
Catherine O
de O
Marneffe O
, O
Bill O
MacCartney O
, O
and O
Christopher O
D. O
Manning O
. O

2006 O
. O

Generating O
typed O
dependency B-TaskName
parses I-TaskName
from O
phrase O
structure O
parses O
. O

In O
Proceedings O
of O
the O
Fifth O
International O
Conference O
on O
Language O
Resources O
and O
Evaluation O
( O
LREC’06 O
) O
, O
Genoa O
, O
Italy O
. O

European O
Language O
Resources O
Associ- O
ation O
( O
ELRA O
) O
. O

Jacob O
Devlin O
, O
Ming O
- O
Wei O
Chang O
, O
Kenton O
Lee O
, O
and O
Kristina O
Toutanova O
. O
2019 O
. O

BERT B-MethodName
: O
Pre O
- O
training O
of O
deep O
bidirectional O
transformers O
for O
language O
under- O
standing O
. O

In O
Proceedings O
of O
the O
2019 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Human O
Language O
Technologies O
, O
Volume O
1 O
( O
Long O
and O
Short O
Papers O
) O
, O
pages O
4171–4186 O
, O
Minneapolis O
, O
Minnesota O
. O

Associ- O
ation O
for O
Computational O
Linguistics O
. O

Yanai O
Elazar O
, O
Shauli O
Ravfogel O
, O
Alon O
Jacovi O
, O
and O
Yoav O
Goldberg O
. O
2021 O
. O

Amnesic O
probing O
: O
Behavioral O
ex- O
planation O
with O
amnesic O
counterfactuals O
. O

Transac- O
tions O
of O
the O
Association O
for O
Computational O
Linguis- O
tics O
, O
9:160–175 O
. O

Amir O
Feder O
, O
Nadav O
Oved O
, O
Uri O
Shalit O
, O
and O
Roi O
Reichart O
. O

2020 O
. O

Causalm O
: O
Causal O
model O
explanation O
through O
counterfactual O
language O
models O
. O

Guy O
Hacohen O
, O
Leshem O
Choshen O
, O
and O
D. O
Weinshall O
. O
2020 O
. O

Let O
’s O
agree O
to O
agree O
: O
Neural O
networks O
share O
classiﬁcation O
order O
on O
real O
datasets O
. O

International O
Conference O
of O
Machine O
Learning O
. O

91Iris O
Hendrickx O
, O
Su O
Nam O
Kim O
, O
Zornitsa O
Kozareva O
, O
Preslav O
Nakov O
, O
Diarmuid O
Ó O
Séaghdha O
, O
Sebastian O
Padó O
, O
Marco O
Pennacchiotti O
, O
Lorenza O
Romano O
, O
and O
Stan O
Szpakowicz O
. O
2009 O
. O

SemEval-2010 O
task O
8 O
: O
Multi O
- O
way O
classiﬁcation O
of O
semantic O
relations O
be- O
tween O
pairs O
of O
nominals O
. O

In O
Proceedings O
of O
the O
Workshop O
on O
Semantic O
Evaluations O
: O
Recent O
Achieve- O
ments O
and O
Future O
Directions O
( O
SEW-2009 O
) O
, O
pages O
94 O
– O
99 O
, O
Boulder O
, O
Colorado O
. O

Association O
for O
Computa- O
tional O
Linguistics O
. O

Andrej O
Karpathy O
, O
Justin O
Johnson O
, O
and O
Li O
Fei O
- O
Fei O
. O
2015 O
. O

Visualizing O
and O
understanding O
recurrent O
networks O
. O

Divyansh O
Kaushik O
, O
Eduard O
Hovy O
, O
and O
Zachary O
Lipton O
. O

2020 O
. O

Learning O
the O
difference O
that O
makes O
a O
differ- O
ence O
with O
counterfactually O
- O
augmented O
data O
. O

In O
Inter- O
national O
Conference O
on O
Learning O
Representations O
. O

Jiwei O
Li O
, O
Xinlei O
Chen O
, O
Eduard O
Hovy O
, O
and O
Dan O
Jurafsky O
. O
2016 O
. O

Visualizing O
and O
understanding O
neural O
models O
in O
NLP B-TaskName
. O

In O
Proceedings O
of O
the O
2016 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Human O
Language O
Tech- O
nologies O
, O
pages O
681–691 O
, O
San O
Diego O
, O
California O
. O

As- O
sociation O
for O
Computational O
Linguistics O
. O

Y O
. O

Li O
, O
J. O
Yosinski O
, O
J. O
Clune O
, O
H. O
Lipson O
, O
and O
J. O
Hopcroft O
. O

2015 O
. O

Convergent O
learning O
: O
Do O
different O
neu- O
ral O
networks O
learn O
the O
same O
representations O
? O

In O
FE@NIPS O
. O

Judea O
Pearl O
. O

2001 O
. O

Direct O
and O
indirect O
effects O
. O

In O
Pro- O
ceedings O
of O
the O
17th O
Conference O
in O
Uncertainty O
in O
Artiﬁcial O
Intelligence O
, O
UAI O
’ O
01 O
, O
page O
411–420 O
, O
San O
Francisco O
, O
CA O
, O
USA O
. O

Morgan O
Kaufmann O
Publishers O
Inc. O

Matthew O
Peters O
, O
Mark O
Neumann O
, O
Luke O
Zettlemoyer O
, O
and O
Wen O
- O
tau O
Yih O
. O
2018 O
. O

Dissecting O
contextual O
word O
embeddings O
: O
Architecture O
and O
representation O
. O

InProceedings O
of O
the O
2018 O
Conference O
on O
Em- O
pirical O
Methods O
in O
Natural O
Language O
Processing O
, O
pages O
1499–1509 O
, O
Brussels O
, O
Belgium O
. O

Association O
for O
Computational O
Linguistics O
. O

Drew O
Reisinger O
, O
Rachel O
Rudinger O
, O
Francis O
Ferraro O
, O
Craig O
Harman O
, O
Kyle O
Rawlins O
, O
and O
Benjamin O
Van O
Durme O
. O

2015 O
. O

Semantic O
proto O
- O
roles O
. O

Transac- O
tions O
of O
the O
Association O
for O
Computational O
Linguis- O
tics O
, O
3:475–488 O
. O

Anna O
Rogers O
, O
Olga O
Kovaleva O
, O
and O
Anna O
Rumshisky O
. O

2020 O
. O

A O
primer O
in O
bertology O
: O
What O
we O
know O
about O
how O
bert O
works O
. O

M. O
Schlichtkrull O
, O
Nicola O
De O
Cao O
, O
and O
Ivan O
Titov O
. O

2020 O
. O

Interpreting O
graph O
neural O
networks O
for O
nlp O
with O
dif- O
ferentiable O
edge O
masking O
. O

Rico O
Sennrich O
. O

2017 O
. O

How O
grammatical O
is O
character- O
level O
neural O
machine O
translation O
? O

assessing O
MT O
qual- O
ity O
with O
contrastive O
translation O
pairs O
. O

In O
Proceed- O
ings O
of O
the O
15th O
Conference O
of O
the O
European O
Chap- O
ter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Volume O
2 O
, O
Short O
Papers O
, O
pages O
376–382 O
, O
Valencia O
, O
Spain O
. O

Association O
for O
Computational O
Linguistics O
. O

Natalia O
Silveira O
, O
Timothy O
Dozat O
, O
Marie O
- O
Catherine O
de O
Marneffe O
, O
Samuel O
Bowman O
, O
Miriam O
Connor O
, O
John O
Bauer O
, O
and O
Chris O
Manning O
. O

2014 O
. O

A O
gold O
stan- O
dard O
dependency O
corpus O
for O
English O
. O

In O
Proceedings O
of O
the O
Ninth O
International O
Conference O
on O
Language O
Resources O
and O
Evaluation O
( O
LREC’14 O
) O
, O
pages O
2897 O
– O
2904 O
, O
Reykjavik O
, O
Iceland O
. O

European O
Language O
Re- O
sources O
Association O
( O
ELRA O
) O
. O

Ian O
Tenney O
, O
Dipanjan O
Das O
, O
and O
Ellie O
Pavlick O
. O
2019a O
. O

BERT B-MethodName
rediscovers O
the O
classical O
NLP B-TaskName
pipeline O
. O

In O
Proceedings O
of O
the O
57th O
Annual O
Meeting O
of O
the O
Asso- O
ciation O
for O
Computational O
Linguistics O
, O
pages O
4593 O
– O
4601 O
, O
Florence O
, O
Italy O
. O
Association O
for O
Computational O
Linguistics O
. O

Ian O
Tenney O
, O
Patrick O
Xia O
, O
Berlin O
Chen O
, O
Alex O
Wang O
, O
Adam O
Poliak O
, O
R O
Thomas O
McCoy O
, O
Najoung O
Kim O
, O
Benjamin O
Van O
Durme O
, O
Sam O
Bowman O
, O
Dipanjan O
Das O
, O
and O
Ellie O
Pavlick O
. O
2019b O
. O

What O
do O
you O
learn O
from O
context O
? O

probing O
for O
sentence O
structure O
in O
contextu- O
alized O
word O
representations O
. O

In O
International O
Con- O
ference O
on O
Learning O
Representations O
. O

Jesse O
Vig O
, O
Sebastian O
Gehrmann O
, O
Yonatan O
Belinkov O
, O
Sharon O
Qian O
, O
Daniel O
Nevo O
, O
Yaron O
Singer O
, O
and O
Stuart O
Shieber O
. O

2020 O
. O

Causal O
mediation O
analysis O
for O
inter- O
preting O
neural O
nlp O
: O
The O
case O
of O
gender O
bias O
. O

Alex O
Wang O
, O
Ian O
F. O
Tenney O
, O
Yada O
Pruksachatkun O
, O
Katherin O
Yu O
, O
Jan O
Hula O
, O
Patrick O
Xia O
, O
Raghu O
Pappa- O
gari O
, O
Shuning O
Jin O
, O
R. O
Thomas O
McCoy O
, O
Roma O
Pa- O
tel O
, O
Yinghui O
Huang O
, O
Jason O
Phang O
, O
Edouard O
Grave O
, O
Najoung O
Kim O
, O
Phu O
Mon O
Htut O
, O
Thibault O
F’evry O
, O
Berlin O
Chen O
, O
Nikita O
Nangia O
, O
Haokun O
Liu O
, O
, O
An- O
had O
Mohananey O
, O
Shikha O
Bordia O
, O
Ellie O
Pavlick O
, O
and O
Samuel O
R. O
Bowman O
. O

2019 O
. O

jiant O
1.0 O
: O
A O
software O
toolkit O
for O
research O
on O
general O
- O
purpose O
text O
under- O
standing O
models O
. O

http://jiant.info/ O
. O

Ralph O
Weischedel O
, O
Martha O
Palmer O
, O
Mitchell O
Marcus O
, O
Eduard O
Hovy O
, O
Sameer O
Pradhan O
, O
Lance O
Ramshaw O
, O
Ni- O
anwen O
Xue O
, O
Ann O
Taylor O
, O
Jeff O
Kaufman O
, O
Michelle O
Franchini O
, O
et O
al O
. O
2013 O
. O

Ontonotes O
release O
5.0 O
ldc2013t19 O
. O

Linguistic O
Data O
Consortium O
, O
Philadel- O
phia O
, O
PA O
, O
23 O
. O

Peng O
Xu O
, O
Jaeho O
Kang O
, O
Michael O
Ringgaard O
, O
and O
Franz O
Och O
. O
2009 O
. O

Using O
a O
dependency B-TaskName
parser I-TaskName
to O
improve O
smt O
for O
subject O
- O
object O
- O
verb O
languages O
. O

In O
Proceed- O
ings O
of O
Human O
Language O
Technologies O
: O
The O
2009 O
Annual O
Conference O
of O
the O
North O
American O
Chap- O
ter O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
NAACL O
’ O
09 O
, O
page O
245–253 O
, O
USA O
. O
Association O
for O
Computational O
Linguistics O
. O

Jason O
Yosinski O
, O
Jeff O
Clune O
, O
Anh O
Mai O
Nguyen O
, O
Thomas O
J. O
Fuchs O
, O
and O
Hod O
Lipson O
. O
2015 O
. O

Under- O

standing O
neural O
networks O
through O
deep O
visualization O
. O

CoRR O
, O
abs/1506.06579 O
. O

92A O
Appendix O
A.1 O
Additional O
Example O
of O
the O
Extreme O
Case O
We O
show O
another O
example O
of O
a O
task O
- O
pair O
that O
, O
under O
certain O
distributions O
of O
context O
lengths O
, O
exhibits O
similar O
behavior O
to O
that O
observed O
in O
the O
edge O
case O
described O
in O
§ O
3.1.1 O
( O
ﬁgure O
7 O
) O
. O

Figure O
7 O
: O
Elayer B-MetricName
of O
SRL B-TaskName
and O
Non O
- O
term O
. O

for O
different O
context O
length O
ranges O
( O
4 O
left O
blue O
and O
yellow O
pairs O
) O
, O
and O
their
Elayer B-MetricName
when O
all O
instances O
of O
SRL B-TaskName
are O
of O
context O
length O
l2[0;2]and O
all O
those O
of O
Non O
- O
term O
. O

are O
of O
con- O
text O
length O
l9(rightmost O
green O
and O
red O
pair O
) O
. O

While O
for O
every O
context O
length O
range O
, O
SRL B-TaskName
’s O
Elayer B-MetricName
is O
bigger O
than O
that O
of O
Non O
- O
term O
. O
, O
for O
some O
context O
length O
distri- O
bution O
that O
order O
may O
be O
reversed O
. O

A.2 O
Context O
Length O
Distribution O
A O
lot O
of O
our O
work O
deals O
with O
possible O
context O
length O
distributions O
, O
normalizing O
distribution O
, O
and O
accounting O
for O
the O
distribution O
. O

We O
provide O
here O
the O
actual O
distributions O
which O
are O
the O
underlying O
property O
controlling O
the O
seen O
effects O
. O

We O
provide O
data O
on O
the O
percentage O
of O
examples O
in O
each O
context O
length O
range O
for O
each O
task O
( O
ﬁgure O
8) O
. O

Figure O
8 O
: O
Percentage O
of O
examples O
as O
a O
function O
of O
con- O
text O
length O
range O
, O
for O
each O
of O
the O
7 O
tasks O
( O
see O
legend O
) O
. O

A.3 O
NDE O
vs. O
Unmediated O
Difference O
for O
All O
Task O
- O
Pairs O
For O
every O
task O
- O
pair O
, O
we O
compare O
the O
unmediated O
Elayer B-MetricName
difference O
with O
the O
pair O
’s O
NDE O
. O

Figure O
9 O
presents O
this O
comparison O
for O
each O
task O
- O
pair O
, O
withthe O
distribution O
of O
one O
of O
the O
pair O
’s O
tasks O
being O
applied O
in O
the O
NDE O
calculations O
, O
for O
each O
task O
- O
pair O
. O

A.4 O
Extreme O
Elayer B-MetricName
Differences O
Based O
on O
ﬁgure O
6 O
, O
we O
compute O
the O
extreme O
Elayer B-MetricName
differences O
of O
each O
task O
- O
pair O
. O

Namely O
, O
for O
each O
such O
pair O
, O
we O
juxtapose O
the O
difference O
between O
the O
maximal O
possible O
Elayer B-MetricName
of O
the O
ﬁrst O
task O
and O
the O
minimal O
Elayer B-MetricName
of O
the O
second O
one O
with O
the O
opposite O
case O
( O
the O
difference O
between O
the O
minimal O
possible O
Elayer B-MetricName
of O
the O
ﬁrst O
task O
and O
the O
maximal O
Elayer B-MetricName
of O
the O
second O
one O
) O
. O

Our O
results O
can O
be O
seen O
in O
ﬁgure O
10 O
. O

93 O
Figure O
9 O
: O
Difference O
between O
unmediated O
Elayer B-MetricName
and O
NDE O
for O
every O
task O
- O
pair O
. O

The O
employed O
context O
length O
distributions O
( O
as O
part O
of O
the O
NDE O
calculations O
) O
are O
, O
from O
left O
to O
right O
, O
of O
NER B-TaskName
, O
SRL B-TaskName
, O
Dep B-TaskName
. O
, O
Non O
- O
term O
. O
, O
SRL B-TaskName
, O
Co B-TaskName
- I-TaskName
ref I-TaskName
. O
, O
Dep B-TaskName
. O
, O
Non O
- O
term O
. O
, O
SRL B-TaskName
, O
Non O
- O
term O
. O
, O
SPR B-TaskName
, O
SRL B-TaskName
, O
SPR B-TaskName
, O
SPR B-TaskName
, O
Non O
- O
term O
. O
, O
SRL B-TaskName
, O
RC B-TaskName
, O
NER B-TaskName
, O
Non O
- O
term O
. O
, O
Dep B-TaskName
. O
and O
SRL B-TaskName
. O

Figure O
10 O
: O
Difference O
between O
the O
minimal O
possible O
expected O
layer O
of O
the O
left O
task O
and O
the O
maximal O
possible O
expected O
layer O
of O
the O
right O
task O
( O
blue O
- O
see O
legend O
) O
, O
and O
vice O
- O
versa O
( O
yellow O
- O
see O
legend O
) O
, O
for O
every O
task O
- O
pair O
. O

