Proceedings O
of O
the O
2018 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
, O
pages O
1‚Äì10 O
Brussels O
, O
Belgium O
, O
October O
31 O
- O
November O
4 O
, O
2018 O
. O

c O

2018 O
Association O
for O
Computational O
Linguistics1Privacy O
- O
preserving O
Neural B-TaskName
Representations I-TaskName
of O

Text O
Maximin O

Coavoux O
Shashi O
Narayan O
Shay O
B. O
Cohen O
Institute O
for O
Language O
, O
Cognition O
and O
Computation O
School O
of O
Informatics O
, O
University O
of O
Edinburgh O
fmcoavoux O
, O
scohen O
g@inf.ed.ac.uk,shashi.narayan@ed.ac.uk O
Abstract O
This O
article O
deals O
with O
adversarial O
attacks O
to- O
wards O
deep O
learning O
systems O
for O
Natural O
Lan- O
guage O
Processing O
( O
NLP O
) O
, O
in O
the O
context O
of O
pri- O
vacy O
protection O
. O

We O
study O
a O
speciÔ¨Åc O
type O
of O
at- O
tack O
: O
an O
attacker O
eavesdrops O
on O
the O
hidden O
rep- O
resentations O
of O
a O
neural O
text O
classiÔ¨Åer O
and O
tries O
to O
recover O
information O
about O
the O
input O
text O
. O

Such O
scenario O
may O
arise O
in O
situations O
when O
the O
computation O
of O
a O
neural O
network O
is O
shared O
across O
multiple O
devices O
, O
e.g. O
some O
hidden O
rep- O
resentation O
is O
computed O
by O
a O
user O
‚Äôs O
device O
and O
sent O
to O
a O
cloud O
- O
based O
model O
. O

We O
measure O
the O
privacy O
of O
a O
hidden O
representation O
by O
the O
abil- O
ity O
of O
an O
attacker O
to O
predict O
accurately O
speciÔ¨Åc O
private O
information O
from O
it O
and O
characterize O
the O
tradeoff O
between O
the O
privacy O
and O
the O
util- O
ity O
of O
neural O
representations O
. O

Finally O
, O
we O
pro- O
pose O
several O
defense O
methods O
based O
on O
modi- O
Ô¨Åed O
training O
objectives O
and O
show O
that O
they O
im- O
prove O
the O
privacy O
of O
neural O
representations O
. O

1 O
Introduction O
This O
article O
presents O
an O
adversarial O
scenario O
meant O
at O
characterizing O
the O
privacy O
of O
neural O
representa- O
tions O
for O
NLP O
tasks O
, O
as O
well O
as O
defense O
methods O
designed O
to O
improve O
the O
privacy O
of O
those O
represen- O
tations O
. O

A O
deep B-MethodName
neural I-MethodName
network I-MethodName
constructs O
inter- O
mediate O
hidden O
representations O
to O
extract O
features O
from O
its O
input O
. O

Such O
representations O
are O
trained O
to O
predict O
a O
label O
, O
and O
therefore O
should O
contain O
use- O
ful O
features O
for O
the O
Ô¨Ånal O
prediction O
. O

However O
, O
they O
might O
also O
encode O
information O
about O
the O
input O
that O
a O
user O
wants O
to O
keep O
private O
( O
e.g. O
personal O
data O
) O
and O
can O
be O
exploited O
for O
adversarial O
usages O
. O

We O
study O
a O
speciÔ¨Åc O
type O
of O
attack O
on O
neural O
rep- O
resentations O
: O
an O
attacker O
eavesdrops O
on O
the O
hidden O
representations O
of O
novel O
input O
examples O
( O
that O
are O
not O
in O
the O
training O
set O
) O
and O
tries O
to O
recover O
informa- O
tion O
about O
the O
content O
of O
the O
input O
text O
( O
Figure O
1 O
) O
. O

A O
typical O
scenario O
where O
such O
attacks O
would O
oc- O
cur O
is O
when O
the O
computation O
of O
a O
deep O
neural O
net O
Latent O
representation O
, O
sent O
over O
a O
channel O

zAttackery O
x O
Private O
inputDesired O
  O
OutputFigure O
1 O
: O
General O
setting O
illustration O
. O

The O
main O
classi- O
Ô¨Åer O
predicts O
a O
label O
yfrom O
a O
textx O
, O
the O
attacker O
tries O
to O
recover O
some O
private O
information O
zcontained O
in O
xfrom O

the O
latent O
representation O
used O
by O
the O
main O
classiÔ¨Åer O
. O
is O
shared O
between O
several O
devices O
( O
Li O
et O
al O
. O
, O
2017 O
) O
. O

For O
example O
, O
a O
user O
‚Äôs O
device O
computes O
a O
represen- O
tation O
of O
a O
textual O
input O
, O
and O
sends O
it O
a O
to O
cloud- O
based O
neural O
network O
to O
obtain O
, O
e.g. O
the O
topic O
of O
the O
text O
or O
its O
sentiment O
. O

The O
scenario O
is O
illustrated O
in O
Figure O
1 O
. O

Private O
information O
can O
take O
the O
form O
of O
key O
phrases O
explicitly O
contained O
in O
the O
text O
. O

However O
, O
it O
can O
also O
be O
implicit O
. O

For O
example O
, O
demographic O
information O
about O
the O
author O
of O
a O
text O
can O
be O
pre- O
dicted O
with O
above O
chance O
accuracy O
from O
linguistic O
cues O
in O
the O
text O
itself O
( O
Rosenthal O
and O
McKeown O
, O
2011 O
; O
Preot O
¬∏iuc O
- O
Pietro O
et O
al O
. O
, O
2015 O
) O
. O

Independently O
of O
its O
explicitness O
, O
some O
of O
this O
private O
information O
correlates O
with O
the O
output O
la- O
bels O
, O
and O
therefore O
will O
be O
learned O
by O
the O
network O
. O

In O
such O
a O
case O
, O
there O
is O
a O
tradeoff O
between O
the O
util- O
ity O
of O
the O
representation O
( O
measured O
by O
the O
accu- O
racy O
of O
the O
network O
) O
and O
its O
privacy O
. O

It O
might O
be O

2necessary O
to O
sacriÔ¨Åce O
some O
accuracy O
in O
order O
to O
satisfy O
privacy O
requirements O
. O

However O
, O
this O
is O
not O
the O
case O
of O
all O
private O
in- O
formation O
, O
since O
some O
of O
it O
is O
not O
relevant O
for O
the O
prediction O
of O
the O
text O
label O
. O

Still O
, O
private O
infor- O
mation O
might O
be O
learned O
incidentally O
. O

This O
non- O
intentional O
and O
incidental O
learning O
also O
raises O
pri- O
vacy O
concerns O
, O
since O
an O
attacker O
with O
an O
access O
to O
the O
hidden O
representations O
, O
may O
exploit O
them O
to O
re- O
cover O
information O
about O
the O
input O
. O

In O
this O
paper O
we O
explore O
the O
following O
situation O
: O
( O
i O
) O
amain O
classiÔ¨Åer O
uses O
a O
deep O
network O
to O
predict O
a O
label O
from O
textual O
data O
; O
( O
ii O
) O
an O
attacker O
eaves- O
drops O
on O
the O
hidden O
layers O
of O
the O
network O
and O
tries O
to O
recover O
information O
about O
the O
input O
text O
of O
un- O
seen O
examples O
. O

In O
contrast O
to O
previous O
work O
about O
neural O
networks O
and O
privacy O
( O
Papernot O
et O
al O
. O
, O
2016 O
; O
Carlini O
et O
al O
. O
, O
2018 O
) O
we O
do O
not O
protect O
the O
privacy O
of O
examples O
from O
the O
training O
set O
, O
but O
the O
privacy O
of O
unseen O
examples O
provided O
, O
e.g. O
, O
by O
a O
user O
. O

An O
example O
of O
a O
potential O
application O
would O
be O
a O
spam O
detection O
service O
with O
the O
following O
con- O
straints O
: O
the O
service O
provider O
does O
not O
access O
ver- O

batim O
emails O
sent O
to O
users O
, O
only O
their O
vector O
repre- O
sentations O
. O

Theses O
vector O
representations O
should O
not O
be O
usable O
to O
gather O
information O
about O
the O
user O
‚Äôs O
contacts O
or O
correspondents O
, O
i.e. O
protect O
the O
user O
from O
proÔ¨Åling O
. O

This O
paper O
makes O
the O
following O
contributions:1 O
We O
propose O
a O
metric O
to O
measure O
the O
privacy O
of O
the O
neural O
representation O
of O
an O
input O
for O
Natural O
Language O
Processing O
tasks O
. O

The O
met- O
ric O
is O
based O
on O
the O
ability O
of O
an O
attacker O
to O
recover O
information O
about O
the O
input O
from O
the O
latent O
representation O
only O
. O

We O
present O
defense O
methods O
designed O
against O
this O
type O
of O
attack O
. O

The O
methods O
are O
based O
on O
modiÔ¨Åed O
training O
objectives O
and O
lead O
to O
an O
improved O
privacy O
- O
accuracy O
tradeoff O
. O

2 O
Adversarial O
Scenario O
In O
the O
scenario O
we O
propose O
, O
each O
example O
consists O
of O
a O
triple O
( O
x;y;z O
) O
, O
wherexis O
a O
natural O
language O
text O
, O
yis O
a O
single O
label O
( O
e.g. O
topic O
or O
sentiment O
) O
, O
andzis O
a O
vector O
of O
private O
information O
contained O
inx O
. O

Our O
base O
setting O
has O
two O
entities O
: O
( O
i O
) O
a O
main O
classiÔ¨Åer O
whose O
role O
is O
to O
learn O
to O
predict O
yfrom O
x O
, O
( O
ii O
) O
an O
attacker O
who O
learns O
to O
predict O
zfrom O
the O
latent O
representation O
of O
xused O
by O
the O
main O
classi- O
Ô¨Åer O
. O

We O
illustrate O
this O
setting O
in O
Figure O
1 O
. O

In O
order O
to O
evaluate O
the O
utility O
and O
privacy O
of O
a O
speciÔ¨Åc O
model O
, O
we O
proceed O
in O
three O
phases O
: O
Phase O
1 O
. O

Training O
of O
the O
main O
classiÔ¨Åer O
on O
( O
x;y)pairs O
and O
evaluation O
of O
its O
accuracy O
; O
Phase O
2 O
. O
Generation O
of O
a O
dataset O
of O
pairs O
( O
r(x);z)for O
the O
attacker O
, O
ris O
the O
representation O
function O
of O
the O
main O
classiÔ¨Åer O
( O
ris O
deÔ¨Åned O
in O
Sec- O
tion O
2.1 O
) O
; O
Phase O
3 O
. O

Training O
of O
the O
attacker O
‚Äôs O
network O
and O
evaluation O
of O
its O
performance O
for O
measuring O
pri- O
vacy O
. O

In O
the O
remainder O
of O
this O
section O
, O
we O
describe O
the O
main O
classiÔ¨Åer O
( O
Section O
2.1 O
) O
, O
and O
the O
attacker O
‚Äôs O
model O
( O
Section O
2.2 O
) O
. O

2.1 O
Text O
ClassiÔ¨Åer O
As O
our O
base O
model O
, O
we O
chose O
a O
standard O
LSTM B-MethodName
architecture I-MethodName
( O
Hochreiter O
and O
Schmidhuber O
, O
1997 O
) O
for O
sequence O
classiÔ¨Åcation O
. O

LSTM O
- O
based O
archi- O
tectures O
have O
been O
applied O
to O
many O
NLP O
tasks O
, O
including O
sentiment B-TaskName
classiÔ¨Åcation I-TaskName
( O
Wang O
et O
al O
. O
, O
2016 O
) O
and O
text B-TaskName
classiÔ¨Åcation I-TaskName
( O
Zhou O
et O
al O
. O
, O
2016 O
) O
. O

First O
, O
an O
LSTM O
encoder O
computes O
a O
Ô¨Åxed O
- O
size O
representation O
r(x)from O
a O
sequence O
of O
tokens O
x= O
( O
x1;x2;:::;x O
n)projected O
to O
an O
embedding O
space O
. O

We O
use O
rto O
denote O
the O
parameters O
used O
to O
construct O
r. O

They O
include O
the O
parameters O
of O
the O
LSTM O
, O
as O
well O
as O
the O
word O
embeddings O
. O

Then O
, O
the O
encoder O
output O
r(x)is O
fed O
as O
input O
to O
a O
feedfor- O
ward O
network O
with O
parameters O
pthat O
predicts O
the O
labelyof O
the O
text O
, O
with O
a O
softmax O
output O
activa- O
tion O
. O

In O
the O
standard O
setting O
, O
the O
model O
is O
trained O
to O
minimize O
the O
negative O
log O
- O
likelihood O
of O
ylabels O
: O
Lm(r;p O
) O

= O
NX O
i=1 logP(y(i)jx(i);r;p O
) O
; O
whereNis O
the O
number O
of O
training O
examples O
. O

2.2 O
Attacker O
‚Äôs O
ClassiÔ¨Åer O
Once O
the O
main O
model O
has O
been O
trained O
, O
we O
assume O
that O
its O
parameters O
randpare O
Ô¨Åxed O
. O

We O
gen- O
erate O
a O
new O
dataset O
made O
of O
pairs O
( O
r(x);z(x O
) O
) O
, O
where O
r(x)is O
the O
hidden O
representation O
used O
by O
the O
main O
model O
and O
z(x)is O
a O
vector O
of O
private O
cat- O
egorical O
variables O
. O

In O
practice O
, O
zis O
a O
vector O
of O
bi- O
nary O
variables O
, O
( O
representing O
e.g. O
demographic O
in- O
formation O
about O
the O
author O
) O
. O

In O
our O
experiments O
, O
we O
use O
the O
same O
training O
examples O
xfor O
the O
main O

3classiÔ¨Åer O
and O
the O
classiÔ¨Åer O
of O
the O
attacker O
. O

How- O
ever O
, O
since O
the O
attacker O
has O
access O
to O
the O
repre- O
sentation O
function O
rparameterized O
by O
r O
, O
they O
can O
generate O
a O
dataset O
from O
any O
corpus O
containing O
the O
private O
variables O
they O
want O
to O
recover O
. O

In O
other O
words O
, O
it O
is O
not O
necessary O
that O
they O
have O
access O
to O
the O
original O
training O
corpus O
to O
train O
their O
classiÔ¨Åer O
. O

The O
attacker O
trains O
a O
second O
feedforward O
net- O
work O
on O
the O
new O
dataset O
f(r(x(i));z(i))giN. O

This O
classiÔ¨Åer O
uses O
a O
sigmoid O
output O
activation O
to O
com- O
pute O
the O
probabilities O
of O
each O
binary O
variable O
in O
z O
: O
P(zjr(x);a O
) O

= O
(FeedForward O
( O
r(x O
) O
) O
): O

It O
is O
trained O
to O
minimize O
the O
negative O
log- O
likelihood O
of O
z O
: O
La(a O
) O

= O
NX O
i=1 logP(z(i)jr(x(i));a O
) O

= O
NX O
i=1KX O
j=1 logP(z(i O
) O
jjr(x(i));a O
) O
; O
assuming O
that O
the O
Kvariables O
in O
zare O
indepen- O
dent O
. O

Since O
the O
parameters O
used O
to O
construct O
rare O
Ô¨Åxed O
, O
the O
attacker O
only O
acts O
upon O
its O
own O
parame- O
tersato O
optimize O
this O
loss B-MetricName
. O

We O
use O
the O
performance O
of O
the O
attacker O
‚Äôs O
clas- O
siÔ¨Åer O
as O
a O
proxy O
for O
privacy O
. O

If O
its O
accuracy B-MetricName
is O
high O
, O
then O
an O
eavesdropper O
can O
easily O
recover O
in- O
formation O
about O
the O
input O
document O
. O

In O
contrast O
, O
if O
its O
accuracy B-MetricName
is O
low O
( O
i.e. O
close O
to O
that O
of O
a O
most- O
frequent O
label O
baseline O
) O
, O
then O
we O
may O
reasonably O
conclude O
that O
rdoes O
not O
encode O
enough O
informa- O
tion O
to O
reconstruct O
x O
, O
and O
mainly O
contains O
infor- O
mation O
that O
is O
useful O
to O
predict O
y. O
In O
general O
, O
the O
performance O
of O
a O
single O
attacker O
does O
not O
provide O
sufÔ¨Åcient O
evidence O
to O
conclude O
that O
the O
input O
representation O
ris O
robust O
to O
an O
at- O
tack O
. O

It O
should O
be O
robust O
to O
any O
type O
of O
reconstruc- O
tion O
method O
. O

In O
the O
scope O
of O
this O
paper O
though O
, O
we O
only O
experiment O
with O
a O
feedforward O
network O
reconstructor O
, O
i.e. O
a O
powerful O
learner O
. O

In O
the O
following O
sections O
, O
we O
propose O
several O
training O
method O
modiÔ¨Åcations O
aimed O
at O
obfuscat- O

ing O
private O
information O
from O
the O
hidden O
represen- O
tation O
r(x O
) O
. O

Intuitively O
, O
the O
aim O
of O
these O
modiÔ¨Åca- O
tions O
is O
to O
minimize O
some O
measure O
of O
information O
between O
randzto O
make O
the O
prediction O
of O
zhard O
. O

An O
obvious O
choice O
for O
that O
measure O
would O
be O
the O
Mutual B-MetricName
Information I-MetricName
( O
MI B-MetricName
) O
between O
randz O
. O

How- O
ever O
, O
MI B-MetricName
is O
hard O
to O
compute O
due O
to O
the O
continuous O
distribution O
of O
rand O
does O
not O
lend O
itself O
well O
to O
stochastic O
optimization. O

3 O
Defenses O
Against O
Adversarial O
Attacks O

In O
this O
section O
, O
we O
present O
three O
training O
methods O
designed O
as O
defenses O
against O
the O
type O
of O
attack O
we O
described O
in O
Section O
2.2 O
. O

The O
Ô¨Årst O
two O
methods O
are O
based O
on O
two O
neural O
networks O
with O
rival O
objective O
functions O
( O
Section O
3.1 O
) O
. O

The O
last O
method O
is O
meant O
at O
discouraging O
the O
model O
to O
cluster O
together O
train- O

ing O
examples O
with O
similar O
private O
variables O
z(Sec- O
tion O
3.2 O
) O
. O

3.1 O
Adversarial O
Training O
First O
, O
we O
propose O
to O
frame O
the O
training O
of O
the O
main O
classiÔ¨Åer O
as O
a O
two O
- O
agent O
process O
: O
the O
main O
agent O
and O
an O
adversarial O
generator O
, O
exploiting O
a O
set- O
ting O
similar O
to O
Generative B-MethodName
Adversarial I-MethodName
Networks I-MethodName
( O
GAN B-MethodName
, O
Goodfellow O
et O

al O
. O
, O
2014 O
) O
. O

The O
generator O
learns O
to O
reconstruct O
examples O
from O
the O
hidden O
representation O
, O
whereas O
the O
main O
agent O
learns O
( O
i O
) O
to O
perform O
its O
main O
task O
( O
ii O
) O
to O
make O
the O
task O
of O
the O
generator O
difÔ¨Åcult O
. O

We O
experiment O
with O
two O
types O
of O
generators O
: O
a O
classiÔ¨Åer O
that O
predicts O
the O
binary O
attributes O
z(x O
) O
used O
as O
a O
proxy O
for O
the O
reconstruction O
of O
x(Sec- O
tion O
3.1.1 O
) O
and O
a O
character O
- O
based O
language O
model O
that O
directly O
optimizes O
the O
likelihood O
of O
the O
train- O
ing O
examples O
( O
Section O
3.1.2 O
) O
. O

3.1.1 O
Adversarial B-TaskName
ClassiÔ¨Åcation I-TaskName
: O

Multidetasking O
In O
order O
not O
to O
make O
r(x)a O
good O
representation O
for O
reconstructing O
z O
, O
we O
make O
two O
modiÔ¨Åcations O
to O
the O
training O
setup O
of O
the O
main O
model O
( O
Phase O
1 O
): O
We O
use O
a O
duplicate O
adversarial O
classiÔ¨Åer O
, O
with O
parameters O
0 O
a O
, O
that O
tries O
to O
predict O
z O
from O
r(x O
) O
. O

It O
is O
trained O
simultaneously O
with O
the O
main O
classiÔ¨Åer O
. O

Its O
training O
examples O
are O
generated O
on O
the O
Ô¨Çy O
, O
and O
change O
overtime O
as O
the O
main O
classiÔ¨Åer O
updates O
its O
own O
parame- O
ters O
. O

This O
classiÔ¨Åer O
simulates O
an O
attack O
dur- O
ing O
training O
. O

We O
modify O
the O
objective O
function O
of O
the O
main O
classiÔ¨Åer O
to O
incorporate O
a O
penalty O
when O
the O
adversarial O
classiÔ¨Åer O
is O
good O
at O
reconstruct- O
ingz O
. O

In O
other O
words O
, O
the O
main O
classiÔ¨Åer O
tries O
to O
update O
its O
parameters O
so O
as O
to O
confuse O
the O
duplicate O
attacker O
. O

Formally O
, O
for O
a O
single O
data O
point O
( O
x;y;z O
) O
, O
the O
adversarial O
classiÔ¨Åer O
optimizes O
: O
La0(x;y;z;0 O
a)= logP(zjr(x);0 O
a O
) O
; O

4whereas O
the O
main O
classiÔ¨Åer O
optimizes O
: O
Lm(x;y;z;r;p)=  O

logP(yjx;r;p O
) O

  O

logP(:zjr(x);0 O
a O
): O
The O
Ô¨Årst O
term O
of O
this O
equation O
is O
the O
log O
- O
likelihood O
of O
theylabels O
. O

The O
second O
term O
is O
designed O
to O
de- O
ceive O
the O
adversary O
. O

The O
hyperparameters O

  O
> O
0 O
and O

  O
> O
0control O
the O
relative O
importance O
of O
both O
terms O
. O

As O
in O
a O
GAN O
, O
the O
losses O
of O
both O
classiÔ¨Åers O
are O
interdependent O
, O
but O
their O
parameters O
are O
distinct O
: O
the O
adversary O
can O
only O
update O
0 O
aand O
the O
main O
classiÔ¨Åer O
can O
only O
update O
randp O
. O

The O
duplicate O
adversarial O
classiÔ¨Åer O
is O
identical O
to O
the O
classiÔ¨Åer O
used O
to O
evaluate O
privacy O
after O
the O
main O
model O
has O
been O
trained O
and O
its O
parameters O
are O
Ô¨Åxed O
. O

However O
, O
both O
classiÔ¨Åers O
are O
completely O
distinct O
: O
the O
former O
is O
used O
during O
the O
training O
of O
the O
main O
model O
( O
Phase O
1 O
) O
to O
take O
privacy O
into O
ac- O
count O
whereas O
the O
latter O
is O
used O
to O
evaluate O
the O
pri- O
vacy O
of O
the O
Ô¨Ånal O
model O
( O
Phase O
3 O
) O
, O
as O
is O
described O
in O
Section O
2 O
. O

3.1.2 O
Adversarial O
Generation O

The O
second O
type O
of O
generator O
we O
use O
is O
a O
character- B-MethodName
based I-MethodName
LSTM I-MethodName
language O
model O
that O
is O
trained O
to O
re- O
construct O
full O
training O
examples O
. O

For O
a O
single O
ex- O
ample O
( O
x;y O
) O
, O
the O
hidden O
state O
of O
the O
LSTM O
is O
ini- O
tialized O
with O
r(x O
) O
, O
computed O
by O
the O
main O
model O
. O

The O
generator O
optimizes O
: O
Lg(x;y;`;r O
) O

= O
 logP(xjr(x); O
` O
) O
= O
 CX O
i=1logP(xijxi 1 O
1;r(x); O
` O
) O
; O
where O
`is O
the O
set O
of O
parameters O
of O
the O
LSTM O
generator O
, O
xiis O
theithcharacter O
in O
the O
document O
, O
and O
C B-HyperparameterName
is O
the O
length B-HyperparameterName
of I-HyperparameterName
the I-HyperparameterName
document I-HyperparameterName
in I-HyperparameterName
number I-HyperparameterName
of I-HyperparameterName
characters I-HyperparameterName
. O

The O
generator O
has O
no O
control O
over O
r(x O
) O
, O
and O
optimizes O
the O
objective O
only O
by O
updat- O
ing O
its O
own O
parameters O
 O
` O
. O

Conversely O
, O
the O
loss O
of O
the O
main O
model O
is O
modi- O
Ô¨Åed O
as O
follows O
: O

Lm(x;y;r;p)=  O

logP(yjx;r;p O
) O

  O

Lg(x;y;`;r O
): O

The O
Ô¨Årst O
term O
maximizes O
the O
likelihood O
of O
the O
y O
labels O
whereas O
the O
second O
term O
is O
meant O
at O
mak- O
ing O
the O
reconstruction O
difÔ¨Åcult O
by O
maximizing O
the O
loss O
of O
the O
generator O
. O

As O
in O
the O
loss O
function O
de- O
scribed O
in O
the O
previous O
section O
, O

and O

controlthe O
relative O
importance O
of O
both O
terms O
. O

Once O
again O
, O
the O
main O
classiÔ¨Åer O
can O
optimize O
the O
second O
term O
only O
by O
updating O
r O
, O
since O
it O
has O
no O
control O
over O
the O
parameters O
of O
the O
adversarial O
generator O
. O

A O
key O
property O
of O
this O
defense O
method O
is O
that O
it O
has O
no O
awareness O
of O
what O
the O
private O
variables O
z O
are O
. O

Therefore O
, O
it O
has O
the O
potential O
to O
protect O
the O
neural O
representation O
against O
an O
attack O
on O
any O
pri- O
vate O
information O
. O

From O
a O
broader O
perspective O
, O
the O
goal O
of O
this O
defense O
method O
is O
to O
specialize O
the O
hid- O
den O
representation O
r(x)to O
the O
task O
at O
hand O
( O
sen- B-TaskName
timent I-TaskName
or O
topic B-TaskName
prediction I-TaskName
) O
and O
to O
avoid O
learning O
anything O
not O
relevant O
to O
it O
. O

3.2 O

Declustering O
The O
last O
strategy O
we O
employ O
to O
make O
the O
task O
of O
the O
attacker O
harder O
is O
based O
on O
the O
intuition O
that O
pri- O
vate O
variables O
zare O
easier O
to O
predict O
from O
rwhen O
the O
main O
model O
learns O
implicitly O
to O
cluster O
exam- O
ples O
with O
similar O
zin O
the O
same O
regions O
of O
the O
rep- O
resentation O
space O
. O

In O
order O
to O
avoid O
such O
implicit O
clustering O
, O
we O
add O
a O
term O
to O
the O
training O
objective O
of O
the O
main O
model O
that O
penalizes O
pairs O
of O
examples O
( O
x;x0)that O
( O
i O
) O
have O
similar O
reconstructions O
z(x)z(x0)(ii O
) O
have O
hidden O
representations O
r(x)andr(x0)in O
the O
same O
region O
of O
space O
. O

We O
use O
the O
following O
modi- O
Ô¨Åed O
loss O
for O
a O
single O
example O
: O
Lm(x;y;z;r;p O
) O
= O
 logP(yjx;r;p O
) O

+ O

( O
0:5 `(z;z0))jjr(x) r(x0)jj2 O
2 O
; O
where O
( O
x0;z0)is O
another O
example O
sampled O
uni- O
formly O
from O
the O
training O
set O
, O

is O
a O
hyperparame- O
ter O
controlling O
the O
importance O
of O
the O
second O
term O
, O
and`(;)2[0;1]is O
the O
normalized O
Hamming O
dis- O
tance O
. O

4 O
Experiments O
Our O
experiments O
are O
meant O
to O
characterize O
the O
privacy B-MetricName
- I-MetricName
utility I-MetricName
tradeoff I-MetricName
of O
neural O
representations O
on O
text B-TaskName
classiÔ¨Åcation I-TaskName
tasks O
, O
and O
evaluating O
if O
the O
proposed O
defense O
methods O
have O
a O
positive O
im- O
pact O
on O
it O
. O

We O
Ô¨Årst O
describe O
the O
datasets O
we O
used O
( O
Section O
4.1 O
) O
and O
the O
experimental O
protocol O
( O
Section O
4.2 O
) O
, O
then O
we O
discuss O
the O
results O
( O
Sec- O
tion O
4.3 O
) O
. O

We O
found O
that O
in O
the O
normal O
train- O
ing O
regime O
, O
where O
no O
defense O
is O
taken O
into O
ac- O
count O
, O
the O
adversary O
can O
recover O
private O
informa- O
tion O
with O
higher O
accuracy O
than O
a O
most O
frequent O
class O
baseline O
. O

Furthermore O
, O
we O
found O
that O
the O
de- O
fenses O
we O
implemented O
have O
a O
positive O
effect O
on O
the O
accuracy B-MetricName
- I-MetricName
privacy I-MetricName
tradeoff I-MetricName
. O

4.1 O
Datasets O
We O
experiment O
with O
two O
text O
classiÔ¨Åcation O
tasks O
: O
sentiment B-TaskName
analysis I-TaskName
( O
Section O
4.1.1 O
) O
and O
topic B-TaskName
clas- I-TaskName
siÔ¨Åcation I-TaskName
( O
Section O
4.1.2 O
) O
. O

The O
sizes O
of O
each O
dataset O
are O
summarized O
in O
Table O
1 O
. O

4.1.1 O
Sentiment B-TaskName
Analysis I-TaskName
We O
use O
the O
Trustpilot B-DatasetName
dataset O
( O
Hovy O
et O
al O
. O
, O
2015 O
) O
for O
sentiment O
analysis O
. O

This O
corpus O
contains O
re- O
views O
associated O
with O
a O
sentiment O
score O
on O
a O
Ô¨Åve O
point O
scale O
, O
and O
self O
- O
reported O
information O
about O
the O
users O
. O

We O
use O
the O
Ô¨Åve O
subcorpora O
correspond- O
ing O
to O
Ô¨Åve O
areas O
( O
Denmark O
, O
France O
, O
Germany O
, O
United O
Kingdom O
, O
United O
States O
) O
. O

We O
Ô¨Ålter O
examples O
containing O
both O
the O
birth O
year O
and O
gender O
of O
the O
author O
of O
the O
review O
and O
use O
these O
variables O
as O
the O
private O
information O
. O

As O
in O
previous O
work O
on O
this O
dataset O
( O
Hovy O
, O
2015 O
; O
Hovy O
and O
S√∏gaard O
, O
2015 O
) O
, O
we O
bin O
the O
age O
of O
the O
author O
into O
two O
categories O
( O
‚Äò O
under O
35 O
‚Äô O
and O
‚Äò O
over O
45 O
‚Äô O
) O
. O

Fi- O
nally O
, O
we O
randomly O
split O
each O
subcorpus O
into O
a O
training O
set O
( O
80 O
% O
) O
, O
a O
development O
set O
( O
10 O
% O
) O
and O
a O
test O
( O
10 O
% O
) O
. O

As O
an O
additional O
experimental O
setting O
, O
we O
use O
both O
demographic O
variables O
( O
gender O
and O
age O
) O
as O
input O
to O
the O
main O
model O
. O

We O
do O
so O
by O
adding O
two O
additional O
tokens O
at O
the O
beginning O
of O
the O
input O
text O
, O
one O
for O
each O
variable O
. O

It O
has O
been O
shown O
that O
those O
variables O
can O
be O
used O
to O
improve O
text B-TaskName
classiÔ¨Åca- I-TaskName
tion I-TaskName
( O
Hovy O
, O
2015 O
) O
. O

Also O
, O
we O
would O
like O
to O
evalu- O
ate O
whether O
the O
attacker O
‚Äôs O
task O
is O
easier O
when O
the O
variables O
to O
predict O
are O
explicitly O
in O
the O
input O
, O
com- O
pared O
to O
when O
these O
information O
are O
only O
poten- O
tially O
and O
implicitly O
in O
the O
input O
. O

In O
other O
words O
, O
this O
setting O
simulates O
the O
case O
where O
private O
in O
- O
formation O
may O
be O
used O
by O
the O
model O
to O
improve O
classiÔ¨Åcation O
, O
but O
should O
not O
be O
exposed O
too O
obvi- O
ously O
. O

In O
the O
rest O
of O
this O
section O
, O
we O
use O
RAW O
to O
denote O
the O
setting O
where O
only O
the O
raw O
text O
is O
used O
as O
input O
and O
+ O
DEMO O
, O
the O
setting O
where O
the O
demo- O
graphic O
variables O
are O
also O
used O
as O
input O
. O

4.1.2 O
Topic B-TaskName
ClassiÔ¨Åcation I-TaskName
We O
perform O
topic B-TaskName
classiÔ¨Åcation I-TaskName
on O
two O
genres O
of O
documents O
: O
news O
articles O
and O
blog O
posts O
. O

News O
article O
For O
topic O
classiÔ¨Åcation O
of O
news O
ar- O
ticle O
, O
we O
use O
two O
datasets O
: O
the O
AG B-DatasetName
news I-DatasetName
corpus I-DatasetName
( O
Del O
Corso O
et O
al O
. O
, O
2005 O
) O
and O
the O
English O
part O
of O
the O
Deutsche B-DatasetName
Welle I-DatasetName
( O
DW B-DatasetName
) O
news O
corpus O
( O
Pappas O
and O
Popescu O
- O
Belis O
, O
2017 O
) O
. O

For O
the O
AG B-DatasetName
corpus I-DatasetName
, O
following O
Zhang O
et O
al O
. O
( O
2015 O
) O
, O
we O
construct O
the O
dataset O
by O
extracting O
doc- O
uments O
belonging O
to O
the O
four O
most O
frequent O
topics O
, O
and O
use O
the O
concatenation O
of O
the O
‚Äò O
title O
‚Äô O
and O
‚Äò O
de- O
scription O
‚Äô O
Ô¨Åelds O
as O
the O
input O
to O
the O
classiÔ¨Åer O
. O

We O
randomly O
split O
the O
corpus O
into O
a O
training O
set O
( O
80 O
% O
) O
, O
a O
development O
set O
( O
10 O
% O
) O
and O
a O
test O
set O
( O
10 O
% O
) O
. O

For O
the O
DW B-DatasetName
dataset O
, O
we O
use O
the O
‚Äò O
text O
‚Äô O
Ô¨Åeld O
as O
input O
, O
and O
the O
standard O
split O
. O

We O
kept O
only O
documents O
belonging O
to O
the O
20 O
most O
frequent O
topics O
. O

The O
attacker O
tries O
to O
detect O
which O
named O
enti- O
ties O
appear O
in O
the O
input O
text O
( O
each O
coefÔ¨Åcient O
in O
z(x)indicates O
whether O
a O
speciÔ¨Åc O
named O
entity O
oc- O
curs O
in O
the O
text O
) O
. O

For O
both O
datasets O
, O
we O
used O
the O
named O
entity O
recognition O
system O
from O
the O
NLTK O
package O
( O
Bird O
et O
al O
. O
, O
2009 O
) O
to O
associate O
each O
ex- O
ample O
with O
the O
list O
of O
named O
entities O
that O
occur O
in O
it O
. O

We O
select O
the O
Ô¨Åve O
most O
frequent O
named O
entities O
with O
type O
‚Äò O
person O
‚Äô O
, O
and O
only O
keep O
examples O
con- O
taining O
at O
least O
one O
of O
these O
named O
entities O
. O

This O
Ô¨Åltering O
is O
necessary O
to O
avoid O
a O
very O
unbalanced O
dataset O
( O
since O
each O
selected O
named O
entity O
appears O
usually O
in O
very O
few O
articles O
) O
. O

Blog O
posts O
We O
used O
the O
blog O
authorship O
corpus O
presented O
by O
Schler O
et O
al O
. O

( O
2006 O
) O
, O
a O
collection O
of O
blog O
posts O
associated O
with O
the O
age O
and O
gender O
of O
the O
authors O
, O
as O
provided O
by O
the O
authors O
themselves O
. O

Since O
the O
blog O
posts O
have O
no O
topic O
annotation O
, O
we O
ran O
the O
LDA O
algorithm O
( O
Blei O
et O
al O
. O
, O
2003 O
) O
on O
the O
whole O
collection O
( O
with O
10 O
topics O
) O
. O

The O
LDA O
out- O
puts O
a O
distribution O
on O
topics O
for O
each O
blog O
post O
. O

We O
selected O
posts O
with O
a O
single O
dominating O
topic O
( O
> O
80 O
% O
) O
and O
discarded O
the O
other O
posts O
. O

We O
binned O
age O
into O
two O
category O
( O
under O
20 O
and O
over O
30 O
) O
. O

We O
used O
the O
age O
and O
gender O
of O
the O
author O
as O
the O
private O
variables O
. O

These O
variables O
have O
a O
very O
unbalanced O
distribution O
in O
the O
dataset O
, O
we O
randomly O
select O
ex- O
amples O
to O
obtain O
uniform O
distributions O
of O
private O
variables O
. O

Finally O
, O
we O
split O
the O
corpus O
into O
a O
train- O
ing O
set O
( O
80 O
% O
) O
, O
a O
validation O
set O
and O
a O
test O
set O
( O
10 O
% O
each O
) O
. O

4.2 O
Protocol O
Evaluation O
For O
the O
main O
task O
, O
we O
report O
a O
single O
accuracy B-MetricName
measure O
. O

For O
measuring O
the O
privacy O
of O
a O
representation O
, O
we O
compute O
the O
following O
metrics O
: O
For O
demographic O
variables O
( O
sentiment B-TaskName
analy- I-TaskName
sis I-TaskName
and O
blog O
post O
topic B-TaskName
classiÔ¨Åcation I-TaskName
): O
1-X B-MetricName
, O
where O
X B-MetricName
is O
the B-MetricName
average I-MetricName
of I-MetricName
the I-MetricName
accuracy I-MetricName
of O
the O
attacker O
on O
the O
prediction O
of O
gender O
and O
age O
; O
For O
named O
entities O
( O
news O
topic B-TaskName
classiÔ¨Åca- I-TaskName
tion I-TaskName
): O
1-F B-MetricName
, O
where O
F B-MetricName
is O
an O
F B-MetricName
- O
score O
computed O
over O
the O
set O
of O
binary O
variables O
in O
zthat O
in- O
dicate O
the O
presence O
of O
named O
entities O
in O
the O
input O
example O
. O

Training O
protocol O
We O
implemented O
our O
model O
using O
Dynet B-MethodName
( O
Neubig O
et O
al O
. O
, O
2017 O
) O
. O

The O
feedfor- O
ward O
components O
( O
both O
of O
the O
main O
model O
and O
of O
the O
attacker O
) O
have O
a O
single O
hidden O
layer O
of O
64 B-HyperparameterValue
units O
with O
a O
ReLU O
activation O
. O

Word O
embeddings O
have O
32 B-HyperparameterValue
units O
. O

The O
LSTM O
encoder O
has O
a O
single O
layer O
of O
varying O
sizes O
, O
since O
it O
is O
expected O
that O
the O
amount O
of O
information O
that O
can O
be O
learned O
depends O
on O
the O
size O
of O
these O
representations O
. O

We O
used O
the O
Adam O
optimizer O
( O
Kingma O
and O
Ba O
, O
2014 O
) O
with O
the O
default O
learning B-HyperparameterName
rate I-HyperparameterName
, O
and O
0.2 B-HyperparameterValue
dropout B-HyperparameterName
rate I-HyperparameterName
for O
the O
LSTM O
. O

We O
used O
= O
0.1 B-HyperparameterValue
for O
the O
declustering O
method O
, O
based O
on O
preliminary O
experiments O
. O

For O
the O
other O
defense O
methods O
, O
we O
used O
= O
= O
1 B-HyperparameterValue
and O
did O
not O
experiment O
with O
other O
values O
. O

For O
each O
dataset O
, O
and O
each O
LSTM B-HyperparameterName
state I-HyperparameterName
di- I-HyperparameterName
mension I-HyperparameterName
( O
f O
8 B-HyperparameterValue
, O
16 B-HyperparameterValue
, O
32 B-HyperparameterValue
, O
64 B-HyperparameterValue
, O
128 B-HyperparameterValue
g O
) O
, O
we O
train O
the O
main O
model O
for O
8 B-HyperparameterValue
epochs B-HyperparameterName
( O
sentiment B-TaskName
classiÔ¨Åcation I-TaskName
) O
or O
16 B-HyperparameterValue
epochs B-HyperparameterName
( O
topic B-TaskName
classiÔ¨Åcation I-TaskName
) O
, O
and O
select O
the O
model O
with O
the O
best O
accuracy B-MetricValue
on O
the O
development O
set O
. O

Then O
, O
we O
generate O
the O
dataset O
for O
the O
attacker O
, O
train O
the O
adversarial O
model O
for O
16 O
epochs O
and O
se- O
lect O
the O
model O
with O
the O
worst O
privacy O
on O
the O
devel- O
opment O
set O
( O
i.e. O
the O
most O
successful O
attacker O
) O
. O

It O
has O
to O
be O
noted O
that O
we O
select O
the O
models O
that O
implement O
defenses O
on O
their O
accuracy O
, O
rather O
than O
their O
privacy O
or O
a O
combination O
thereof O
. O

In O
prac- O
tice O
, O
we O
could O
also O
base O
the O
selection O
strategy O
on O
a O
privacy O
budget O
: O
selecting O
the O
most O
accurate O
model O
with O
privacy O
above O
a O
certain O
threshold O
. O

4.3 O
Results O
This O
section O
discusses O
results O
for O
the O
sentiment O
analysis O
task O
( O
Section O
4.3.1 O
) O
and O
the O
topic B-TaskName
classi- I-TaskName
Ô¨Åcation I-TaskName
task O
( O
Section O
4.3.2 O
) O
. O

4.3.1 O
Sentiment B-TaskName
Analysis I-TaskName
How O
private O
are O
neural O
representations O
? O

Be- O
fore O
discussing O
the O
effect O
of O
proposed O
defense O
methods O
, O
we O
motivate O
empirically O
our O
approach O
by O
showing O
that O
adversarial O
models O
can O
recover O
pri- O
vate O
information O
with O
reasonable O
accuracy O
when O
the O
attack O
is O
targeted O
towards O
a O
model O
that O
imple- O
ments O
none O
of O
the O
presented O
defense O
methods O
. O

To O
do O
so O
, O
we O
compare O
the O
accuracy B-MetricName
of O
adversar- O
ial O
models O
to O
two O
types O
of O
baselines O
: O
As O
a O
lower O
bound O
, O
we O
use O
the O
most O
frequent O
class O
baseline O
. O

As O
an O
upper O
bound O
, O
we O
trained O
a O
classi- O
Ô¨Åer O
that O
can O
optimize O
the O
hidden O
represen- O
tations O
( O
r O
) O
for O
the O
attacker O
‚Äôs O
tasks O
. O

In O
other O
words O
, O
this O
baseline O
is O
trained O
to O
predict O
de- O
mographic O
variables O
from O
x O
, O
as O
if O
it O
were O
the O
main O
task O
. O

In O
Table O
2 O
, O
we O
compare O
both O
baselines O
to O
the O
best O
adversary O
in O
the O
two O
settings O
( O
RAW O
and O
+ O
DEMO O
) O
among O
the O
models O
trained O
with O
no O
de- O
fenses O
. O

First O
of O
all O
, O
we O
observe O
that O
apart O
from O
gender O
on O
the O
German O
dataset O
, O
the O
trained O
baseline O
outperforms O
the O
most O
frequent O
class O
baseline O
by O
a O
wide O
margin O
( O
8 O
to O
25 O
absolute O
difference O
) O
. O

Sec- O
ond O
of O
all O
, O
the O
attacker O
is O
able O
to O
outperform O
the O
most O
frequent O
class O
baseline O
overall O
, O
even O
in O
the O
RAW O
setting O
. O

In O
more O
details O
, O
for O
age O
, O
the O
adver- O
sary O
is O
well O
over O
the O
baseline O
in O
all O
cases O
except O
US O
. O

On O
the O
other O
hand O
, O
gender O
seems O
harder O
to O
predict O
: O
the O
adversary O
outperforms O
the O
most O
fre- O
quent O
class O
baseline O
only O
in O
the O
+ O
DEMO O
setting O
. O

The O
same O
pattern O
is O
visible O
for O
the O
blog O
post O
dataset O
, O
also O
presented O
in O
the O
last O
line O
of O
Table O
2 O
: O
the O
best O
adversaries O
are O
14 B-MetricValue
points O
over O
the O
base- O
line O
for O
gender O
and O
5 B-MetricValue
points O
for O
age O
, O
i.e. O
almost O
as O
good O
as O
a O
model O
that O
can O
Ô¨Åne O
tune O
the O
hidden O
representations O
. O

These O
results O
justify O
our O
approach O
, O
since O
they O
demonstrate O
that O
hidden O
representations O
learn O
pri- O
vate O
information O
about O
the O
input O
, O
and O
can O
be O
ex- O
ploited O
to O
recover O
this O
information O
with O
reasonable O
accuracy B-MetricName
. O

Effect O
of O
defenses O
We O
report O
results O
for O
the O
main O
task O
accuracy O
and O
the O
representation O
privacy O
in O
Ta- O
ble O
3 O
for O
the O
+ O
DEMO O
setting O
and O
in O
Table O
4 O
for O
the O
RAW O
setting O
. O

Recall O
that O
the O
privacy O
measure O
( O
Priv O
. O
) O
is O
computed O
by O
1-X B-MetricName
where O
X B-MetricName
is O
the O
av- B-MetricName
erage I-MetricName
accuracy I-MetricName
of O
the O
attacker O
on O
gender O
and O
age O
predictions O
. O

When O
this O
privacy O
metric O
is O
higher O
, O
it O
is O
more O
difÔ¨Åcult O
to O
exploit O
the O
hidden O
repre- O
sentation O
of O
the O
network O
to O
recover O
information O
about O
x O
. O

The O
‚Äò O
Standard O
‚Äô O
columns O
contain O
the O
ac- B-MetricName
curacy I-MetricName
and O
privacy O
of O
the O
base O
model O
described O
in O
Section O
2 O
. O

The O
next O
columns O
present O
the O
abso- O
lute O
variation O
in O
accuracy B-MetricName
and O
privacy O
for O
the O
three O
defense O
methods O
presented O
in O
Section O
3 O
: O
Multi- O
detasking O
, O
Adversarial O
Generation O
, O
and O
Decluster- O
ing O
. O

We O
also O
report O
for O
each O
corpus O
the O
most O
fre- O
quent O
class O
baseline O
for O
the O
main O
task O
accuracy O
, O
and O
the O
privacy O
of O
the O
most O
frequent O
class O
base- O
lines O
on O
private O
variables O
( O
i.e. O
the O
upper O
bound O
for O
privacy O
) O
. O

The O
three O
modiÔ¨Åed O
training O
methods O
designed O
as O
defenses O
have O
a O
positive O
effect O
on O
privacy O
. O

De- O
spite O
a O
model O
selection O
based O
on O
accuracy B-MetricName
, O
they O
lead O
to O
an O
improvement O
in O
privacy O
on O
all O
datasets O
, O
except O
on O
the O
France O
subcorpus O
. O

In O
most O
cases O
, O
we O
observe O
only O
a O
small O
decrease O
in O
accuracy B-MetricName
, O
or O
even O
an O
improvement O
at O
times O
( O
e.g. O
multidetasking O
on O
the O
Germany O
dataset O
, O
RAW O
setting O
) O
, O
thus O
improv- O
ing O
the O
tradeoff O
between O
the O
utility O
and O
the O
privacy O
of O
the O
text O
representations O
. O

84.3.2 O
Topic B-TaskName
ClassiÔ¨Åcation I-TaskName
We O
report O
results O
on O
topic B-TaskName
classiÔ¨Åcation I-TaskName
in O
Table O
5 O
. O

News O
articles O
For O
the O
news O
corpora O
, O
the O
privacy B-MetricName
metric O
is O
based O
on O
the O
F B-MetricName
- O
score O
on O
the O
binary O
vari- O
ables O
zindicating O
the O
presence O
or O
absence O
of O
a O
named O
entity O
in O
the O
text O
. O

First O
of O
all O
, O
we O
ob- O
serve O
that O
defense O
methods O
that O
explicitly O
use O
z O
( O
i.e. O
multidetasking O
and O
declustering O
) O
, O
have O
a O
very O
positive O
effect O
on O
privacy O
, O
but O
also O
a O
detrimental O
effect O
on O
the O
main O
task O
. O

We O
hypothesize O
that O
this O
is O
due O
to O
the O
strong O
correlations O
between O
the O
main O
task O
labelsyand O
the O
private O
information O
z. O

As O
a O
result O
, O
improving O
the O
privacy O
of O
the O
neural O
repre- O
sentations O
comes O
at O
a O
cost O
in O
accuracy B-MetricName
. O

In O
contrast O
, O
the O
adversarial O
generation O
defense O
method O
lead O
to O
an O
improvement O
in O
accuracy B-MetricName
, O
that O
is O
quite O
substantial O
for O
the O
DW B-DatasetName
corpus O
. O

We O
specu- O
late O
that O
this O
is O
due O
to O
the O
secondary O
term O
in O
the O
ob- O
jective O
function O
of O
the O
main O
model O
( O
Section O
3.1.2 O
) O
that O
helps O
avoiding O
overÔ¨Åtting O
the O
main O
task O
or O
learning O
spurious O
features O
. O

Blog O
posts O
On O
the O
blog O
post O
dataset O
, O
the O
effects O
are O
smaller O
, O
which O
we O
attribute O
to O
the O
nature O
of O
the O
task O
of O
the O
attacker O
. O

The O
defense O
methods O
con- O
sistently O
improve O
privacy O
and O
, O
in O
one O
case O
, O
accu- O
racy O
. O

The O
best O
effects O
on O
the O
tradeoff O
are O
achieved O
with O
the O
multidetasking O
and O
adversarial O
generation O
methods O
. O

5 O
Discussion O
The O
main O
result O
of O
our O
experiments O
is O
that O
the O
de- O
fenses O
we O
propose O
improve O
privacy O
with O
usually O
a O
small O
effect O
, O
either O
positive O
or O
negative O
, O
on O
accu- B-MetricName
racy I-MetricName
, O
thus O
improving O
the O
tradeoff O
between O
the O
util- O
ity O
and O
the O
privacy O
of O
neural O
representations O
. O

An O
important O
direction O
for O
future O
work O
is O
the O
choice O
of O
a O
strategy O
for O
model O
selection O
. O

The O
tradeoff O
between O
utility O
and O
privacy O
can O
be O
con- O
trolled O
in O
many O
ways O
. O

For O
example O
, O
the O
impor- O
tance O
of O
both O
terms O
in O
the O
loss O
functions O
in O
Sec- O
tion O
3.1 O
can O
be O
controlled O
to O
favor O
either O
privacy O
or O
utility O
. O

In O
the O
scope O
of O
this O
paper O
, O
we O
did O
not O
perform O
thorough O
hyperparameter O
tuning O
, O
but O
be- O
lieve O
that O
doing O
so O
is O
important O
for O
achieving O
better O
results O
, O
since O
the O
effects O
of O
defense O
method O
can O
be O
more O
drastic O
than O
desired O
in O
some O
cases O
, O
as O
exem- O
pliÔ¨Åed O
on O
the O
news O
corpora O
( O
Table O
5 O
) O
. O

Overall O
, O
we O
found O
that O
the O
multidetasking O
ap- O
proach O
lead O
to O
the O
more O
stable O
improvements O
and O
should O
be O
preferred O
in O
most O
cases O
, O
since O
it O
is O
alsothe O
less O
computationnally O
expensive O
defense O
. O

On O
the O
other O
hand O
, O
the O
adversarial O
generation O
method O
does O
not O
require O
the O
speciÔ¨Åcation O
of O
private O
vari- O
ables O
, O
and O
thus O
is O
a O
more O
general O
approach O
. O

6 O
Related O
Work O
The O
deployment O
of O
machine O
learning O
in O
both O
academic O
and O
industrial O
contexts O
raises O
concerns O
about O
adversarial O
uses O
of O
machine O
learning O
, O
as O
well O
as O
concerns O
about O
attacks O
speciÔ¨Åcally O
targeted O
at O
these O
algorithms O
that O
often O
rely O
on O
large O
amounts O
of O
data O
, O
including O
personal O
data O
. O

More O
generally O
, O
the O
framework O
of O
differential O
privacy O
( O
Dwork O
, O
2006 O
) O
provides O
privacy O
guaran- O
tees O
for O
the O
problem O
of O
releasing O
information O
with- O
out O
compromising O
conÔ¨Ådential O
data O
, O
and O
usually O
involves O
adding O
noise O
in O
the O
released O
information O
. O

It O
has O
been O
applied O
to O
the O
training O
of O
deep O
learning O
models O
( O
Abadi O
et O
al O
. O
, O
2016 O
; O

Papernot O
et O
al O
. O
, O
2016 O
; O
Papernot O
et O
al O
. O
, O
2018 O
) O
, O
and O
Bayesian O
topic O
models O
( O
Schein O
et O
al O
. O
, O
2018 O
) O
. O

The O
notion O
of O
privacy O
is O
particularly O
crucial O
to O
NLP O
, O
since O
it O
deals O
with O
textual O
data O
, O
oftentimes O
user O
- O
generated O
data O
, O
that O
contain O
a O
lot O
of O
private O
in- O
formation O
. O

For O
example O
, O
textual O
data O
contain O
a O
lot O
of O
signal O
about O
authors O
( O
Hovy O
and O
Spruit O
, O
2016 O
) O
. O

and O
can O
be O
leveraged O
to O
predict O
demographic O
vari- O
ables O
( O
Rosenthal O
and O
McKeown O
, O
2011 O
; O
Preot O
¬∏iuc- O
Pietro O
et O
al O
. O
, O
2015 O
) O
. O

Oftentimes O
, O
this O
information O
is O
not O
explicit O
in O
the O
text O
but O
latent O
and O
related O
to O
the O
usage O
of O
various O
linguistic O
traits O
. O

Our O
work O
is O
based O
on O
a O
stronger O
hypothesis O
: O
this O
latent O
infor- O
mation O
is O
still O
present O
in O
vectorial O
representations O
of O
texts O
, O
even O
if O
the O
representations O
have O
not O
been O
supervised O
by O
these O
latent O
variables O
. O

Li O
et O
al O
. O

( O
2017 O
) O
study O
the O
privacy O
of O
unsuper- O
vised O
representations O
of O
images O
, O
and O
measures O
their O
privacy O
with O
the O
peak O
signal O
to O
noise O
ratio O
between O
an O
original O
image O
and O
its O
reconstruction O
by O
an O
attacker O
. O

They O
Ô¨Ånd O
a O
tradeoff O
between O
the O
privacy O
of O
the O
learned O
representations O
and O
the O
ac- O
curacy O
of O
an O
image O
classiÔ¨Åcation O
model O
that O
uses O
these O
representations O
as O
inputs O
. O

Our O
setting O
is O
complementary O
since O
it O
is O
applied O
to O
NLP O
tasks O
, O
but O
explores O
a O
similar O
problem O
in O
the O
case O
of O
rep- O
resentations O
learned O
with O
a O
task O
supervision O
. O

A O
related O
problem O
is O
the O
unintended O
memoriza- O
tion O
of O
private O
data O
from O
the O
training O
set O
and O
has O
been O
addressed O
by O
Carlini O
et O
al O
. O

( O
2018 O
) O
. O

They O
tackle O
this O
problem O
in O
the O
context O
of O
text O
gener- O
ation O
( O
machine B-TaskName
translation I-TaskName
, O
language B-TaskName
modelling I-TaskName
) O
. O

If O
an O
attacker O
has O
access O
to O
e.g. O
a O
trained O
language O
model O
, O
they O
are O
likely O
to O
be O
able O
to O
generate O
sen- O
tences O
from O
the O
training O
set O
, O
since O
the O
language O
model O
is O
trained O
to O
assign O
high O
probabilities O
to O
those O
sentences O
. O

Such O
memorization O
is O
problem- O
atic O
when O
the O
training O
data O
contains O
private O
infor- O
mation O
and O
personal O
data O
. O

The O
experimental O
set- O
ting O
we O
explore O
is O
different O
from O
these O
works O
: O
we O
assume O
that O
the O
attacker O
has O
access O
to O
a O
hidden O
layer O
of O
the O
network O
and O
tries O
to O
recover O
informa- O
tion O
about O
an O
input O
example O
that O
is O
not O
in O
the O
train- O
ing O
set O
. O

In O
a O
recent O
study O
, O
Li O
et O
al O
. O

( O
2018 O
) O
proposed O
a O
method O
based O
on O
GAN O
designed O
to O
improve O
the O
robustness O
and O
privacy O
of O
neural O
representations O
, O
applied O
to O
part B-TaskName
- I-TaskName
of I-TaskName
- I-TaskName
speech I-TaskName
tagging I-TaskName
and O
sentiment B-TaskName
analysis I-TaskName
. O

They O
use O
a O
training O
scheme O
with O
two O
agents O
similar O
to O
our O
multidetasking O
strategy O
( O
Sec- O
tion O
3.1.1 O
) O
, O
and O
found O
that O
it O
made O
neural O
represen- O
tations O
more O
robust O
and O
accurate O
. O

However O
, O
they O
only O
use O
a O
single O
adversary O
to O
alter O
the O
training O
of O
the O
main O
model O
and O
to O
evaluate O
the O
privacy O
of O
the O
representations O
, O
with O
the O
risk O
of O
overestimat- O
ing O
privacy O
. O

In O
contrast O
, O
once O
the O
parameters O
of O
our O
main O
model O
are O
Ô¨Åxed O
, O
we O
train O
a O
new O
classiÔ¨Åer O
from O
scratch O
to O
evaluate O
privacy O
. O

7 O
Conclusion O
We O
have O
presented O
an O
adversarial O
scenario O
and O
used O
it O
to O
measure O
the O
privacy O
of O
hidden O
repre- O
sentations O
in O
the O
context O
of O
two O
NLP O
tasks O
: O
senti- B-TaskName
ment I-TaskName
analysis I-TaskName
and O
topic B-TaskName
classiÔ¨Åcation I-TaskName
of O
news O
arti- O
cle O
and O
blog O
posts O
. O

We O
have O
shown O
that O
in O
general O
, O
it O
is O
possible O
for O
an O
attacker O
to O
recover O
private O
vari- O
ables O
with O
higher O
than O
chance O
accuracy O
, O
using O
only O
hidden O
representations O
. O

In O
order O
to O
improve O
the O
privacy O
of O
hidden O
representations O
, O
we O
have O
pro- O
posed O
defense O
methods O
based O
on O
modiÔ¨Åcations O
of O
the O
training O
objective O
of O
the O
main O
model O
. O

Empiri- O
cally O
, O
the O
proposed O
defenses O
lead O
to O
models O
with O
a O
better O
privacy O
. O

Acknowledgments O
We O
thank O
the O
anonymous O
reviewers O
and O
members O
of O
the O
Cohort O
for O
helpful O
feedback O
on O
previous O
ver- O
sions O
of O
the O
article O
. O

We O
gratefully O
acknowledge O
the O
support O
of O
the O
European O
Union O
under O
the O
Horizon O
2020 O
SUMMA O
project O
( O
grant O
agreement O
688139 O
) O
, O
and O
the O
support O
of O
Huawei O
Technologies O
. O

References O
Martin O
Abadi O
, O
Andy O
Chu O
, O
Ian O
Goodfellow O
, O
H. O
Bren- O
dan O
McMahan O
, O
Ilya O
Mironov O
, O
Kunal O
Talwar O
, O
and O
Li O
Zhang O
. O

2016 O
. O

Deep O
learning O
with O
differential O
pri- O
vacy O
. O

In O
Proceedings O
of O
the O
2016 O
ACM O
SIGSAC O
Conference O
on O
Computer O
and O
Communications O
Se- O
curity O
, O
CCS O
‚Äô O
16 O
, O
pages O
308‚Äì318 O
, O
New O
York O
, O
NY O
, O
USA O
. O
ACM O
. O

Steven O
Bird O
, O
Ewan O
Klein O
, O
and O
Edward O
Loper O
. O
2009 O
. O

Natural O
Language O
Processing O
with O
Python O
, O
1st O
edi- O
tion O
. O

O‚ÄôReilly O
Media O
, O
Inc. O
David O
M. O
Blei O
, O
Andrew O
Y O
. O

Ng O
, O
and O
Michael O
I. O
Jordan O
. O

2003 O
. O

Latent O
dirichlet O
allocation O
. O

Journal O
of O
Ma- O
chine O

Learning O
Research O
, O
3:993‚Äì1022 O
. O

Nicholas O
Carlini O
, O
Chang O
Liu O
, O
Jernej O
Kos O
, O
¬¥ O
Ulfar O
Erlings- O
son O
, O
and O
Dawn O
Song O
. O

2018 O
. O

The B-MethodName
secret I-MethodName
sharer I-MethodName
: O
Mea- O
suring O
unintended O
neural O
network O
memorization O
& O
extracting O
secrets O
. O

CoRR O
, O
abs/1802.08232 O
. O

Gianna O
M. O
Del O
Corso O
, O
Antonio O
Gull O
¬¥ O
ƒ± O
, O
and O
Francesco O
Romani O
. O

2005 O
. O

Ranking O
a O
stream O
of O
news O
. O

In O
Pro- O
ceedings O
of O
the O
14th O
International O
Conference O
on O
World O
Wide O
Web O
, O
WWW O
‚Äô O
05 O
, O
pages O
97‚Äì106 O
, O
New O
York O
, O
NY O
, O
USA O
. O
ACM O
. O

Cynthia O
Dwork O
. O

2006 O
. O

Differential O
privacy O
. O

In O
33rd O
International O
Colloquium O
on O
Automata O
, O
Languages O
and O
Programming O
, O
part O
II O
( O
ICALP O
2006 O
) O
, O
volume O
4052 O
, O
pages O
1‚Äì12 O
, O
Venice O
, O
Italy O
. O

Springer O
Verlag O
. O

Ian O
Goodfellow O
, O
Jean O
Pouget O
- O
Abadie O
, O
Mehdi O
Mirza O
, O
Bing O
Xu O
, O
David O
Warde O
- O
Farley O
, O
Sherjil O
Ozair O
, O
Aaron O
Courville O
, O
and O
Yoshua O
Bengio O
. O

2014 O
. O

Generative O
adversarial O
nets O
. O

In O
Z. O
Ghahramani O
, O
M. O
Welling O
, O
C. O
Cortes O
, O
N. O
D. O
Lawrence O
, O
and O
K. O
Q. O
Weinberger O
, O
editors O
, O
Advances O
in O
Neural O
Information O
Processing O
Systems O
27 O
, O
pages O
2672‚Äì2680 O
. O

Curran O
Associates O
, O
Inc. O

Sepp O
Hochreiter O
and O
J O
¬®urgen O
Schmidhuber O
. O

1997 O
. O

Long O
short O
- O
term O
memory O
. O

Neural O
computation O
, O
9(8):1735‚Äì1780 O
. O

Dirk O
Hovy O
. O
2015 O
. O

Demographic O
factors O
improve O
clas- O
siÔ¨Åcation O
performance O
. O

In O
Proceedings O
of O
the O
53rd O
Annual O
Meeting O
of O
the O
Association O
for O
Computa- O
tional O
Linguistics O
and O
the O
7th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
( O
Vol- O
ume O
1 O
: O
Long O
Papers O
) O
, O
pages O
752‚Äì762 O
, O
Beijing O
, O
China O
. O

Association O
for O
Computational O
Linguistics O
. O

Dirk O
Hovy O
, O
Anders O
Johannsen O
, O
and O
Anders O
S√∏gaard O
. O

2015 O
. O

User O
review O
sites O
as O
a O
resource O
for O
large- O
scale O
sociolinguistic O
studies O
. O

In O
Proceedings O
of O
the O
24th O
International O
Conference O
on O
World O
Wide O
Web O
, O
WWW O
‚Äô O
15 O
, O
pages O
452‚Äì461 O
, O
Republic O
and O
Canton O
of O
Geneva O
, O
Switzerland O
. O

International O
World O
Wide O
Web O
Conferences O
Steering O
Committee O
. O

Dirk O
Hovy O
and O
Anders O
S√∏gaard O
. O

2015 O
. O

Tagging O
perfor- O
mance O
correlates O
with O
author O
age O
. O

In O
Proceedings O
of O
the O
53rd O
Annual O
Meeting O
of O
the O
Association O
for O

10Computational O
Linguistics O
and O
the O
7th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
( O
Volume O
2 O
: O
Short O
Papers O
) O
, O
pages O
483‚Äì488 O
, O
Beijing O
, O
China O
. O
Association O
for O
Computational O
Linguistics O
. O

Dirk O
Hovy O
and O
Shannon O
L. O
Spruit O
. O

2016 O
. O

The O
social O
impact O
of O
natural O
language O
processing O
. O

In O
Proceed- O
ings O
of O
the O
54th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
( O
Volume O
2 O
: O
Short O
Pa- O
pers O
) O
, O
pages O
591‚Äì598 O
, O
Berlin O
, O
Germany O
. O

Association O
for O
Computational O
Linguistics O
. O

Diederik O
P. O
Kingma O
and O
Jimmy O
Ba O
. O
2014 O
. O

Adam O
: O
A O
method O
for O
stochastic O
optimization O
. O

CoRR O
, O
abs/1412.6980 O
. O

Meng O
Li O
, O
Liangzhen O
Lai O
, O
Naveen O
Suda O
, O
Vikas O
Chan- O
dra O
, O
and O
David O
Z. O
Pan O
. O
2017 O
. O
Privynet B-MethodName
: O
A B-MethodName
Ô¨Çexible I-MethodName
framework I-MethodName
for I-MethodName
privacy I-MethodName
- I-MethodName
preserving I-MethodName
deep I-MethodName
neural I-MethodName
net- I-MethodName
work I-MethodName
training I-MethodName
with I-MethodName
A I-MethodName
Ô¨Åne I-MethodName
- I-MethodName
grained I-MethodName
privacy I-MethodName
control I-MethodName
. O

CoRR O
, O
abs/1709.06161 O
. O

Yitong O
Li O
, O
Timothy O
Baldwin O
, O
and O
Trevor O
Cohn O
. O

2018 O
. O

Towards O
robust O
and O
privacy O
- O
preserving O
text O
repre- O
sentations O
. O

In O
Proceedings O
of O
the O
56th O
Annual O
Meet- O
ing O
of O
the O
Association O
for O
Computational O
Linguistics O
( O
Volume O
2 O
: O
Short O
Papers O
) O
, O
pages O
25‚Äì30 O
, O
Melbourne O
, O
Australia O
. O

Association O
for O
Computational O
Linguis- O
tics O
. O

Graham O
Neubig O
, O
Chris O
Dyer O
, O
Yoav O
Goldberg O
, O
Austin O
Matthews O
, O
Waleed O
Ammar O
, O
Antonios O
Anastasopou- O
los O
, O
Miguel O
Ballesteros O
, O
David O
Chiang O
, O
Daniel O
Clothiaux O
, O
Trevor O
Cohn O
, O
Kevin O
Duh O
, O
Manaal O
Faruqui O
, O
Cynthia O
Gan O
, O
Dan O
Garrette O
, O
Yangfeng O
Ji O
, O
Lingpeng O
Kong O
, O
Adhiguna O
Kuncoro O
, O
Gaurav O
Ku- O
mar O
, O
Chaitanya O
Malaviya O
, O
Paul O
Michel O
, O
Yusuke O
Oda O
, O
Matthew O
Richardson O
, O
Naomi O
Saphra O
, O
Swabha O
Swayamdipta O
, O
and O
Pengcheng O
Yin O
. O
2017 O
. O
Dynet B-MethodName
: O
The B-MethodName
dynamic I-MethodName
neural I-MethodName
network I-MethodName
toolkit I-MethodName
. O

arXiv O
preprint O
arXiv:1701.03980 O
. O

Nicolas O
Papernot O
, O
Mart O
¬¥ O
ƒ±n O
Abadi O
, O
¬¥ O
Ulfar O
Erlingsson O
, O
Ian O
J. O
Goodfellow O
, O
and O
Kunal O
Talwar O
. O

2016 O
. O

Semi- O
supervised O
knowledge O
transfer O
for O
deep O
learning O
from O
private O
training O
data O
. O

CoRR O
, O
abs/1610.05755 O
. O

Nicolas O
Papernot O
, O
Shuang O
Song O
, O
Ilya O
Mironov O
, O
Ananth O
Raghunathan O
, O
Kunal O
Talwar O
, O
and O
¬¥ O
Ulfar O
Erlingsson O
. O

2018 O
. O

Scalable O
Private O
Learning O
with O
PATE B-MethodName
. O

ArXiv O
e O

-prints O
, O
abs/1802.08908 O
. O

Nikolaos O
Pappas O
and O
Andrei O
Popescu O
- O
Belis O
. O

2017 O
. O

Multilingual O
hierarchical O
attention O
networks O
for O
doc- O
ument O
classiÔ¨Åcation O
. O

In O
Proceedings O
of O
the O
Eighth O
International O
Joint O
Conference O
on O
Natural O
Lan- O
guage O
Processing O
( O
Volume O
1 O
: O
Long O
Papers O
) O
, O
pages O
1015‚Äì1025 O
, O
Taipei O
, O
Taiwan O
. O

Asian O
Federation O
of O
Natural O
Language O
Processing O
. O

Daniel O
Preot O
¬∏iuc O
- O
Pietro O
, O
Vasileios O
Lampos O
, O
and O
Niko- O
laos O
Aletras O
. O

2015 O
. O

An O
analysis O
of O
the O
user O
occupa- O
tional O
class O
through O
twitter O
content O
. O

In O
Proceedings O
of O
the O
53rd O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
and O
the O
7th O
InternationalJoint O
Conference O
on O
Natural O
Language O
Processing O
( O
Volume O
1 O
: O
Long O
Papers O
) O
, O
pages O
1754‚Äì1764 O
, O
Bei- O
jing O
, O
China O
. O

Association O
for O
Computational O
Linguis- O
tics O
. O

Sara O
Rosenthal O
and O
Kathleen O
McKeown O
. O
2011 O
. O

Age O
prediction O
in O
blogs O
: O
A O
study O
of O
style O
, O
content O
, O
and O
online O
behavior O
in O
pre- O
and O
post O
- O
social O
media O
gen- O
erations O
. O

In O
Proceedings O
of O
the O
49th O
Annual O
Meet- O
ing O
of O
the O
Association O
for O
Computational O
Linguis- O

tics O
: O
Human O
Language O
Technologies O
, O
pages O
763 O
‚Äì O
772 O
, O
Portland O
, O
Oregon O
, O
USA O
. O
Association O
for O
Com- O
putational O
Linguistics O
. O

Aaron O
Schein O
, O
Zhiwei O
Steven O
Wu O
, O
Mingyuan O
Zhou O
, O
and O
Hanna O
Wallach O
. O

2018 O
. O

Locally O
Private O
Bayesian O
Inference O
for O
Count O
Models O
. O

ArXiv O
e O
- O
prints O
, O
abs/1803.08471 O
. O

Jonathan O
Schler O
, O
Moshe O
Koppel O
, O
Shlomo O
Argamon O
, O
and O
James O
Pennebaker O
. O

2006 O
. O

Effects O
of O
age O
and O
gender O
on O
blogging O
. O

In O
Computational O
Approaches O
to O
Analyzing O
Weblogs O
- O
Papers O
from O
the O
AAAI O
Spring O
Symposium O
, O
Technical O
Report O
, O
volume O
SS-06 O
- O
03 O
, O
pages O
191‚Äì197 O
. O

Yequan O
Wang O
, O
Minlie O
Huang O
, O
Xiaoyan O
Zhu O
, O
and O
Li O
Zhao O
. O

2016 O
. O

Attention O
- O
based O
LSTM O
for O
aspect- O
level O
sentiment B-TaskName
classiÔ¨Åcation I-TaskName
. O

In O
Proceedings O
of O
the O
2016 O
Conference O
on O
Empirical O
Methods O
in O
Natu- O
ral O
Language O
Processing O
, O
pages O
606‚Äì615 O
, O
Austin O
, O
Texas O
. O

Association O
for O
Computational O
Linguistics O
. O

Xiang O
Zhang O
, O
Junbo O
Zhao O
, O
and O
Yann O
LeCun O
. O
2015 O
. O

Character O
- O
level O
convolutional O
networks O
for O
text O
clas- O
siÔ¨Åcation O
. O

In O
C. O
Cortes O
, O
N. O
D. O
Lawrence O
, O
D. O
D. O
Lee O
, O
M. O
Sugiyama O
, O
and O
R. O
Garnett O
, O
editors O
, O
Advances O
in O
Neural O
Information O
Processing O
Systems O
28 O
, O
pages O
649‚Äì657 O
. O

Curran O
Associates O
, O
Inc. O

Peng O
Zhou O
, O
Zhenyu O
Qi O
, O
Suncong O
Zheng O
, O
Jiaming O
Xu O
, O
Hongyun O
Bao O
, O
and O
Bo O
Xu O
. O

2016 O
. O

Text B-TaskName
classification I-TaskName
improved O
by O
integrating O
bidirectional O
lstm O
with O
two- O
dimensional O
max O
pooling O
. O

In O
Proceedings O
of O
COL- O
ING O
2016 O
, O
the O
26th O
International O
Conference O
on O
Computational O
Linguistics O
: O
Technical O
Papers O
, O
pages O
3485‚Äì3495 O
, O
Osaka O
, O
Japan O
. O

The O
COLING O
2016 O
Or- O
ganizing O
Committee O
. O